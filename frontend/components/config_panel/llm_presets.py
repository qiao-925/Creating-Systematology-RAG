"""
LLM é¢„è®¾é¢æ¿ç»„ä»¶ - LLM é¢„è®¾é€‰æ‹©çš„ UI æ§åˆ¶

ä¸»è¦åŠŸèƒ½ï¼š
- render_llm_preset_selector(): é¢„è®¾é€‰æ‹©å™¨ï¼ˆç²¾ç¡®/å¹³è¡¡/åˆ›æ„ï¼‰
- render_model_selector(): æ¨¡å‹é€‰æ‹©å™¨
"""

import streamlit as st
from typing import Callable, Optional

from backend.infrastructure.config import config
from backend.infrastructure.llms import get_available_models
from frontend.components.config_panel.models import LLM_PRESETS


def render_model_selector(
    on_model_change: Optional[Callable[[str], None]] = None,
) -> None:
    """æ¸²æŸ“æ¨¡å‹é€‰æ‹©å™¨
    
    Args:
        on_model_change: æ¨¡å‹å˜æ›´å›è°ƒ
    """
    try:
        models = get_available_models()
        if not models:
            st.info("âš ï¸ æœªé…ç½®å¯ç”¨æ¨¡å‹")
            return
        
        # æ„å»ºé€‰é¡¹å­—å…¸ï¼š{æ˜¾ç¤ºåç§°: æ¨¡å‹ID}
        model_options = {model.name: model.id for model in models}
        model_names = list(model_options.keys())
        
        # è·å–å½“å‰é€‰æ‹©çš„æ¨¡å‹
        current_model_id = st.session_state.get(
            'selected_model', config.get_default_llm_id()
        )
        
        # æ‰¾åˆ°å½“å‰æ¨¡å‹åœ¨åˆ—è¡¨ä¸­çš„ç´¢å¼•
        current_index = 0
        for i, (name, model_id) in enumerate(model_options.items()):
            if model_id == current_model_id:
                current_index = i
                break
        
        # æ˜¾ç¤ºæ¨¡å‹é€‰æ‹©å™¨
        selected_name = st.selectbox(
            "ğŸ¤– é€‰æ‹©æ¨¡å‹",
            options=model_names,
            index=current_index,
            key="model_selector_config",
            help="åˆ‡æ¢ä¸åŒçš„ LLM æ¨¡å‹ã€‚åˆ‡æ¢åï¼Œå½“å‰ä¼šè¯çš„åç»­æ¶ˆæ¯å°†ä½¿ç”¨æ–°æ¨¡å‹ã€‚"
        )
        
        # æ›´æ–° session_state
        selected_model_id = model_options[selected_name]
        if st.session_state.get('selected_model') != selected_model_id:
            st.session_state.selected_model = selected_model_id
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ¨ç†æ¨¡å‹
            model_config = config.get_llm_model_config(selected_model_id)
            if model_config and model_config.supports_reasoning:
                st.info(f"âœ… å·²åˆ‡æ¢åˆ° {selected_name}ï¼ˆæ”¯æŒæ¨ç†é“¾ï¼‰")
            else:
                st.info(f"âœ… å·²åˆ‡æ¢åˆ° {selected_name}")
            
            if on_model_change:
                on_model_change(selected_model_id)
    
    except Exception as e:
        st.error(f"åŠ è½½æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        st.session_state.selected_model = config.get_default_llm_id()


def render_llm_preset_selector(
    on_preset_change: Optional[Callable[[str], None]] = None,
) -> None:
    """æ¸²æŸ“ LLM é¢„è®¾é€‰æ‹©å™¨
    
    Args:
        on_preset_change: é¢„è®¾å˜æ›´å›è°ƒ
    """
    # åˆå§‹åŒ–çŠ¶æ€
    if 'llm_preset' not in st.session_state:
        st.session_state.llm_preset = 'balanced'
    
    current_preset = st.session_state.llm_preset
    
    # æ£€æŸ¥å½“å‰æ¨¡å‹æ˜¯å¦ä¸ºæ¨ç†æ¨¡å‹ï¼ˆä¸æ”¯æŒ temperatureï¼‰
    current_model_id = st.session_state.get(
        'selected_model', config.get_default_llm_id()
    )
    model_config = config.get_llm_model_config(current_model_id)
    is_reasoning_model = model_config and model_config.supports_reasoning
    
    # æ„å»ºé€‰é¡¹
    preset_keys = list(LLM_PRESETS.keys())
    preset_names = [LLM_PRESETS[k]["name"] for k in preset_keys]
    
    current_index = preset_keys.index(current_preset) if current_preset in preset_keys else 1
    
    # é¢„è®¾é€‰æ‹©
    st.markdown("**ğŸ¨ å›ç­”é£æ ¼**")
    
    if is_reasoning_model:
        st.caption("âš ï¸ æ¨ç†æ¨¡å‹ä¸æ”¯æŒè°ƒæ•´é£æ ¼")
        # æ˜¾ç¤ºä½†ç¦ç”¨
        st.radio(
            "é€‰æ‹©é£æ ¼",
            options=preset_names,
            index=current_index,
            key="llm_preset_radio_disabled",
            disabled=True,
            label_visibility="collapsed",
        )
    else:
        selected_name = st.radio(
            "é€‰æ‹©é£æ ¼",
            options=preset_names,
            index=current_index,
            key="llm_preset_radio",
            label_visibility="collapsed",
        )
        
        # æ›´æ–°é¢„è®¾
        selected_key = preset_keys[preset_names.index(selected_name)]
        if selected_key != current_preset:
            st.session_state.llm_preset = selected_key
            if on_preset_change:
                on_preset_change(selected_key)
    
    # æ˜¾ç¤ºå½“å‰é¢„è®¾è¯´æ˜
    preset_info = LLM_PRESETS.get(current_preset, LLM_PRESETS["balanced"])
    st.caption(f"ğŸ’¡ {preset_info['description']}")
    
    if not is_reasoning_model:
        st.caption(f"Temperature: {preset_info['temperature']}")
