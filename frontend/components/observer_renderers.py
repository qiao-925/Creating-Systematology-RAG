"""
è§‚å¯Ÿå™¨ä¿¡æ¯æ¸²æŸ“ç»„ä»¶

ä¸»è¦åŠŸèƒ½ï¼š
- æ¸²æŸ“ LlamaDebug å®Œæ•´ä¿¡æ¯
- æ¸²æŸ“ RAGAS å®Œæ•´ä¿¡æ¯
"""

import streamlit as st


def render_llamadebug_full_info(debug_log: dict) -> None:
    """æŒ‰æ‰§è¡Œæµç¨‹æ¸²æŸ“ LlamaDebug å…¨é‡ä¿¡æ¯"""
    
    # ========== é˜¶æ®µ1: æŸ¥è¯¢å¼€å§‹ ==========
    st.markdown("##### ğŸ“ 1. æŸ¥è¯¢é˜¶æ®µ")
    if debug_log.get('query'):
        st.markdown(f"**åŸå§‹æŸ¥è¯¢**: `{debug_log['query']}`")
    
    # æŸ¥è¯¢å¤„ç†ç»“æœï¼ˆæ–°å¢ï¼‰
    query_processing = debug_log.get('query_processing')
    if query_processing:
        col1, col2 = st.columns(2)
        with col1:
            if query_processing.get('rewritten_queries'):
                rewritten = query_processing['rewritten_queries']
                if len(rewritten) > 0:
                    st.markdown(f"**æ”¹å†™åçš„æŸ¥è¯¢**: `{rewritten[0]}`")
                    if len(rewritten) > 1:
                        with st.expander(f"å…¶ä»–æ”¹å†™ç‰ˆæœ¬ ({len(rewritten)-1} ä¸ª)", expanded=False):
                            for i, q in enumerate(rewritten[1:], 2):
                                st.markdown(f"**ç‰ˆæœ¬ {i}**: `{q}`")
        
        with col2:
            if query_processing.get('processing_method'):
                method = query_processing['processing_method']
                method_label = "ç®€å•æŸ¥è¯¢ï¼ˆè·³è¿‡LLMï¼‰" if method == "simple" else "LLMå¤„ç†"
                st.markdown(f"**å¤„ç†æ–¹å¼**: {method_label}")
        
        # æ„å›¾ç†è§£ç»“æœï¼ˆæ–°å¢ï¼‰
        understanding = query_processing.get('understanding')
        if understanding:
            with st.expander("ğŸ§  æŸ¥è¯¢æ„å›¾ç†è§£", expanded=False):
                if isinstance(understanding, dict):
                    if understanding.get('query_type'):
                        st.markdown(f"**æŸ¥è¯¢ç±»å‹**: `{understanding['query_type']}`")
                    if understanding.get('complexity'):
                        complexity = understanding['complexity']
                        complexity_label = {
                            'simple': 'ç®€å•',
                            'medium': 'ä¸­ç­‰',
                            'complex': 'å¤æ‚'
                        }.get(complexity, complexity)
                        st.markdown(f"**å¤æ‚åº¦**: {complexity_label}")
                    if understanding.get('intent'):
                        st.markdown(f"**æŸ¥è¯¢æ„å›¾**: {understanding['intent']}")
                    if understanding.get('entities'):
                        entities = understanding['entities']
                        if entities:
                            st.markdown(f"**å…³é”®å®ä½“**: {', '.join(entities)}")
                    if understanding.get('confidence') is not None:
                        st.markdown(f"**ç½®ä¿¡åº¦**: {understanding['confidence']:.2f}")
                else:
                    st.json(understanding)
    
    # é…ç½®ä¿¡æ¯ï¼ˆæ–°å¢ï¼‰
    if debug_log.get('llm_model') or debug_log.get('retrieval_strategy') or debug_log.get('top_k'):
        with st.expander("âš™ï¸ é…ç½®ä¿¡æ¯", expanded=False):
            col1, col2, col3 = st.columns(3)
            with col1:
                if debug_log.get('llm_model'):
                    st.markdown(f"**LLMæ¨¡å‹**: `{debug_log['llm_model']}`")
                if debug_log.get('llm_params'):
                    params = debug_log['llm_params']
                    if params.get('temperature') is not None:
                        st.markdown(f"**Temperature**: {params['temperature']}")
                    if params.get('max_tokens') is not None:
                        st.markdown(f"**Max Tokens**: {params['max_tokens']}")
            with col2:
                if debug_log.get('retrieval_strategy'):
                    st.markdown(f"**æ£€ç´¢ç­–ç•¥**: `{debug_log['retrieval_strategy']}`")
            with col3:
                if debug_log.get('top_k'):
                    st.markdown(f"**Top K**: {debug_log['top_k']}")
    
    # åŸºç¡€ç»Ÿè®¡
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("äº‹ä»¶æ€»æ•°", debug_log.get('events_count', 0))
    with col2:
        st.metric("LLMè°ƒç”¨", debug_log.get('llm_calls', 0))
    with col3:
        st.metric("æ£€ç´¢è°ƒç”¨", debug_log.get('retrieval_calls', 0))
    with col4:
        total_time = debug_log.get('total_time', 0)
        if total_time:
            st.metric("æ€»è€—æ—¶", f"{total_time:.3f}s")
    
    # äº‹ä»¶ç±»å‹ç»Ÿè®¡
    if debug_log.get('event_type_counts'):
        st.markdown("**äº‹ä»¶ç±»å‹ç»Ÿè®¡**:")
        event_counts = debug_log['event_type_counts']
        cols = st.columns(min(len(event_counts), 5))
        for idx, (event_type, count) in enumerate(list(event_counts.items())[:5]):
            with cols[idx % 5]:
                st.markdown(f"- `{event_type}`: {count}")
    
    st.divider()
    
    # ========== é˜¶æ®µ2: æ£€ç´¢é˜¶æ®µ ==========
    st.markdown("##### ğŸ” 2. æ£€ç´¢é˜¶æ®µ")
    
    # æ£€ç´¢ç»Ÿè®¡
    retrieval_info = debug_log.get('retrieval', {})
    if retrieval_info:
        col1, col2, col3 = st.columns(3)
        with col1:
            if retrieval_info.get('nodes_retrieved'):
                st.metric("æ£€ç´¢èŠ‚ç‚¹æ•°", retrieval_info['nodes_retrieved'])
        with col2:
            if retrieval_info.get('retrieval_time'):
                st.metric("æ£€ç´¢è€—æ—¶", f"{retrieval_info['retrieval_time']:.3f}s")
        with col3:
            if retrieval_info.get('similarity_cutoff'):
                st.metric("ç›¸ä¼¼åº¦é˜ˆå€¼", f"{retrieval_info['similarity_cutoff']:.3f}")
        
        # æ£€ç´¢èŠ‚ç‚¹è¯¦æƒ…
        if retrieval_info.get('nodes'):
            with st.expander(f"æŸ¥çœ‹æ£€ç´¢èŠ‚ç‚¹ ({len(retrieval_info['nodes'])} ä¸ª)", expanded=False):
                for i, node in enumerate(retrieval_info['nodes'], 1):
                    st.markdown(f"**èŠ‚ç‚¹ {i}**:")
                    if isinstance(node, dict):
                        if node.get('text'):
                            st.text(node['text'][:500] + "..." if len(node['text']) > 500 else node['text'])
                        if node.get('score') is not None:
                            st.caption(f"ç›¸ä¼¼åº¦: {node['score']:.4f}")
                        if node.get('metadata'):
                            with st.expander("å…ƒæ•°æ®", expanded=False):
                                st.json(node['metadata'])
                    else:
                        st.text(str(node)[:500])
                    st.divider()
    
    st.divider()
    
    # ========== é˜¶æ®µ3: LLMç”Ÿæˆé˜¶æ®µ ==========
    st.markdown("##### ğŸ¤– 3. LLMç”Ÿæˆé˜¶æ®µ")
    
    llm_info = debug_log.get('llm_generation', {})
    if llm_info:
        col1, col2, col3 = st.columns(3)
        with col1:
            if llm_info.get('generation_time'):
                st.metric("ç”Ÿæˆè€—æ—¶", f"{llm_info['generation_time']:.3f}s")
        with col2:
            if llm_info.get('tokens_generated'):
                st.metric("ç”ŸæˆTokenæ•°", llm_info['tokens_generated'])
        with col3:
            if llm_info.get('tokens_per_second'):
                st.metric("ç”Ÿæˆé€Ÿåº¦", f"{llm_info['tokens_per_second']:.1f} tokens/s")
        
        # LLMè°ƒç”¨è¯¦æƒ…
        if llm_info.get('calls'):
            with st.expander(f"æŸ¥çœ‹LLMè°ƒç”¨è¯¦æƒ… ({len(llm_info['calls'])} æ¬¡)", expanded=False):
                for i, call in enumerate(llm_info['calls'], 1):
                    st.markdown(f"**è°ƒç”¨ {i}**:")
                    if isinstance(call, dict):
                        if call.get('prompt'):
                            with st.expander("Prompt", expanded=False):
                                st.text(call['prompt'][:1000] + "..." if len(call['prompt']) > 1000 else call['prompt'])
                        if call.get('response'):
                            with st.expander("Response", expanded=False):
                                st.text(call['response'][:1000] + "..." if len(call['response']) > 1000 else call['response'])
                        if call.get('tokens'):
                            st.caption(f"Tokens: {call['tokens']}")
                    else:
                        st.text(str(call)[:500])
                    st.divider()
    
    st.divider()
    
    # ========== é˜¶æ®µ4: åå¤„ç†é˜¶æ®µ ==========
    st.markdown("##### ğŸ”§ 4. åå¤„ç†é˜¶æ®µ")
    
    postprocess_info = debug_log.get('postprocessing', {})
    if postprocess_info:
        if postprocess_info.get('reranking_applied'):
            st.markdown("**é‡æ’åº**: âœ… å·²åº”ç”¨")
            if postprocess_info.get('reranked_count'):
                st.metric("é‡æ’åºåèŠ‚ç‚¹æ•°", postprocess_info['reranked_count'])
        else:
            st.markdown("**é‡æ’åº**: âŒ æœªåº”ç”¨")
    
    st.divider()
    
    # ========== é˜¶æ®µ5: å®Œæ•´äº‹ä»¶åˆ—è¡¨ ==========
    st.markdown("##### ğŸ“‹ 5. å®Œæ•´äº‹ä»¶åˆ—è¡¨")
    
    if debug_log.get('events'):
        with st.expander("æŸ¥çœ‹æ‰€æœ‰äº‹ä»¶", expanded=False):
            for i, event in enumerate(debug_log['events'], 1):
                st.markdown(f"**äº‹ä»¶ {i}**:")
                if isinstance(event, dict):
                    st.json(event)
                else:
                    st.text(str(event))
                st.divider()


def render_ragas_full_info(ragas_log: dict) -> None:
    """æŒ‰æ‰§è¡Œæµç¨‹æ¸²æŸ“ RAGAS å…¨é‡ä¿¡æ¯"""
    
    is_pending = ragas_log.get('pending_evaluation', False)
    status_icon = "â³" if is_pending else "âœ…"
    
    # ========== é˜¶æ®µ1: æ•°æ®æ”¶é›†é˜¶æ®µ ==========
    st.markdown("##### ğŸ“¥ 1. æ•°æ®æ”¶é›†é˜¶æ®µ")
    
    st.markdown(f"**çŠ¶æ€**: {status_icon} {'å¾…è¯„ä¼°' if is_pending else 'å·²è¯„ä¼°'}")
    
    # æ•°æ®ç»Ÿè®¡
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç­”æ¡ˆé•¿åº¦", f"{ragas_log.get('answer_length', 0)} å­—ç¬¦")
    with col2:
        st.metric("ä¸Šä¸‹æ–‡æ•°", ragas_log.get('contexts_count', 0))
    with col3:
        st.metric("æ¥æºæ•°", ragas_log.get('sources_count', 0))
    with col4:
        if ragas_log.get('timestamp'):
            from datetime import datetime
            try:
                ts = datetime.fromisoformat(ragas_log['timestamp'].replace('Z', '+00:00'))
                st.caption(f"æ”¶é›†æ—¶é—´: {ts.strftime('%H:%M:%S')}")
            except:
                st.caption(f"æ—¶é—´: {ragas_log['timestamp']}")
    
    # æŸ¥è¯¢å†…å®¹
    if ragas_log.get('query'):
        st.markdown("**ğŸ“ æŸ¥è¯¢å†…å®¹**:")
        st.code(ragas_log['query'], language=None)
    
    # ç­”æ¡ˆå†…å®¹
    if ragas_log.get('answer'):
        with st.expander(f"ğŸ“„ ç­”æ¡ˆå†…å®¹ ({ragas_log.get('answer_length', 0)} å­—ç¬¦)", expanded=False):
            st.markdown(ragas_log['answer'])
    
    # ä¸Šä¸‹æ–‡è¯¦æƒ…
    if ragas_log.get('contexts'):
        st.markdown(f"**ğŸ“š ä¸Šä¸‹æ–‡æ•°æ® ({len(ragas_log['contexts'])} ä¸ª)**:")
        with st.expander(f"æŸ¥çœ‹æ‰€æœ‰ä¸Šä¸‹æ–‡", expanded=False):
            for i, ctx in enumerate(ragas_log['contexts'], 1):
                st.markdown(f"**ä¸Šä¸‹æ–‡ {i}** ({len(ctx)} å­—ç¬¦):")
                st.text(ctx[:800] + "..." if len(ctx) > 800 else ctx)
                st.divider()
    
    # æ¥æºè¯¦æƒ…
    if ragas_log.get('sources'):
        st.markdown(f"**ğŸ”— æ¥æºè¯¦æƒ… ({len(ragas_log['sources'])} ä¸ª)**:")
        with st.expander(f"æŸ¥çœ‹æ‰€æœ‰æ¥æº", expanded=False):
            for i, source in enumerate(ragas_log['sources'], 1):
                st.markdown(f"**æ¥æº {i}**:")
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.text(source.get('text', '')[:400] + "..." if len(source.get('text', '')) > 400 else source.get('text', ''))
                with col2:
                    if source.get('score') is not None:
                        st.metric("ç›¸ä¼¼åº¦", f"{source['score']:.4f}")
                    if source.get('metadata'):
                        with st.expander("å…ƒæ•°æ®", expanded=False):
                            st.json(source['metadata'])
                st.divider()
    elif ragas_log.get('sources_count', 0) > 0:
        st.markdown(f"**ğŸ”— æ¥æºç»Ÿè®¡**: {ragas_log['sources_count']} ä¸ªæ¥æº")
    
    # Ground Truthï¼ˆå¦‚æœæœ‰ï¼‰
    if ragas_log.get('ground_truth'):
        with st.expander("ğŸ¯ Ground Truthï¼ˆçœŸå€¼ï¼‰", expanded=False):
            st.markdown(ragas_log['ground_truth'])
    
    # Trace IDï¼ˆå¦‚æœæœ‰ï¼‰
    if ragas_log.get('trace_id'):
        st.caption(f"Trace ID: {ragas_log['trace_id']}")
    
    st.divider()
    
    # ========== é˜¶æ®µ2: æ‰¹é‡è¯„ä¼°çŠ¶æ€ ==========
    st.markdown("##### ğŸ“Š 2. æ‰¹é‡è¯„ä¼°çŠ¶æ€")
    
    # è®¡ç®—å¾…è¯„ä¼°æ•°æ®é‡
    if 'ragas_logs' in st.session_state:
        pending_count = sum(
            1 for log in st.session_state.ragas_logs 
            if log.get('pending_evaluation', True)
        )
        evaluated_count = len(st.session_state.ragas_logs) - pending_count
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»è®°å½•æ•°", len(st.session_state.ragas_logs))
        with col2:
            st.metric("å¾…è¯„ä¼°", pending_count, delta=None)
        with col3:
            st.metric("å·²è¯„ä¼°", evaluated_count, delta=None)
        
        # æ‰¹é‡è¯„ä¼°è¿›åº¦
        batch_size = ragas_log.get('evaluation_batch_size', 10)
        if is_pending:
            progress = min(pending_count / batch_size, 1.0)
            st.progress(progress)
            st.info(f"â³ å½“å‰è®°å½•å¾…è¯„ä¼°ï¼Œæ‰¹é‡è¯„ä¼°å°†åœ¨è¾¾åˆ° {batch_size} æ¡æ•°æ®æ—¶è‡ªåŠ¨è§¦å‘ï¼ˆå½“å‰: {pending_count}/{batch_size}ï¼‰")
            
            if pending_count > 0:
                st.markdown(f"**è¯„ä¼°é˜Ÿåˆ—**: è¿˜æœ‰ {pending_count - 1} æ¡è®°å½•åœ¨é˜Ÿåˆ—ä¸­ç­‰å¾…")
        else:
            st.success("âœ… æ­¤è®°å½•å·²å®Œæˆè¯„ä¼°")
            if ragas_log.get('evaluation_timestamp'):
                from datetime import datetime
                try:
                    eval_ts = datetime.fromisoformat(ragas_log['evaluation_timestamp'].replace('Z', '+00:00'))
                    st.caption(f"è¯„ä¼°æ—¶é—´: {eval_ts.strftime('%Y-%m-%d %H:%M:%S')}")
                except:
                    st.caption(f"è¯„ä¼°æ—¶é—´: {ragas_log['evaluation_timestamp']}")
    
    st.divider()
    
    # ========== é˜¶æ®µ3: è¯„ä¼°æŒ‡æ ‡è¯¦æƒ… ==========
    st.markdown("##### ğŸ“ˆ 3. è¯„ä¼°æŒ‡æ ‡è¯¦æƒ…")
    
    if not is_pending and ragas_log.get('evaluation_result'):
        eval_result = ragas_log['evaluation_result']
        
        if isinstance(eval_result, dict):
            st.markdown("**è¯„ä¼°æŒ‡æ ‡æ¦‚è§ˆ**:")
            
            metrics_list = list(eval_result.items())
            num_cols = min(len(metrics_list), 5)
            cols = st.columns(num_cols)
            
            for idx, (metric, value) in enumerate(metrics_list):
                with cols[idx % num_cols]:
                    value_str = f"{value:.4f}" if isinstance(value, (int, float)) else str(value)
                    if isinstance(value, (int, float)):
                        if value >= 0.8:
                            color = "ğŸŸ¢"
                            status = "ä¼˜ç§€"
                        elif value >= 0.6:
                            color = "ğŸŸ¡"
                            status = "è‰¯å¥½"
                        else:
                            color = "ğŸ”´"
                            status = "éœ€æ”¹è¿›"
                        
                        st.metric(f"{color} {metric}", value_str, delta=status)
                    else:
                        st.markdown(f"**{metric}**: {value_str}")
            
            st.divider()
            
            # è¯¦ç»†æŒ‡æ ‡è¯´æ˜
            st.markdown("**æŒ‡æ ‡è¯´æ˜**:")
            metric_descriptions = {
                "faithfulness": "å¿ å®åº¦ï¼šç­”æ¡ˆæ˜¯å¦åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡",
                "context_precision": "ä¸Šä¸‹æ–‡ç²¾ç¡®åº¦ï¼šæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ˜¯å¦ç›¸å…³",
                "context_recall": "ä¸Šä¸‹æ–‡å¬å›ç‡ï¼šæ˜¯å¦æ£€ç´¢åˆ°æ‰€æœ‰ç›¸å…³ä¿¡æ¯",
                "answer_relevancy": "ç­”æ¡ˆç›¸å…³æ€§ï¼šç­”æ¡ˆæ˜¯å¦å›ç­”äº†æŸ¥è¯¢",
                "context_relevancy": "ä¸Šä¸‹æ–‡ç›¸å…³æ€§ï¼šä¸Šä¸‹æ–‡æ˜¯å¦ä¸æŸ¥è¯¢ç›¸å…³",
            }
            
            for metric, value in eval_result.items():
                description = metric_descriptions.get(metric, "è¯„ä¼°æŒ‡æ ‡")
                value_str = f"{value:.4f}" if isinstance(value, (int, float)) else str(value)
                
                with st.expander(f"ğŸ“Š {metric}: {value_str}", expanded=False):
                    st.markdown(f"**è¯´æ˜**: {description}")
                    if isinstance(value, (int, float)):
                        st.progress(value)
                        if value >= 0.8:
                            st.success(f"âœ… ä¼˜ç§€ ({value:.2%})")
                        elif value >= 0.6:
                            st.warning(f"âš ï¸ è‰¯å¥½ ({value:.2%})")
                        else:
                            st.error(f"âŒ éœ€æ”¹è¿› ({value:.2%})")
        else:
            st.markdown("**è¯„ä¼°ç»“æœ**:")
            st.text(str(eval_result)[:1000])
    elif is_pending:
        st.info("â³ æ­¤è®°å½•å°šæœªè¯„ä¼°ï¼Œç­‰å¾…æ‰¹é‡è¯„ä¼°è§¦å‘")
    else:
        st.warning("âš ï¸ æš‚æ— è¯„ä¼°ç»“æœ")
    
    st.divider()
    
    # ========== é˜¶æ®µ4: è¯„ä¼°æ•°æ®è´¨é‡ ==========
    st.markdown("##### ğŸ” 4. è¯„ä¼°æ•°æ®è´¨é‡")
    
    # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
    quality_checks = []
    
    if ragas_log.get('query'):
        quality_checks.append(("âœ…", "æŸ¥è¯¢æ•°æ®", "å·²æ”¶é›†", f"{len(ragas_log['query'])} å­—ç¬¦"))
    else:
        quality_checks.append(("âŒ", "æŸ¥è¯¢æ•°æ®", "ç¼ºå¤±", ""))
    
    if ragas_log.get('answer'):
        quality_checks.append(("âœ…", "ç­”æ¡ˆæ•°æ®", "å·²æ”¶é›†", f"{ragas_log.get('answer_length', 0)} å­—ç¬¦"))
    else:
        quality_checks.append(("âŒ", "ç­”æ¡ˆæ•°æ®", "ç¼ºå¤±", ""))
    
    if ragas_log.get('contexts_count', 0) > 0:
        total_ctx_len = sum(len(ctx) for ctx in ragas_log.get('contexts', []))
        quality_checks.append(("âœ…", "ä¸Šä¸‹æ–‡æ•°æ®", f"å·²æ”¶é›† ({ragas_log.get('contexts_count', 0)} ä¸ª)", f"æ€»é•¿åº¦: {total_ctx_len} å­—ç¬¦"))
    else:
        quality_checks.append(("âš ï¸", "ä¸Šä¸‹æ–‡æ•°æ®", "ä¸ºç©º", ""))
    
    if ragas_log.get('sources_count', 0) > 0:
        quality_checks.append(("âœ…", "æ¥æºæ•°æ®", f"å·²æ”¶é›† ({ragas_log.get('sources_count', 0)} ä¸ª)", ""))
    else:
        quality_checks.append(("âš ï¸", "æ¥æºæ•°æ®", "ä¸ºç©º", ""))
    
    if ragas_log.get('ground_truth'):
        quality_checks.append(("âœ…", "Ground Truth", "å·²æä¾›", ""))
    else:
        quality_checks.append(("â„¹ï¸", "Ground Truth", "æœªæä¾›ï¼ˆå¯é€‰ï¼‰", ""))
    
    # æ˜¾ç¤ºè´¨é‡æ£€æŸ¥ç»“æœ
    for icon, check_name, status, detail in quality_checks:
        if detail:
            st.markdown(f"{icon} **{check_name}**: {status} - {detail}")
        else:
            st.markdown(f"{icon} **{check_name}**: {status}")
    
    # æ•°æ®è´¨é‡è¯„åˆ†
    required_checks = [c for c in quality_checks if c[0] != "â„¹ï¸"]
    quality_score = sum(1 for icon, _, _, _ in required_checks if icon == "âœ…") / len(required_checks) if required_checks else 0
    passed_checks = sum(1 for icon, _, _, _ in required_checks if icon == "âœ…")
    st.markdown(f"**æ•°æ®å®Œæ•´æ€§**: {quality_score:.0%} ({passed_checks}/{len(required_checks)} å¿…éœ€é¡¹é€šè¿‡)")
    st.progress(quality_score)
    
    # æ•°æ®è´¨é‡å»ºè®®
    if quality_score < 1.0:
        st.warning("âš ï¸ æ•°æ®ä¸å®Œæ•´ï¼Œå¯èƒ½å½±å“è¯„ä¼°å‡†ç¡®æ€§")
    elif quality_score == 1.0 and ragas_log.get('ground_truth'):
        st.success("âœ… æ•°æ®å®Œæ•´ä¸”åŒ…å« Ground Truthï¼Œè¯„ä¼°ç»“æœæœ€å‡†ç¡®")
    elif quality_score == 1.0:
        st.info("â„¹ï¸ æ•°æ®å®Œæ•´ï¼Œä½†ç¼ºå°‘ Ground Truthï¼Œéƒ¨åˆ†æŒ‡æ ‡å¯èƒ½æ— æ³•è®¡ç®—")
