# å¼€å‘è€…æŒ‡å—

> é¢å‘å¼€å‘è€…çš„è¯¦ç»†ä»£ç è¯´æ˜å’Œå¼€å‘æŒ‡å—

## ç›®å½•

- [å¿«é€Ÿä¸Šæ‰‹](#å¿«é€Ÿä¸Šæ‰‹)
- [ä»£ç ç»“æ„è¯´æ˜](#ä»£ç ç»“æ„è¯´æ˜)
- [æ ¸å¿ƒAPIå‚è€ƒ](#æ ¸å¿ƒapiå‚è€ƒ)
- [å¸¸è§å¼€å‘ä»»åŠ¡](#å¸¸è§å¼€å‘ä»»åŠ¡)
- [è°ƒè¯•æŠ€å·§](#è°ƒè¯•æŠ€å·§)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## å¿«é€Ÿä¸Šæ‰‹

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd Creating-Systematology-RAG

# 2. å®‰è£…å¼€å‘ä¾èµ–
uv sync

# 3. é…ç½®ç¯å¢ƒå˜é‡
cp env.template .env
# ç¼–è¾‘ .env æ–‡ä»¶

# 4. è¿è¡Œæµ‹è¯•
python -m pytest tests/  # å¦‚æœæœ‰æµ‹è¯•

# 5. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
streamlit run app.py
```

### é¡¹ç›®ç»“æ„è¯´æ˜

```
Creating-Systematology-RAG/
â”œâ”€â”€ src/                        # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ __init__.py            # åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ config.py              # é…ç½®ç®¡ç† [é‡è¦]
â”‚   â”œâ”€â”€ data_loader.py         # æ•°æ®åŠ è½½ [æ‰©å±•ç‚¹]
â”‚   â”œâ”€â”€ indexer.py             # ç´¢å¼•æ„å»º [æ ¸å¿ƒ]
â”‚   â”œâ”€â”€ query_engine.py        # æŸ¥è¯¢å¼•æ“ [æ ¸å¿ƒ]
â”‚   â””â”€â”€ chat_manager.py        # å¯¹è¯ç®¡ç† [æ ¸å¿ƒ]
â”œâ”€â”€ app.py                      # Streamlit Web åº”ç”¨
â”œâ”€â”€ main.py                     # CLI å‘½ä»¤è¡Œå·¥å…·
â”œâ”€â”€ data/                       # æ•°æ®ç›®å½•
â”œâ”€â”€ vector_store/              # å‘é‡æ•°æ®åº“å­˜å‚¨
â”œâ”€â”€ sessions/                  # ä¼šè¯è®°å½•
â””â”€â”€ docs/                      # æ–‡æ¡£
    â”œâ”€â”€ ARCHITECTURE.md        # æ¶æ„è®¾è®¡ [å…ˆè¯»è¿™ä¸ª]
    â”œâ”€â”€ DEVELOPER_GUIDE.md     # æœ¬æ–‡ä»¶
    â””â”€â”€ API.md                 # API æ–‡æ¡£
```

**é˜…è¯»é¡ºåºå»ºè®®**ï¼š
1. `docs/ARCHITECTURE.md` - ç†è§£æ•´ä½“æ¶æ„
2. `docs/DEVELOPER_GUIDE.md` - æœ¬æ–‡ï¼Œäº†è§£å¼€å‘ç»†èŠ‚
3. `src/config.py` - ç†è§£é…ç½®ç®¡ç†
4. `src/indexer.py` - ç†è§£æ ¸å¿ƒç´¢å¼•é€»è¾‘
5. `src/query_engine.py` æˆ– `src/chat_manager.py` - æ ¹æ®éœ€æ±‚é€‰æ‹©

---

## ä»£ç ç»“æ„è¯´æ˜

### 1. é…ç½®ç®¡ç†ï¼ˆsrc/config.pyï¼‰

**æ–‡ä»¶èŒè´£**ï¼šç»Ÿä¸€ç®¡ç†æ‰€æœ‰é…ç½®

**æ ¸å¿ƒä»£ç è§£æ**ï¼š

```python
class Config:
    def __init__(self):
        # 1. é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŸºäºä»£ç æ–‡ä»¶ä½ç½®è‡ªåŠ¨ç¡®å®šï¼‰
        self.PROJECT_ROOT = Path(__file__).parent.parent
        
        # 2. API é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        self.DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")
        
        # 3. è·¯å¾„é…ç½®ï¼ˆæ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„ï¼‰
        self.VECTOR_STORE_PATH = self._get_path("VECTOR_STORE_PATH", "vector_store")
```

**å…³é”®æ–¹æ³• `_get_path` è§£æ**ï¼š
```python
def _get_path(self, env_var: str, default: str) -> Path:
    """æ™ºèƒ½è·¯å¾„å¤„ç†
    - å¦‚æœç¯å¢ƒå˜é‡ä¸­æ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
    - å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äº PROJECT_ROOT
    """
    path_str = os.getenv(env_var, default)
    path = Path(path_str)
    
    if not path.is_absolute():
        path = self.PROJECT_ROOT / path  # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        
    return path
```

**ä½¿ç”¨æ–¹å¼**ï¼š
```python
from src.config import config

# ç›´æ¥ä½¿ç”¨å…¨å±€é…ç½®å®ä¾‹
print(config.DEEPSEEK_API_KEY)
print(config.VECTOR_STORE_PATH)
```

**æ‰©å±•é…ç½®**ï¼š
```python
# åœ¨ Config.__init__ ä¸­æ·»åŠ æ–°é…ç½®
self.MY_NEW_CONFIG = os.getenv("MY_NEW_CONFIG", "default_value")

# åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®
MY_NEW_CONFIG=my_value
```

---

### 2. æ•°æ®åŠ è½½å™¨ï¼ˆsrc/data_loader.pyï¼‰

**æ–‡ä»¶èŒè´£**ï¼šåŠ è½½å’Œé¢„å¤„ç†å„ç±»æ•°æ®æº

**ç±»å›¾**ï¼š
```
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ LlamaDocument   â”‚  â† LlamaIndex çš„æ–‡æ¡£ç±»
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚MarkdownLoader  â”‚  â”‚  WebLoader   â”‚  â”‚DocumentProcessor â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**MarkdownLoader è¯¦è§£**ï¼š

```python
class MarkdownLoader:
    def load_file(self, file_path: Path) -> Optional[LlamaDocument]:
        # æ­¥éª¤ 1ï¼šè¯»å–æ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ­¥éª¤ 2ï¼šæå–æ ‡é¢˜ï¼ˆç”¨äºå…ƒæ•°æ®ï¼‰
        title = self._extract_title(content)  # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª "# æ ‡é¢˜"
        
        # æ­¥éª¤ 3ï¼šæ„å»º LlamaDocument
        doc = LlamaDocument(
            text=content,                    # åŸå§‹æ–‡æœ¬
            metadata={                       # å…ƒæ•°æ®
                "file_path": str(file_path),
                "file_name": file_path.name,
                "title": title,
                "source_type": "markdown",
            }
        )
        return doc
```

**ä¸ºä»€ä¹ˆéœ€è¦å…ƒæ•°æ®ï¼Ÿ**
- åœ¨æŸ¥è¯¢ç»“æœä¸­æ˜¾ç¤ºæ¥æº
- æ–¹ä¾¿è¿‡æ»¤å’Œåˆ†ç±»
- ä¾¿äºè°ƒè¯•å’Œè¿½è¸ª

**WebLoader å…³é”®ç‚¹**ï¼š

```python
class WebLoader:
    def load_url(self, url: str) -> Optional[LlamaDocument]:
        # æ­¥éª¤ 1ï¼šå‘é€ HTTP è¯·æ±‚
        response = requests.get(url, headers=self.headers, timeout=self.timeout)
        
        # æ­¥éª¤ 2ï¼šè§£æ HTML
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # æ­¥éª¤ 3ï¼šç§»é™¤æ— ç”¨æ ‡ç­¾
        for script in soup(["script", "style"]):  # åˆ é™¤ JS å’Œ CSS
            script.decompose()
        
        # æ­¥éª¤ 4ï¼šæå–çº¯æ–‡æœ¬
        text = soup.get_text(separator='\n', strip=True)
        
        # æ­¥éª¤ 5ï¼šæ¸…ç†æ ¼å¼
        text = re.sub(r'\n\s*\n', '\n\n', text)  # åˆå¹¶å¤šä½™ç©ºè¡Œ
```

**DocumentProcessor çš„ä½œç”¨**ï¼š

```python
@staticmethod
def clean_text(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬
    1. ç§»é™¤å¤šä½™ç©ºç™½
    2. ç»Ÿä¸€æ¢è¡Œ
    3. å»é™¤é¦–å°¾ç©ºæ ¼
    """
    text = re.sub(r'[ \t]+', ' ', text)      # å¤šä¸ªç©ºæ ¼ â†’ å•ä¸ªç©ºæ ¼
    text = re.sub(r'\n{3,}', '\n\n', text)   # å¤šä¸ªæ¢è¡Œ â†’ ä¸¤ä¸ªæ¢è¡Œ
    return text.strip()
```

**æ·»åŠ æ–°æ•°æ®æºç¤ºä¾‹**ï¼š

```python
class SQLLoader:
    """ä»æ•°æ®åº“åŠ è½½æ•°æ®"""
    
    def __init__(self, connection_string: str):
        self.conn = create_connection(connection_string)
    
    def load_table(self, table_name: str) -> List[LlamaDocument]:
        # 1. æŸ¥è¯¢æ•°æ®åº“
        rows = self.conn.execute(f"SELECT * FROM {table_name}")
        
        # 2. æ¯è¡Œè½¬æ¢ä¸ºæ–‡æ¡£
        documents = []
        for row in rows:
            doc = LlamaDocument(
                text=row['content'],
                metadata={
                    "source_type": "database",
                    "table": table_name,
                    "id": row['id']
                }
            )
            documents.append(doc)
        
        return documents
```

---

### 3. ç´¢å¼•æ„å»ºå™¨ï¼ˆsrc/indexer.pyï¼‰

**æ–‡ä»¶èŒè´£**ï¼šæ„å»ºå’Œç®¡ç†å‘é‡ç´¢å¼•

**åˆå§‹åŒ–æµç¨‹è¯¦è§£**ï¼š

```python
class IndexManager:
    def __init__(self, ...):
        # æ­¥éª¤ 1ï¼šåŠ è½½ Embedding æ¨¡å‹
        self.embed_model = HuggingFaceEmbedding(
            model_name="BAAI/bge-base-zh-v1.5",  # ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹
            trust_remote_code=True,
        )
        # é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹åˆ° ~/.cache/huggingface/
        
        # æ­¥éª¤ 2ï¼šå…¨å±€é…ç½®ï¼ˆå½±å“æ‰€æœ‰ LlamaIndex æ“ä½œï¼‰
        Settings.embed_model = self.embed_model      # è®¾ç½® embedding
        Settings.chunk_size = 512                    # åˆ†å—å¤§å°
        Settings.chunk_overlap = 50                  # é‡å å¤§å°
        
        # æ­¥éª¤ 3ï¼šåˆå§‹åŒ– Chroma
        self.chroma_client = chromadb.PersistentClient(
            path=str(self.persist_dir)  # SQLite å­˜å‚¨è·¯å¾„
        )
        
        # æ­¥éª¤ 4ï¼šåˆ›å»ºæˆ–è·å–é›†åˆ
        self.chroma_collection = self.chroma_client.get_or_create_collection(
            name=self.collection_name
        )
        
        # æ­¥éª¤ 5ï¼šåŒ…è£…ä¸º LlamaIndex çš„ VectorStore
        self.vector_store = ChromaVectorStore(
            chroma_collection=self.chroma_collection
        )
```

**ç´¢å¼•æ„å»ºçš„ä¸¤ç§æ¨¡å¼**ï¼š

```python
def build_index(self, documents: List[LlamaDocument]) -> VectorStoreIndex:
    # æ¨¡å¼ 1ï¼šä»å¤´åˆ›å»ºç´¢å¼•
    if self._index is None:
        self._index = VectorStoreIndex.from_documents(
            documents,
            storage_context=self.storage_context,
            show_progress=True
        )
        # å†…éƒ¨æµç¨‹ï¼š
        # 1. åˆ†å—ï¼ˆSentenceSplitterï¼‰
        # 2. æ¯ä¸ªå— â†’ embed_model â†’ å‘é‡
        # 3. å‘é‡ + å…ƒæ•°æ® â†’ Chroma å­˜å‚¨
    
    # æ¨¡å¼ 2ï¼šå¢é‡æ·»åŠ 
    else:
        for doc in documents:
            self._index.insert(doc)
        # é€‚ç”¨äºå·²æœ‰ç´¢å¼•ï¼Œåªæ·»åŠ æ–°æ–‡æ¡£
```

**ä¸ºä»€ä¹ˆéœ€è¦ StorageContextï¼Ÿ**

```python
self.storage_context = StorageContext.from_defaults(
    vector_store=self.vector_store
)
```

`StorageContext` æ˜¯ LlamaIndex çš„å­˜å‚¨æŠ½è±¡å±‚ï¼š
- ç®¡ç†å‘é‡å­˜å‚¨
- ç®¡ç†æ–‡æ¡£å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
- ç®¡ç†ç´¢å¼•ç»“æ„å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
- ä¾¿äºåœ¨ä¸åŒå­˜å‚¨åç«¯é—´åˆ‡æ¢

**Chroma çš„æ•°æ®ç»“æ„**ï¼š

```
Chroma Collection
â”œâ”€â”€ id: å”¯ä¸€æ ‡è¯†ç¬¦
â”œâ”€â”€ embedding: å‘é‡ [768ç»´æµ®ç‚¹æ•°]
â”œâ”€â”€ document: æ–‡æœ¬å†…å®¹
â””â”€â”€ metadata: {
    "file_name": "xxx.md",
    "title": "xxx",
    ...
}
```

**æŸ¥è¯¢å‘é‡æ•°æ®åº“çš„åº•å±‚æµç¨‹**ï¼š

```python
# 1. ç”¨æˆ·é—®é¢˜å‘é‡åŒ–
question = "ä»€ä¹ˆæ˜¯ç³»ç»Ÿç§‘å­¦ï¼Ÿ"
question_vector = embed_model.get_text_embedding(question)  # [768]

# 2. Chroma ç›¸ä¼¼åº¦æœç´¢ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
results = chroma_collection.query(
    query_embeddings=[question_vector],
    n_results=3  # top 3
)

# 3. è¿”å›æœ€ç›¸ä¼¼çš„æ–‡æ¡£å—
```

---

### 4. æŸ¥è¯¢å¼•æ“ï¼ˆsrc/query_engine.pyï¼‰

**æ–‡ä»¶èŒè´£**ï¼šå¤„ç†æŸ¥è¯¢ï¼Œç”Ÿæˆå¸¦å¼•ç”¨çš„ç­”æ¡ˆ

**CitationQueryEngine å·¥ä½œåŸç†**ï¼š

```python
self.query_engine = CitationQueryEngine.from_args(
    index,
    llm=self.llm,
    similarity_top_k=3,         # æ£€ç´¢ 3 ä¸ªæ–‡æ¡£
    citation_chunk_size=512,    # å¼•ç”¨å—å¤§å°
)
```

**å†…éƒ¨æµç¨‹ï¼ˆç®€åŒ–ç‰ˆï¼‰**ï¼š

```python
def query(self, question: str):
    # æ­¥éª¤ 1ï¼šæ£€ç´¢ç›¸å…³æ–‡æ¡£
    retrieved_nodes = index.retrieve(question, top_k=3)
    
    # æ­¥éª¤ 2ï¼šæ„å»ºå¸¦ç¼–å·çš„ä¸Šä¸‹æ–‡
    context = ""
    for i, node in enumerate(retrieved_nodes, 1):
        context += f"[{i}] {node.text}\n\n"
    
    # æ­¥éª¤ 3ï¼šæ„å»º Prompt
    prompt = f"""
    åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼Œå¹¶åœ¨ç­”æ¡ˆä¸­å¼•ç”¨æ¥æºç¼–å· [1], [2], [3]ã€‚
    
    ä¸Šä¸‹æ–‡ï¼š
    {context}
    
    é—®é¢˜ï¼š{question}
    
    ç­”æ¡ˆï¼š
    """
    
    # æ­¥éª¤ 4ï¼šè°ƒç”¨ LLM
    answer = llm.complete(prompt)
    
    # æ­¥éª¤ 5ï¼šè§£æå¼•ç”¨
    # answer ä¸­åŒ…å« [1], [2] ç­‰å¼•ç”¨æ ‡è®°
    
    return answer, retrieved_nodes
```

**DeepSeek API è°ƒç”¨ç»†èŠ‚**ï¼š

```python
from llama_index.llms.openai import OpenAI

self.llm = OpenAI(
    api_key="sk-xxx",
    api_base="https://api.deepseek.com/v1",  # å…³é”®ï¼šDeepSeek ç«¯ç‚¹
    model="deepseek-chat",
    temperature=0.1,  # ä½æ¸©åº¦ â†’ æ›´ç¡®å®šæ€§çš„è¾“å‡º
)

# å®é™…è°ƒç”¨
response = self.llm.complete(prompt)
# ç­‰ä»·äºï¼š
# POST https://api.deepseek.com/v1/completions
# {
#   "model": "deepseek-chat",
#   "prompt": "...",
#   "temperature": 0.1
# }
```

**temperature å‚æ•°è¯´æ˜**ï¼š
- `0.0`ï¼šå®Œå…¨ç¡®å®šæ€§ï¼Œæ¯æ¬¡è¾“å‡ºç›¸åŒ
- `0.1-0.3`ï¼šè¾ƒç¡®å®šï¼Œé€‚åˆé—®ç­”
- `0.7-1.0`ï¼šè¾ƒéšæœºï¼Œé€‚åˆåˆ›ä½œ

**æå–å¼•ç”¨æ¥æºçš„ä»£ç **ï¼š

```python
def query(self, question: str) -> Tuple[str, List[dict]]:
    response = self.query_engine.query(question)
    
    # æå–ç­”æ¡ˆ
    answer = str(response)
    
    # æå–å¼•ç”¨æ¥æº
    sources = []
    if hasattr(response, 'source_nodes'):
        for i, node in enumerate(response.source_nodes, 1):
            source = {
                'index': i,                    # å¼•ç”¨ç¼–å·
                'text': node.node.text,        # åŸæ–‡
                'score': node.score,           # ç›¸ä¼¼åº¦åˆ†æ•°
                'metadata': node.node.metadata # å…ƒæ•°æ®ï¼ˆæ–‡ä»¶åç­‰ï¼‰
            }
            sources.append(source)
    
    return answer, sources
```

---

### 5. å¯¹è¯ç®¡ç†å™¨ï¼ˆsrc/chat_manager.pyï¼‰

**æ–‡ä»¶èŒè´£**ï¼šç®¡ç†å¤šè½®å¯¹è¯å’Œä¸Šä¸‹æ–‡

**æ•°æ®ç»“æ„è®¾è®¡**ï¼š

```python
@dataclass
class ChatTurn:
    """å•è½®å¯¹è¯"""
    question: str            # ç”¨æˆ·é—®é¢˜
    answer: str              # AI å›ç­”
    sources: List[dict]      # å¼•ç”¨æ¥æº
    timestamp: str           # æ—¶é—´æˆ³

class ChatSession:
    """å¯¹è¯ä¼šè¯"""
    session_id: str                  # ä¼šè¯ ID
    history: List[ChatTurn]          # å¯¹è¯å†å²
    created_at: str                  # åˆ›å»ºæ—¶é—´
    updated_at: str                  # æ›´æ–°æ—¶é—´
```

**ä¸ºä»€ä¹ˆåˆ†ç¦»æ•°æ®å’Œé€»è¾‘ï¼Ÿ**
- `ChatSession`ï¼šçº¯æ•°æ®ï¼Œæ˜“äºåºåˆ—åŒ–å’Œå­˜å‚¨
- `ChatManager`ï¼šä¸šåŠ¡é€»è¾‘ï¼Œå¤„ç†å¯¹è¯æµç¨‹

**CondensePlusContextChatEngine è¯¦è§£**ï¼š

```python
self.chat_engine = CondensePlusContextChatEngine.from_defaults(
    retriever=index.as_retriever(similarity_top_k=3),
    llm=self.llm,
    memory=self.memory,
    context_prompt="ä½ æ˜¯ç³»ç»Ÿç§‘å­¦ä¸“å®¶..."
)
```

**å†…éƒ¨å·¥ä½œæµç¨‹**ï¼š

```python
# å‡è®¾å¯¹è¯å†å²ï¼š
# User: ä»€ä¹ˆæ˜¯ç³»ç»Ÿç§‘å­¦ï¼Ÿ
# AI: ç³»ç»Ÿç§‘å­¦æ˜¯ç ”ç©¶ç³»ç»Ÿä¸€èˆ¬è§„å¾‹çš„å­¦ç§‘...

# å½“å‰é—®é¢˜ï¼š
user_message = "å®ƒæœ‰å“ªäº›åˆ†æ”¯ï¼Ÿ"

# æ­¥éª¤ 1ï¼šCondenseï¼ˆé—®é¢˜å‡ç»ƒï¼‰
# ç»“åˆå†å²ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆç‹¬ç«‹é—®é¢˜
condensed_question = condense_llm.complete(
    f"å†å²å¯¹è¯ï¼š{memory}\nå½“å‰é—®é¢˜ï¼š{user_message}\n\n"
    f"è¯·ç”Ÿæˆä¸€ä¸ªç‹¬ç«‹çš„ã€å®Œæ•´çš„é—®é¢˜ï¼š"
)
# è¾“å‡ºï¼š"ç³»ç»Ÿç§‘å­¦æœ‰å“ªäº›åˆ†æ”¯ï¼Ÿ"

# æ­¥éª¤ 2ï¼šæ£€ç´¢ç›¸å…³æ–‡æ¡£
retrieved_docs = retriever.retrieve(condensed_question)

# æ­¥éª¤ 3ï¼šç”Ÿæˆå›ç­”
answer = llm.complete(
    f"ä¸Šä¸‹æ–‡ï¼š{retrieved_docs}\n"
    f"å¯¹è¯å†å²ï¼š{memory}\n"
    f"é—®é¢˜ï¼š{user_message}\n"
    f"ç­”æ¡ˆï¼š"
)

# æ­¥éª¤ 4ï¼šæ›´æ–°è®°å¿†
memory.put(ChatMessage(role="user", content=user_message))
memory.put(ChatMessage(role="assistant", content=answer))
```

**ä¼šè¯æŒä¹…åŒ–å®ç°**ï¼š

```python
def save(self, save_dir: Path):
    # åºåˆ—åŒ–ä¸º JSON
    data = self.to_dict()  # è½¬æ¢ä¸ºå­—å…¸
    
    file_path = save_dir / f"{self.session_id}.json"
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    # ensure_ascii=False: ä¿æŒä¸­æ–‡å¯è¯»
    # indent=2: æ ¼å¼åŒ–è¾“å‡º

@classmethod
def load(cls, file_path: Path):
    # ä» JSON ååºåˆ—åŒ–
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    return cls.from_dict(data)
```

**ä¼šè¯æ¢å¤æ—¶è®°å¿†çš„é‡å»º**ï¼š

```python
def load_session(self, file_path: Path):
    # 1. åŠ è½½ä¼šè¯æ•°æ®
    self.current_session = ChatSession.load(file_path)
    
    # 2. é‡å»ºè®°å¿†
    self.memory.reset()
    for turn in self.current_session.history:
        self.memory.put(ChatMessage(role="user", content=turn.question))
        self.memory.put(ChatMessage(role="assistant", content=turn.answer))
    # ç°åœ¨ AI èƒ½"è®°èµ·"ä¹‹å‰çš„å¯¹è¯
```

---

## æ ¸å¿ƒAPIå‚è€ƒ

### ConfigManager API

```python
from src.config import config

# è®¿é—®é…ç½®
api_key = config.DEEPSEEK_API_KEY
vector_path = config.VECTOR_STORE_PATH

# éªŒè¯é…ç½®
is_valid, error = config.validate()

# ç¡®ä¿ç›®å½•å­˜åœ¨
config.ensure_directories()
```

### DataLoader API

```python
from src.data_loader import (
    MarkdownLoader,
    WebLoader,
    load_documents_from_directory,
    load_documents_from_urls
)

# æ–¹å¼ 1ï¼šä½¿ç”¨ Loader ç±»
loader = MarkdownLoader()
doc = loader.load_file(Path("document.md"))
docs = loader.load_directory(Path("./docs"), recursive=True)

# æ–¹å¼ 2ï¼šä½¿ç”¨ä¾¿æ·å‡½æ•°ï¼ˆæ¨èï¼‰
docs = load_documents_from_directory("./data/raw", recursive=True)
docs = load_documents_from_urls(["http://example.com/article"])
```

### IndexManager API

```python
from src.indexer import IndexManager

# åˆ›å»ºç´¢å¼•ç®¡ç†å™¨
index_manager = IndexManager(
    collection_name="my_docs",
    chunk_size=512,
    chunk_overlap=50
)

# æ„å»ºç´¢å¼•
index = index_manager.build_index(documents)

# è·å–ç´¢å¼•
index = index_manager.get_index()

# è·å–ç»Ÿè®¡
stats = index_manager.get_stats()

# æ¸…ç©ºç´¢å¼•
index_manager.clear_index()

# æµ‹è¯•æœç´¢
results = index_manager.search("æŸ¥è¯¢æ–‡æœ¬", top_k=5)
```

### QueryEngine API

```python
from src.query_engine import QueryEngine, SimpleQueryEngine

# åˆ›å»ºæŸ¥è¯¢å¼•æ“ï¼ˆå¸¦å¼•ç”¨ï¼‰
query_engine = QueryEngine(index_manager)

# æŸ¥è¯¢
answer, sources = query_engine.query("ä»€ä¹ˆæ˜¯ç³»ç»Ÿç§‘å­¦ï¼Ÿ")

# æ ¼å¼åŒ–è¾“å‡º
from src.query_engine import format_sources
print(answer)
print(format_sources(sources))

# ç®€å•æŸ¥è¯¢ï¼ˆæ— å¼•ç”¨ï¼‰
simple_engine = SimpleQueryEngine(index_manager)
answer = simple_engine.query("å¿«é€Ÿé—®é¢˜")
```

### ChatManager API

```python
from src.chat_manager import ChatManager

# åˆ›å»ºå¯¹è¯ç®¡ç†å™¨
chat_manager = ChatManager(index_manager)

# å¼€å§‹æ–°ä¼šè¯
session = chat_manager.start_session()

# å¯¹è¯
answer, sources = chat_manager.chat("ä»€ä¹ˆæ˜¯ç³»ç»Ÿç§‘å­¦ï¼Ÿ")
answer, sources = chat_manager.chat("å®ƒæœ‰å“ªäº›åº”ç”¨ï¼Ÿ")  # ç†è§£"å®ƒ"æŒ‡ç³»ç»Ÿç§‘å­¦

# è·å–å½“å‰ä¼šè¯
session = chat_manager.get_current_session()

# ä¿å­˜ä¼šè¯
chat_manager.save_current_session()

# åŠ è½½ä¼šè¯
chat_manager.load_session(Path("sessions/session_xxx.json"))

# é‡ç½®ä¼šè¯
chat_manager.reset_session()
```

---

## å¸¸è§å¼€å‘ä»»åŠ¡

### ä»»åŠ¡ 1ï¼šæ·»åŠ  PDF æ”¯æŒ

**æ­¥éª¤**ï¼š

1. å®‰è£…ä¾èµ–ï¼š
```bash
uv add pypdf
```

2. åˆ›å»º PDFLoaderï¼š
```python
# src/data_loader.py

from pypdf import PdfReader

class PDFLoader:
    def load_file(self, file_path: Path) -> Optional[LlamaDocument]:
        reader = PdfReader(file_path)
        
        text = ""
        for page in reader.pages:
            text += page.extract_text()
        
        return LlamaDocument(
            text=text,
            metadata={
                "file_path": str(file_path),
                "file_name": file_path.name,
                "source_type": "pdf",
                "page_count": len(reader.pages)
            }
        )
```

3. åœ¨ UI ä¸­æ·»åŠ æ”¯æŒï¼ˆapp.pyï¼‰ï¼š
```python
uploaded_files = st.file_uploader(
    "é€‰æ‹©æ–‡ä»¶",
    type=['md', 'markdown', 'pdf'],  # æ·»åŠ  pdf
    accept_multiple_files=True
)
```

### ä»»åŠ¡ 2ï¼šæ·»åŠ æ–‡æ¡£è¿‡æ»¤

```python
# src/indexer.py

class IndexManager:
    def search_by_metadata(
        self,
        query: str,
        filters: dict,
        top_k: int = 5
    ) -> List[dict]:
        """æŒ‰å…ƒæ•°æ®è¿‡æ»¤æœç´¢
        
        ç¤ºä¾‹ï¼š
        results = index_manager.search_by_metadata(
            query="ç³»ç»Ÿç§‘å­¦",
            filters={"source_type": "markdown", "title": "é’±å­¦æ£®"}
        )
        """
        retriever = self.index.as_retriever(
            similarity_top_k=top_k,
            filters=filters  # Chroma æ”¯æŒå…ƒæ•°æ®è¿‡æ»¤
        )
        nodes = retriever.retrieve(query)
        return [self._node_to_dict(node) for node in nodes]
```

### ä»»åŠ¡ 3ï¼šæ·»åŠ æŸ¥è¯¢æ—¥å¿—

```python
# æ–°å»º src/logger.py

import logging
from datetime import datetime

class QueryLogger:
    def __init__(self, log_file: str = "query_log.json"):
        self.log_file = log_file
    
    def log_query(self, question: str, answer: str, sources: List[dict]):
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "question": question,
            "answer": answer,
            "num_sources": len(sources),
            "source_files": [s['metadata'].get('file_name') for s in sources]
        }
        
        # è¿½åŠ åˆ°æ—¥å¿—æ–‡ä»¶
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')

# ä½¿ç”¨
# src/query_engine.py

from src.logger import QueryLogger

class QueryEngine:
    def __init__(self, ...):
        self.logger = QueryLogger()
    
    def query(self, question: str):
        answer, sources = ...  # åŸæœ‰é€»è¾‘
        
        # è®°å½•æ—¥å¿—
        self.logger.log_query(question, answer, sources)
        
        return answer, sources
```

### ä»»åŠ¡ 4ï¼šå®ç°æ–‡æ¡£æ›´æ–°æ£€æµ‹

```python
# src/indexer.py

import hashlib

class IndexManager:
    def get_document_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œ"""
        with open(file_path, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    
    def is_document_updated(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡æ¡£æ˜¯å¦æ›´æ–°"""
        current_hash = self.get_document_hash(file_path)
        
        # ä»å…ƒæ•°æ®ä¸­è·å–æ—§å“ˆå¸Œ
        # éœ€è¦åœ¨ç´¢å¼•æ—¶ä¿å­˜å“ˆå¸Œå€¼åˆ°å…ƒæ•°æ®
        
        return current_hash != stored_hash
    
    def incremental_update(self, directory: Path):
        """å¢é‡æ›´æ–°ï¼šåªé‡æ–°ç´¢å¼•ä¿®æ”¹è¿‡çš„æ–‡æ¡£"""
        for file in directory.glob("**/*.md"):
            if self.is_document_updated(file):
                # åˆ é™¤æ—§æ–‡æ¡£
                self.delete_document(str(file))
                
                # é‡æ–°ç´¢å¼•
                doc = load_document(file)
                doc.metadata['file_hash'] = self.get_document_hash(file)
                self.build_index([doc])
```

---

## è°ƒè¯•æŠ€å·§

### 1. æŸ¥çœ‹æ£€ç´¢åˆ°çš„æ–‡æ¡£

```python
# åœ¨ query_engine.py ä¸­æ·»åŠ è°ƒè¯•ä»£ç 

def query(self, question: str):
    response = self.query_engine.query(question)
    
    # è°ƒè¯•ï¼šæ‰“å°æ£€ç´¢åˆ°çš„æ–‡æ¡£
    print("\n=== æ£€ç´¢åˆ°çš„æ–‡æ¡£ ===")
    for i, node in enumerate(response.source_nodes, 1):
        print(f"\n[{i}] ç›¸ä¼¼åº¦: {node.score:.4f}")
        print(f"æ–‡ä»¶: {node.node.metadata.get('file_name')}")
        print(f"å†…å®¹: {node.node.text[:200]}...")
    
    return answer, sources
```

### 2. æµ‹è¯• Embedding è´¨é‡

```python
# æµ‹è¯•è„šæœ¬

from src.indexer import IndexManager

index_manager = IndexManager()

# æµ‹è¯•æŸ¥è¯¢
queries = [
    "ä»€ä¹ˆæ˜¯ç³»ç»Ÿç§‘å­¦ï¼Ÿ",
    "é’±å­¦æ£®çš„è´¡çŒ®",
    "ç³»ç»Ÿå·¥ç¨‹æ–¹æ³•"
]

for query in queries:
    print(f"\næŸ¥è¯¢: {query}")
    results = index_manager.search(query, top_k=3)
    for i, result in enumerate(results, 1):
        print(f"{i}. åˆ†æ•°: {result['score']:.4f}")
        print(f"   æ–‡ä»¶: {result['metadata']['file_name']}")
```

### 3. æ€§èƒ½åˆ†æ

```python
import time

def query_with_timing(self, question: str):
    start = time.time()
    
    # æ£€ç´¢é˜¶æ®µ
    retrieval_start = time.time()
    retrieved_nodes = self.index.retrieve(question)
    retrieval_time = time.time() - retrieval_start
    
    # ç”Ÿæˆé˜¶æ®µ
    generation_start = time.time()
    answer = self.llm.complete(...)
    generation_time = time.time() - generation_start
    
    total_time = time.time() - start
    
    print(f"æ£€ç´¢è€—æ—¶: {retrieval_time:.2f}s")
    print(f"ç”Ÿæˆè€—æ—¶: {generation_time:.2f}s")
    print(f"æ€»è€—æ—¶: {total_time:.2f}s")
    
    return answer
```

### 4. ä½¿ç”¨ LlamaIndex çš„è°ƒè¯•å·¥å…·

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging

logging.basicConfig(level=logging.DEBUG)
logging.getLogger("llama_index").setLevel(logging.DEBUG)

# ç°åœ¨ä¼šçœ‹åˆ°æ‰€æœ‰ LlamaIndex çš„å†…éƒ¨æ“ä½œ
```

---

## æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†

```python
# å¥½çš„åšæ³•
def load_file(self, file_path: Path) -> Optional[LlamaDocument]:
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return self._create_document(content, file_path)
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None
    except UnicodeDecodeError:
        print(f"âŒ æ–‡ä»¶ç¼–ç é”™è¯¯: {file_path}")
        return None
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {file_path} - {e}")
        return None
```

### 2. é…ç½®éªŒè¯

```python
# å¯åŠ¨æ—¶éªŒè¯é…ç½®
def main():
    is_valid, error = config.validate()
    if not is_valid:
        print(f"âŒ é…ç½®é”™è¯¯: {error}")
        sys.exit(1)
    
    # ç»§ç»­æ‰§è¡Œ...
```

### 3. èµ„æºæ¸…ç†

```python
# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
class IndexManager:
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        # æ¸…ç†èµ„æº
        if self.chroma_client:
            # Chroma ä¼šè‡ªåŠ¨å¤„ç†
            pass

# ä½¿ç”¨
with IndexManager() as index_manager:
    index_manager.build_index(documents)
# è‡ªåŠ¨æ¸…ç†
```

### 4. å•å…ƒæµ‹è¯•

```python
# tests/test_data_loader.py

import pytest
from src.data_loader import MarkdownLoader

def test_markdown_loader():
    loader = MarkdownLoader()
    
    # æµ‹è¯•æ–‡ä»¶åŠ è½½
    doc = loader.load_file(Path("test.md"))
    assert doc is not None
    assert doc.metadata['source_type'] == 'markdown'
    
    # æµ‹è¯•æ ‡é¢˜æå–
    assert doc.metadata['title'] == 'æµ‹è¯•æ ‡é¢˜'
```

### 5. ä»£ç ç»„ç»‡

```python
# å¥½çš„åšæ³•ï¼šå°†å¤æ‚é€»è¾‘åˆ†è§£ä¸ºå°å‡½æ•°

class QueryEngine:
    def query(self, question: str):
        # ä¸»æµç¨‹æ¸…æ™°
        retrieved_docs = self._retrieve_documents(question)
        context = self._build_context(retrieved_docs)
        answer = self._generate_answer(question, context)
        sources = self._extract_sources(retrieved_docs)
        return answer, sources
    
    def _retrieve_documents(self, question: str):
        # ä¸“æ³¨äºæ£€ç´¢é€»è¾‘
        ...
    
    def _build_context(self, docs):
        # ä¸“æ³¨äºä¸Šä¸‹æ–‡æ„å»º
        ...
```

---

## å¸¸è§é—®é¢˜

### Q1ï¼šå¦‚ä½•å¤„ç†ä¸­æ–‡åˆ†è¯ï¼Ÿ

**A**ï¼šbge-base-zh-v1.5 æ¨¡å‹å†…ç½®äº†ä¸­æ–‡åˆ†è¯ï¼Œæ— éœ€é¢å¤–å¤„ç†ã€‚

### Q2ï¼šå¦‚ä½•ä¼˜åŒ–æ£€ç´¢ç²¾åº¦ï¼Ÿ

**A**ï¼š
1. è°ƒæ•´ `chunk_size`ï¼ˆæ›´å°çš„å—æ›´ç²¾ç¡®ï¼Œä½†ä¸Šä¸‹æ–‡å°‘ï¼‰
2. å¢åŠ  `similarity_top_k`ï¼ˆæ£€ç´¢æ›´å¤šæ–‡æ¡£ï¼‰
3. ä½¿ç”¨æ›´å¥½çš„ embedding æ¨¡å‹
4. å®ç°æ··åˆæ£€ç´¢ï¼ˆå‘é‡ + å…³é”®è¯ï¼‰

### Q3ï¼šå¦‚ä½•å¤„ç†è¶…é•¿æ–‡æ¡£ï¼Ÿ

**A**ï¼š
```python
# æ–¹æ³• 1ï¼šå¢å¤§ chunk_size
Settings.chunk_size = 1024

# æ–¹æ³• 2ï¼šä½¿ç”¨å±‚æ¬¡åŒ–ç´¢å¼•
# å…ˆç´¢å¼•æ‘˜è¦ï¼Œå†ç´¢å¼•è¯¦ç»†å†…å®¹

# æ–¹æ³• 3ï¼šä½¿ç”¨ LlamaIndex çš„ HierarchicalNodeParser
from llama_index.core.node_parser import HierarchicalNodeParser
```

### Q4ï¼šå¦‚ä½•å®ç°å¤šè¯­è¨€æ”¯æŒï¼Ÿ

**A**ï¼š
```python
# ä½¿ç”¨å¤šè¯­è¨€ embedding æ¨¡å‹
self.embed_model = HuggingFaceEmbedding(
    model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
)
```

---

## æ€»ç»“

æœ¬å¼€å‘è€…æŒ‡å—æ¶µç›–äº†ï¼š
- âœ… è¯¦ç»†çš„ä»£ç è§£æ
- âœ… æ ¸å¿ƒ API ä½¿ç”¨æ–¹æ³•
- âœ… å¸¸è§å¼€å‘ä»»åŠ¡ç¤ºä¾‹
- âœ… è°ƒè¯•æŠ€å·§
- âœ… æœ€ä½³å®è·µ

**ä¸‹ä¸€æ­¥å»ºè®®**ï¼š
1. é˜…è¯» [æ¶æ„è®¾è®¡æ–‡æ¡£](ARCHITECTURE.md) äº†è§£æ•´ä½“æ¶æ„
2. è¿è¡Œç¤ºä¾‹ä»£ç ï¼Œç†è§£å·¥ä½œæµç¨‹
3. å°è¯•å®ç°ä¸€ä¸ªå°åŠŸèƒ½
4. æŸ¥çœ‹ LlamaIndex å®˜æ–¹æ–‡æ¡£æ·±å…¥å­¦ä¹ 

## ç›¸å…³æ–‡æ¡£

- [æ¶æ„è®¾è®¡](ARCHITECTURE.md) - ç³»ç»Ÿæ¶æ„å’Œè®¾è®¡æ€è·¯
- [APIå‚è€ƒ](API.md) - å®Œæ•´çš„APIæ¥å£æ–‡æ¡£
- [æŠ€æœ¯å†³ç­–](DECISIONS.md) - æŠ€æœ¯é€‰å‹çš„åŸå› 
- [å¼€å‘æ—¥å¿—](CHANGELOG.md) - é¡¹ç›®è¿›å±•è®°å½•

ç¥å¼€å‘é¡ºåˆ©ï¼ğŸš€

