"""
æŸ¥è¯¢å¼•æ“æ¨¡å—
é›†æˆDeepSeek APIï¼Œå®ç°å¸¦å¼•ç”¨æº¯æºçš„æŸ¥è¯¢åŠŸèƒ½
"""

from typing import List, Optional, Tuple
from llama_index.core import VectorStoreIndex
from llama_index.core.query_engine import CitationQueryEngine
from llama_index.core.schema import Response
from llama_index.llms.openai import OpenAI

from src.config import config
from src.indexer import IndexManager


class QueryEngine:
    """æŸ¥è¯¢å¼•æ“"""
    
    def __init__(
        self,
        index_manager: IndexManager,
        api_key: Optional[str] = None,
        api_base: Optional[str] = None,
        model: Optional[str] = None,
        similarity_top_k: Optional[int] = None,
        citation_chunk_size: int = 512,
    ):
        """åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“
        
        Args:
            index_manager: ç´¢å¼•ç®¡ç†å™¨
            api_key: DeepSeek APIå¯†é’¥
            api_base: APIç«¯ç‚¹
            model: æ¨¡å‹åç§°
            similarity_top_k: æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£æ•°é‡
            citation_chunk_size: å¼•ç”¨å—å¤§å°
        """
        self.index_manager = index_manager
        self.similarity_top_k = similarity_top_k or config.SIMILARITY_TOP_K
        self.citation_chunk_size = citation_chunk_size
        
        # é…ç½®DeepSeek LLM
        self.api_key = api_key or config.DEEPSEEK_API_KEY
        self.api_base = api_base or config.DEEPSEEK_API_BASE
        self.model = model or config.LLM_MODEL
        
        if not self.api_key:
            raise ValueError("æœªè®¾ç½®DEEPSEEK_API_KEYï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶")
        
        print(f"ğŸ¤– åˆå§‹åŒ–DeepSeek LLM: {self.model}")
        self.llm = OpenAI(
            api_key=self.api_key,
            api_base=self.api_base,
            model=self.model,
            temperature=0.1,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„å›ç­”
        )
        
        # è·å–ç´¢å¼•
        self.index = self.index_manager.get_index()
        
        # åˆ›å»ºå¸¦å¼•ç”¨çš„æŸ¥è¯¢å¼•æ“
        print("ğŸ“ åˆ›å»ºå¼•ç”¨æŸ¥è¯¢å¼•æ“")
        self.query_engine = CitationQueryEngine.from_args(
            self.index,
            llm=self.llm,
            similarity_top_k=self.similarity_top_k,
            citation_chunk_size=self.citation_chunk_size,
        )
        
        print("âœ… æŸ¥è¯¢å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def query(self, question: str) -> Tuple[str, List[dict]]:
        """æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›å¸¦å¼•ç”¨çš„ç­”æ¡ˆ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            (ç­”æ¡ˆæ–‡æœ¬, å¼•ç”¨æ¥æºåˆ—è¡¨)
        """
        try:
            print(f"\nğŸ’¬ æŸ¥è¯¢: {question}")
            
            # æ‰§è¡ŒæŸ¥è¯¢
            response: Response = self.query_engine.query(question)
            
            # æå–ç­”æ¡ˆ
            answer = str(response)
            
            # æå–å¼•ç”¨æ¥æº
            sources = []
            if hasattr(response, 'source_nodes') and response.source_nodes:
                for i, node in enumerate(response.source_nodes, 1):
                    source = {
                        'index': i,
                        'text': node.node.text,
                        'score': node.score if hasattr(node, 'score') else None,
                        'metadata': node.node.metadata,
                    }
                    sources.append(source)
            
            print(f"âœ… æŸ¥è¯¢å®Œæˆï¼Œæ‰¾åˆ° {len(sources)} ä¸ªå¼•ç”¨æ¥æº")
            
            return answer, sources
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            raise
    
    def get_retriever(self):
        """è·å–æ£€ç´¢å™¨ï¼ˆç”¨äºé«˜çº§ç”¨æ³•ï¼‰"""
        return self.index.as_retriever(similarity_top_k=self.similarity_top_k)


class SimpleQueryEngine:
    """ç®€å•æŸ¥è¯¢å¼•æ“ï¼ˆä¸å¸¦å¼•ç”¨æº¯æºï¼Œç”¨äºå¿«é€ŸæŸ¥è¯¢ï¼‰"""
    
    def __init__(
        self,
        index_manager: IndexManager,
        api_key: Optional[str] = None,
        api_base: Optional[str] = None,
        model: Optional[str] = None,
        similarity_top_k: Optional[int] = None,
    ):
        """åˆå§‹åŒ–ç®€å•æŸ¥è¯¢å¼•æ“
        
        Args:
            index_manager: ç´¢å¼•ç®¡ç†å™¨
            api_key: DeepSeek APIå¯†é’¥
            api_base: APIç«¯ç‚¹
            model: æ¨¡å‹åç§°
            similarity_top_k: æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£æ•°é‡
        """
        self.index_manager = index_manager
        self.similarity_top_k = similarity_top_k or config.SIMILARITY_TOP_K
        
        # é…ç½®DeepSeek LLM
        self.api_key = api_key or config.DEEPSEEK_API_KEY
        self.api_base = api_base or config.DEEPSEEK_API_BASE
        self.model = model or config.LLM_MODEL
        
        if not self.api_key:
            raise ValueError("æœªè®¾ç½®DEEPSEEK_API_KEY")
        
        self.llm = OpenAI(
            api_key=self.api_key,
            api_base=self.api_base,
            model=self.model,
            temperature=0.1,
        )
        
        # è·å–ç´¢å¼•
        self.index = self.index_manager.get_index()
        
        # åˆ›å»ºæ ‡å‡†æŸ¥è¯¢å¼•æ“
        self.query_engine = self.index.as_query_engine(
            llm=self.llm,
            similarity_top_k=self.similarity_top_k,
        )
    
    def query(self, question: str) -> str:
        """æ‰§è¡Œç®€å•æŸ¥è¯¢
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            ç­”æ¡ˆæ–‡æœ¬
        """
        try:
            response = self.query_engine.query(question)
            return str(response)
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            raise


def format_sources(sources: List[dict]) -> str:
    """æ ¼å¼åŒ–å¼•ç”¨æ¥æºä¸ºå¯è¯»æ–‡æœ¬
    
    Args:
        sources: å¼•ç”¨æ¥æºåˆ—è¡¨
        
    Returns:
        æ ¼å¼åŒ–çš„æ–‡æœ¬
    """
    if not sources:
        return "ï¼ˆæ— å¼•ç”¨æ¥æºï¼‰"
    
    formatted = "\n\nğŸ“š å¼•ç”¨æ¥æºï¼š\n"
    for source in sources:
        formatted += f"\n[{source['index']}] "
        
        # æ·»åŠ æ–‡æ¡£ä¿¡æ¯
        metadata = source['metadata']
        if 'title' in metadata:
            formatted += f"{metadata['title']}"
        elif 'file_name' in metadata:
            formatted += f"{metadata['file_name']}"
        elif 'url' in metadata:
            formatted += f"{metadata['url']}"
        
        # æ·»åŠ ç›¸ä¼¼åº¦åˆ†æ•°
        if source['score'] is not None:
            formatted += f" (ç›¸ä¼¼åº¦: {source['score']:.2f})"
        
        formatted += f"\n   {source['text'][:200]}..."
        
        if len(source['text']) > 200:
            formatted += f"\n   ï¼ˆå…±{len(source['text'])}å­—ï¼‰"
    
    return formatted


def create_query_engine(
    index_manager: IndexManager,
    with_citation: bool = True
) -> QueryEngine | SimpleQueryEngine:
    """åˆ›å»ºæŸ¥è¯¢å¼•æ“ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Args:
        index_manager: ç´¢å¼•ç®¡ç†å™¨
        with_citation: æ˜¯å¦ä½¿ç”¨å¼•ç”¨æº¯æº
        
    Returns:
        QueryEngineæˆ–SimpleQueryEngineå¯¹è±¡
    """
    if with_citation:
        return QueryEngine(index_manager)
    else:
        return SimpleQueryEngine(index_manager)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    from llama_index.core import Document as LlamaDocument
    
    print("=== æµ‹è¯•æŸ¥è¯¢å¼•æ“ ===\n")
    
    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
    test_docs = [
        LlamaDocument(
            text="""ç³»ç»Ÿç§‘å­¦æ˜¯20ä¸–çºªä¸­æœŸå…´èµ·çš„ä¸€é—¨æ–°å…´å­¦ç§‘ï¼Œå®ƒç ”ç©¶ç³»ç»Ÿçš„ä¸€èˆ¬è§„å¾‹å’Œæ–¹æ³•ã€‚
            ç³»ç»Ÿç§‘å­¦åŒ…æ‹¬ç³»ç»Ÿè®ºã€æ§åˆ¶è®ºã€ä¿¡æ¯è®ºç­‰å¤šä¸ªåˆ†æ”¯ã€‚""",
            metadata={"title": "ç³»ç»Ÿç§‘å­¦æ¦‚è¿°", "source": "test"}
        ),
        LlamaDocument(
            text="""é’±å­¦æ£®ï¼ˆ1911-2009ï¼‰æ˜¯ä¸­å›½è‘—åç§‘å­¦å®¶ï¼Œè¢«èª‰ä¸º"ä¸­å›½èˆªå¤©ä¹‹çˆ¶"ã€‚
            ä»–åœ¨ç³»ç»Ÿå·¥ç¨‹å’Œç³»ç»Ÿç§‘å­¦é¢†åŸŸåšå‡ºäº†æ°å‡ºè´¡çŒ®ï¼Œæå‡ºäº†å¼€æ”¾çš„å¤æ‚å·¨ç³»ç»Ÿç†è®ºã€‚""",
            metadata={"title": "é’±å­¦æ£®ç”Ÿå¹³", "source": "test"}
        ),
        LlamaDocument(
            text="""ç³»ç»Ÿå·¥ç¨‹æ˜¯ä¸€ç§ç»„ç»‡ç®¡ç†æŠ€æœ¯ï¼Œç”¨äºè§£å†³å¤§è§„æ¨¡å¤æ‚ç³»ç»Ÿçš„è®¾è®¡å’Œå®æ–½é—®é¢˜ã€‚
            é’±å­¦æ£®å°†ç³»ç»Ÿå·¥ç¨‹å¼•å…¥ä¸­å›½ï¼Œå¹¶ç»“åˆä¸­å›½å®é™…è¿›è¡Œäº†åˆ›æ–°æ€§å‘å±•ã€‚""",
            metadata={"title": "ç³»ç»Ÿå·¥ç¨‹ç®€ä»‹", "source": "test"}
        ),
    ]
    
    # åˆ›å»ºç´¢å¼•
    index_manager = IndexManager(collection_name="test_query")
    index_manager.build_index(test_docs)
    
    # åˆ›å»ºæŸ¥è¯¢å¼•æ“
    query_engine = QueryEngine(index_manager)
    
    # æµ‹è¯•æŸ¥è¯¢
    question = "é’±å­¦æ£®åœ¨ç³»ç»Ÿç§‘å­¦é¢†åŸŸæœ‰ä»€ä¹ˆè´¡çŒ®ï¼Ÿ"
    answer, sources = query_engine.query(question)
    
    print(f"\né—®é¢˜: {question}")
    print(f"\nç­”æ¡ˆ:\n{answer}")
    print(format_sources(sources))
    
    # æ¸…ç†
    index_manager.clear_index()
    print("\nâœ… æµ‹è¯•å®Œæˆ")

