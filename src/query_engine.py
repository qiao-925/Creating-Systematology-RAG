"""
æŸ¥è¯¢å¼•æ“æ¨¡å—
é›†æˆDeepSeek APIï¼Œå®ç°å¸¦å¼•ç”¨æº¯æºçš„æŸ¥è¯¢åŠŸèƒ½
æ”¯æŒPhoenixå¯è§‚æµ‹æ€§å’ŒLlamaDebugHandlerè°ƒè¯•
"""

import time
from typing import List, Optional, Tuple, Dict, Any
from llama_index.core import VectorStoreIndex, Settings
from llama_index.core.query_engine import CitationQueryEngine
from llama_index.core.base.response.schema import Response
from llama_index.core.schema import Document as LlamaDocument
from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler
from llama_index.llms.deepseek import DeepSeek

from src.config import config, get_gpu_device, is_gpu_available
from src.indexer import IndexManager
from src.logger import setup_logger

logger = setup_logger('query_engine')


class QueryEngine:
    """æŸ¥è¯¢å¼•æ“"""
    
    def __init__(
        self,
        index_manager: IndexManager,
        api_key: Optional[str] = None,
        api_base: Optional[str] = None,
        model: Optional[str] = None,
        similarity_top_k: Optional[int] = None,
        citation_chunk_size: int = 512,
        enable_debug: bool = False,
        similarity_threshold: Optional[float] = None,
    ):
        """åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“
        
        Args:
            index_manager: ç´¢å¼•ç®¡ç†å™¨
            api_key: DeepSeek APIå¯†é’¥
            api_base: APIç«¯ç‚¹
            model: æ¨¡å‹åç§°
            similarity_top_k: æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£æ•°é‡
            citation_chunk_size: å¼•ç”¨å—å¤§å°
            enable_debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆLlamaDebugHandlerï¼‰
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼å¯ç”¨æ¨ç†æ¨¡å¼
        """
        self.index_manager = index_manager
        self.similarity_top_k = similarity_top_k or config.SIMILARITY_TOP_K
        self.citation_chunk_size = citation_chunk_size
        self.enable_debug = enable_debug
        self.similarity_threshold = similarity_threshold or config.SIMILARITY_THRESHOLD
        
        # é…ç½®DeepSeek LLM
        self.api_key = api_key or config.DEEPSEEK_API_KEY
        self.model = model or config.LLM_MODEL
        
        if not self.api_key:
            raise ValueError("æœªè®¾ç½®DEEPSEEK_API_KEYï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶")
        
        # é…ç½®è°ƒè¯•æ¨¡å¼
        if self.enable_debug:
            print("ğŸ” å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆLlamaDebugHandlerï¼‰")
            self.llama_debug = LlamaDebugHandler(print_trace_on_end=True)
            Settings.callback_manager = CallbackManager([self.llama_debug])
            logger.info("è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")
        
        print(f"ğŸ¤– åˆå§‹åŒ–DeepSeek LLM: {self.model}")
        # ä½¿ç”¨å®˜æ–¹ DeepSeek é›†æˆ
        self.llm = DeepSeek(
            api_key=self.api_key,
            model=self.model,
            temperature=0.5,  # æé«˜æ¸©åº¦ä»¥å¢å¼ºæ¨ç†èƒ½åŠ›
            max_tokens=4096,
        )
        
        # è·å–ç´¢å¼•
        self.index = self.index_manager.get_index()
        
        # åˆ›å»ºå¸¦å¼•ç”¨çš„æŸ¥è¯¢å¼•æ“
        print("ğŸ“ åˆ›å»ºå¼•ç”¨æŸ¥è¯¢å¼•æ“")
        self.query_engine = CitationQueryEngine.from_args(
            self.index,
            llm=self.llm,
            similarity_top_k=self.similarity_top_k,
            citation_chunk_size=self.citation_chunk_size,
        )
        
        print("âœ… æŸ¥è¯¢å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def query(self, question: str, collect_trace: bool = False) -> Tuple[str, List[dict], Optional[Dict[str, Any]]]:
        """æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›å¸¦å¼•ç”¨çš„ç­”æ¡ˆ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            collect_trace: æ˜¯å¦æ”¶é›†è¯¦ç»†çš„è¿½è¸ªä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•æ¨¡å¼ï¼‰
            
        Returns:
            (ç­”æ¡ˆæ–‡æœ¬, å¼•ç”¨æ¥æºåˆ—è¡¨, è¿½è¸ªä¿¡æ¯å­—å…¸)
            
        Note:
            è¿½è¸ªä¿¡æ¯åŒ…å«ï¼šæ£€ç´¢æ—¶é—´ã€æ£€ç´¢åˆ°çš„chunkã€ç›¸ä¼¼åº¦åˆ†æ•°ã€LLMè°ƒç”¨æ—¶é—´ç­‰
        """
        trace_info = None
        
        try:
            # è·å–å½“å‰è®¾å¤‡ä¿¡æ¯
            device = get_gpu_device()
            device_mode = "GPUåŠ é€Ÿ" if device.startswith("cuda") else "CPUæ¨¡å¼"
            
            print(f"\nğŸ’¬ æŸ¥è¯¢: {question}")
            logger.debug(f"æŸ¥è¯¢è®¾å¤‡: {device} ({device_mode})")
            
            if collect_trace:
                trace_info = {
                    "query": question,
                    "start_time": time.time(),
                    "retrieval": {},
                    "llm_generation": {}
                }
            
            # ===== 1. æ‰§è¡Œæ£€ç´¢ =====
            retrieval_start = time.time()
            
            # è·å– Collection ç»Ÿè®¡ä¿¡æ¯
            stats = self.index_manager.get_stats()
            collection_total_docs = stats.get('document_count', 0)
            collection_name = stats.get('collection_name', 'unknown')
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
            if 'error' in stats:
                error_info = stats.get('error', 'æœªçŸ¥é”™è¯¯')
                logger.warning(f"âš ï¸  è·å–Collectionç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºç°é—®é¢˜: {error_info}")
                print(f"âš ï¸  è·å–Collectionç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºç°é—®é¢˜: {error_info}")
                print(f"   è¿™å¯èƒ½æ˜¯å› ä¸ºcollectionæœªæ­£ç¡®åˆå§‹åŒ–æˆ–è®¿é—®å¤±è´¥")
            
            logger.info(f"ğŸ“Š Collection ä¿¡æ¯: {collection_name}, æ€»æ–‡æ¡£æ•°: {collection_total_docs}")
            print(f"ğŸ“Š Collection: {collection_name}, æ€»æ–‡æ¡£æ•°: {collection_total_docs}")
            
            # å¦‚æœæ–‡æ¡£æ•°ä¸º0ï¼Œè¾“å‡ºè­¦å‘Š
            if collection_total_docs == 0:
                logger.warning(f"âš ï¸  Collection '{collection_name}' çš„æ–‡æ¡£æ•°ä¸º0ï¼Œå¯èƒ½æ˜¯ç©ºcollectionæˆ–åˆå§‹åŒ–é—®é¢˜")
                print(f"âš ï¸  æ³¨æ„: Collection '{collection_name}' çš„æ–‡æ¡£æ•°ä¸º0")
                print(f"   å¦‚æœè¿™ä¸ç¬¦åˆé¢„æœŸï¼Œè¯·æ£€æŸ¥:")
                print(f"   1. ç´¢å¼•æ˜¯å¦å·²æ­£ç¡®æ„å»º")
                print(f"   2. Collectionåç§°æ˜¯å¦æ­£ç¡®")
                print(f"   3. å‘é‡å­˜å‚¨è·¯å¾„æ˜¯å¦æ­£ç¡®")
            
            # æ‰§è¡ŒæŸ¥è¯¢
            response: Response = self.query_engine.query(question)
            
            retrieval_time = time.time() - retrieval_start
            
            # æå–ç­”æ¡ˆ
            answer = str(response)
            
            # æå–å¼•ç”¨æ¥æº
            sources = []
            if hasattr(response, 'source_nodes') and response.source_nodes:
                logger.info(f"ğŸ” æ£€ç´¢åˆ° {len(response.source_nodes)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
                print(f"ğŸ” æ£€ç´¢åˆ° {len(response.source_nodes)} ä¸ªæ–‡æ¡£ç‰‡æ®µ:")
                
                for i, node in enumerate(response.source_nodes, 1):
                    # æå–å…ƒæ•°æ®ä¸­çš„æ–‡æ¡£ä¿¡æ¯
                    try:
                        metadata = node.node.metadata if hasattr(node, 'node') and hasattr(node.node, 'metadata') else {}
                        if not isinstance(metadata, dict):
                            metadata = {}
                    except Exception:
                        metadata = {}
                    
                    # å°è¯•å¤šç§æ–¹å¼è·å–æ–‡ä»¶è·¯å¾„
                    file_path = (
                        metadata.get('file_path') or 
                        metadata.get('file_name') or 
                        metadata.get('source') or 
                        metadata.get('url') or 
                        'æœªçŸ¥æ¥æº'
                    )
                    file_name = file_path.split('/')[-1] if '/' in file_path else file_path.split('\\')[-1]
                    page_label = metadata.get('page_label', metadata.get('page', ''))
                    doc_id = metadata.get('doc_id', metadata.get('document_id', metadata.get('id', '')))
                    
                    score = node.score if hasattr(node, 'score') else None
                    node_text = node.node.text if hasattr(node, 'node') and hasattr(node.node, 'text') else ''
                    text_preview = node_text[:200] + '...' if len(node_text) > 200 else node_text
                    
                    source = {
                        'index': i,
                        'text': node_text,
                        'score': score,
                        'metadata': metadata,
                    }
                    sources.append(source)
                    
                    # è¯¦ç»†æ—¥å¿—è¾“å‡º
                    score_str = f"{score:.4f}" if score is not None else "N/A"
                    logger.info(
                        f"  [{i}] æ–‡æ¡£ç‰‡æ®µ #{i}:\n"
                        f"    - æ–‡ä»¶å: {file_name}\n"
                        f"    - æ–‡ä»¶è·¯å¾„: {file_path}\n"
                        f"    - ç›¸ä¼¼åº¦åˆ†æ•°: {score_str}\n"
                        f"    - æ–‡æ¡£ID: {doc_id}\n"
                        f"    - é¡µç : {page_label}\n"
                        f"    - å†…å®¹é¢„è§ˆ: {text_preview}\n"
                        f"    - å®Œæ•´å…ƒæ•°æ®: {metadata}"
                    )
                    print(f"  [{i}] {file_name} (åˆ†æ•°: {score_str})")
                    if score is not None:
                        print(f"      è·¯å¾„: {file_path}")
                        print(f"      å†…å®¹: {text_preview}")
                
                # æ±‡æ€»ä¿¡æ¯
                logger.info(
                    f"ğŸ“‹ æ£€ç´¢ç»“æœæ±‡æ€»:\n"
                    f"  - Collection: {collection_name}\n"
                    f"  - Collection æ€»æ–‡æ¡£æ•°: {collection_total_docs}\n"
                    f"  - æ£€ç´¢åˆ°çš„ç‰‡æ®µæ•°: {len(sources)}\n"
                    f"  - æœ‰åˆ†æ•°çš„ç‰‡æ®µæ•°: {len([s for s in sources if s.get('score') is not None])}\n"
                    f"  - æ— åˆ†æ•°çš„ç‰‡æ®µæ•°: {len([s for s in sources if s.get('score') is None])}"
                )
            
            # ===== è¿‡æ»¤ä½è´¨é‡ç»“æœå¹¶è¯„ä¼°æ£€ç´¢è´¨é‡ =====
            numeric_scores = [s.get('score') for s in sources if s.get('score') is not None]
            max_score = max(numeric_scores) if numeric_scores else None
            high_quality_sources = [
                s for s in sources
                if (s.get('score') is not None) and (s.get('score') >= self.similarity_threshold)
            ]
            
            # ä»…å½“å­˜åœ¨æ•°å€¼åˆ†æ•°æ—¶ï¼Œæ‰åŸºäºé˜ˆå€¼è¿›è¡Œè´¨é‡åˆ¤æ–­
            if max_score is not None:
                if len(high_quality_sources) < len(sources):
                    logger.info(
                        f"è¿‡æ»¤äº† {len(sources) - len(high_quality_sources)} ä¸ªä½è´¨é‡ç»“æœï¼ˆé˜ˆå€¼: {self.similarity_threshold}ï¼‰"
                    )
                if max_score < self.similarity_threshold:
                    print(
                        f"âš ï¸  æ£€ç´¢è´¨é‡è¾ƒä½ï¼ˆæœ€é«˜ç›¸ä¼¼åº¦: {max_score:.2f}ï¼‰ï¼Œç­”æ¡ˆå¯èƒ½æ›´å¤šä¾èµ–æ¨¡å‹æ¨ç†"
                    )
                    logger.warning(
                        f"æ£€ç´¢è´¨é‡è¾ƒä½ï¼Œæœ€é«˜ç›¸ä¼¼åº¦: {max_score:.2f}ï¼Œé˜ˆå€¼: {self.similarity_threshold}"
                    )
                elif len(high_quality_sources) >= 2:
                    print(
                        f"âœ… æ£€ç´¢è´¨é‡è‰¯å¥½ï¼ˆé«˜è´¨é‡ç»“æœ: {len(high_quality_sources)}ä¸ªï¼Œæœ€é«˜ç›¸ä¼¼åº¦: {max_score:.2f}ï¼‰"
                    )
            else:
                # åˆ†æ•°ç¼ºå¤±ï¼ˆä¾‹å¦‚ CitationQueryEngine æœªè¿”å› scoreï¼‰ï¼Œæ‰“å°æç¤ºä½†ä¸åˆ¤å®šä¸ºä½ç›¸å…³
                logger.info(
                    "æ£€ç´¢è¯„åˆ†ç¼ºå¤±ï¼šæ‰€æœ‰æ¥æºçš„scoreä¸ºNoneï¼ˆchunks=%sï¼‰ï¼Œè·³è¿‡ä½ç›¸å…³åˆ¤å®šï¼Œä»…ä¾æ®å…¶ä»–æ¡ä»¶å…œåº•",
                    len(sources),
                )
            
            # ===== å…œåº•ç­–ç•¥ï¼ˆæ–¹æ¡ˆAï¼‰ï¼šè¾“å‡ºå®ˆæŠ¤ + çº¯LLMå®šä¹‰ç±»å›ç­” =====
            # è®¡ç®—æ›´å¤šç»Ÿè®¡ä¿¡æ¯ï¼Œä¾¿äºæ—¥å¿—è§‚æµ‹
            scores_list = [s['score'] for s in sources if s.get('score') is not None]
            avg_score = sum(scores_list) / len(scores_list) if scores_list else 0.0
            min_score = min(scores_list) if scores_list else 0.0
            max_score_logged = (max(scores_list) if scores_list else None)
            scores_none_count = len(sources) - len(scores_list)
            
            logger.debug(
                "æ£€ç´¢ç»Ÿè®¡: top_k=%s, chunks=%s, numeric=%s, none=%s, min=%s, avg=%s, max=%s, threshold=%.3f",
                self.similarity_top_k,
                len(sources),
                len(scores_list),
                scores_none_count,
                (f"{min_score:.3f}" if scores_list else "-"),
                (f"{avg_score:.3f}" if scores_list else "-"),
                (f"{max_score_logged:.3f}" if scores_list else "-"),
                self.similarity_threshold,
            )
            
            # åˆ¤å®šæ˜¯å¦éœ€è¦å…œåº•
            fallback_reason = None
            if not sources:
                fallback_reason = "no_sources"
            elif (max_score_logged is not None) and (max_score_logged < self.similarity_threshold):
                fallback_reason = f"low_similarity({max_score_logged:.2f}<{self.similarity_threshold})"
            elif not answer or not answer.strip():
                fallback_reason = "empty_answer"
            
            if fallback_reason:
                print(f"ğŸ›Ÿ  è§¦å‘å…œåº•ç”Ÿæˆï¼ˆåŸå› : {fallback_reason}ï¼‰")
                logger.info(
                    "è§¦å‘å…œåº•ç”Ÿæˆ: reason=%s, chunks=%s, min=%.3f, avg=%.3f, max=%.3f, threshold=%.3f",
                    fallback_reason,
                    len(sources),
                    min_score,
                    avg_score,
                    max_score_logged if max_score_logged is not None else 0.0,
                    self.similarity_threshold,
                )
                
                # çº¯LLMå®šä¹‰ç±»å›ç­”æç¤ºè¯ï¼ˆä¸­æ–‡è¾“å‡ºï¼Œé€‚é…å­¦ä¹ ç”¨é€”ï¼Œæ˜ç¡®è¯´æ˜ä¸ºé€šç”¨æ¨ç†ï¼‰
                fallback_prompt = (
                    "ä½ æ˜¯ä¸€ä½ç³»ç»Ÿç§‘å­¦é¢†åŸŸçš„èµ„æ·±ä¸“å®¶ã€‚å½“å‰æœªæ£€ç´¢åˆ°è¶³å¤Ÿé«˜ç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹ï¼Œ"
                    "è¯·åŸºäºé€šç”¨å­¦æœ¯çŸ¥è¯†ä¸å¸¸è§æ•™æï¼Œå›ç­”ç”¨æˆ·é—®é¢˜ï¼Œç»™å‡ºæ¸…æ™°ã€ç»“æ„åŒ–ã€å¯è‡ªæ´½çš„è§£é‡Šã€‚\n\n"
                    "è¦æ±‚ï¼š\n"
                    "1) å…ˆç»™å‡ºç®€æ˜å®šä¹‰/æ ¸å¿ƒæ€æƒ³ï¼Œå†ç»™å‡ºå…³é”®è¦ç‚¹æ¡ç›®ï¼›\n"
                    "2) ä¿æŒä¸¥è°¨ã€ä¸­ç«‹ï¼Œä¸æé€ å…·ä½“å¼•ç”¨ï¼›\n"
                    "3) å¿…é¡»ç”¨ä¸­æ–‡å›ç­”ï¼›\n"
                    "4) æœ«å°¾å¢åŠ ä¸€è¡Œæç¤ºï¼šâ€˜æ³¨ï¼šæœªæ£€ç´¢åˆ°è¶³å¤Ÿé«˜ç›¸å…³èµ„æ–™ï¼Œæœ¬å›ç­”åŸºäºé€šç”¨çŸ¥è¯†æ¨ç†ï¼Œå¯èƒ½ä¸å«å¼•ç”¨ã€‚â€™\n\n"
                    f"ç”¨æˆ·é—®é¢˜ï¼š{question}\n"
                    "å›ç­”ï¼š"
                )
                try:
                    llm_start = time.time()
                    llm_resp = self.llm.complete(fallback_prompt)
                    llm_time = time.time() - llm_start
                    new_answer = (llm_resp.text or "").strip()
                    if new_answer:
                        answer = new_answer
                    else:
                        # åŒé‡å…œåº•ï¼šç»™å‡ºæœ€å°å¯ç”¨å ä½æ–‡æœ¬
                        answer = (
                            "æŠ±æ­‰ï¼Œæœªæ£€ç´¢åˆ°ä¸è¯¥é—®é¢˜é«˜åº¦ç›¸å…³çš„èµ„æ–™ã€‚åŸºäºä¸€èˆ¬çŸ¥è¯†ï¼š\n"
                            "- è¯¥é—®é¢˜å±äºé€šè¯†ç±»ä¸»é¢˜ï¼Œå»ºè®®è¿›ä¸€æ­¥ç»†åŒ–èŒƒå›´ï¼›\n"
                            "- å¦‚éœ€æƒå¨æ¥æºï¼Œå¯æä¾›æ›´å…·ä½“çš„å…³é”®è¯ä»¥ä¾¿æ£€ç´¢ã€‚\n\n"
                            "æ³¨ï¼šæœªæ£€ç´¢åˆ°è¶³å¤Ÿé«˜ç›¸å…³èµ„æ–™ï¼Œæœ¬å›ç­”åŸºäºé€šç”¨çŸ¥è¯†æ¨ç†ï¼Œå¯èƒ½ä¸å«å¼•ç”¨ã€‚"
                        )
                    logger.info("å…œåº•ç”Ÿæˆå®Œæˆ: length=%s, llm_time=%.2fs", len(answer), llm_time)
                except Exception as fe:
                    logger.error("å…œåº•ç”Ÿæˆå¤±è´¥: %s", fe)
                    # ä»ä¿è¯éç©ºè¾“å‡º
                    answer = (
                        "æŠ±æ­‰ï¼Œå½“å‰æ— æ³•ç”Ÿæˆé«˜è´¨é‡ç­”æ¡ˆã€‚\n"
                        "- å»ºè®®è°ƒæ•´æé—®æ–¹å¼æˆ–è¡¥å……ä¸Šä¸‹æ–‡ï¼›\n"
                        "- ç¨åå¯é‡è¯•ä»¥è·å–æ›´ç¨³å®šç»“æœã€‚\n\n"
                        "æ³¨ï¼šæœªæ£€ç´¢åˆ°è¶³å¤Ÿé«˜ç›¸å…³èµ„æ–™ï¼Œæœ¬å›ç­”åŸºäºé€šç”¨çŸ¥è¯†æ¨ç†ï¼Œå¯èƒ½ä¸å«å¼•ç”¨ã€‚"
                    )
            
            # ===== 2. æ”¶é›†è¿½è¸ªä¿¡æ¯ =====
            if collect_trace and trace_info:
                # ä½¿ç”¨å‰é¢å·²è®¡ç®—çš„ç»Ÿè®¡æ•°æ®ï¼ˆè‹¥è¿˜æœªè®¡ç®—ï¼Œåšå®‰å…¨å›é€€ï¼‰
                _scores = [s['score'] for s in sources if s.get('score') is not None]
                _avg = sum(_scores) / len(_scores) if _scores else 0.0
                _min = min(_scores) if _scores else 0.0
                _max = max(_scores) if _scores else 0.0
                _hq = len([s for s in sources if (s.get('score') is not None) and (s.get('score') >= self.similarity_threshold)])
                _none_count = len(sources) - len(_scores)
                
                trace_info["retrieval"] = {
                    "time_cost": round(retrieval_time, 2),
                    "top_k": self.similarity_top_k,
                    "chunks_retrieved": len(sources),
                    "chunks": sources,
                    "avg_score": round(_avg, 3),
                    "min_score": round(_min, 3),
                    "max_score": round(_max, 3),
                    "threshold": self.similarity_threshold,
                    "high_quality_count": _hq,
                    "numeric_scores_count": len(_scores),
                    "scores_none_count": _none_count,
                }
                
                # æ ‡æ³¨æ˜¯å¦è§¦å‘å…œåº•
                trace_info["llm_generation"] = {
                    "model": self.model,
                    "response_length": len(answer),
                    "fallback_used": bool('fallback_reason' in locals() and fallback_reason),
                    "fallback_reason": fallback_reason if 'fallback_reason' in locals() else None,
                }
                
                trace_info["total_time"] = round(time.time() - trace_info["start_time"], 2)
                
                # è®°å½•è¯¦ç»†æ—¥å¿—
                logger.debug(f"æŸ¥è¯¢è¿½è¸ª: {trace_info}")
            
            print(f"âœ… æŸ¥è¯¢å®Œæˆï¼Œæ‰¾åˆ° {len(sources)} ä¸ªå¼•ç”¨æ¥æº")
            
            return answer, sources, trace_info
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            logger.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
            raise
    
    async def stream_query(self, question: str):
        """å¼‚æ­¥æµå¼æŸ¥è¯¢ï¼ˆç”¨äºWebåº”ç”¨ï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Yields:
            dict: åŒ…å«typeå’Œdataçš„å­—å…¸
                - type='token': dataä¸ºæ–‡æœ¬token
                - type='sources': dataä¸ºå¼•ç”¨æ¥æºåˆ—è¡¨
                - type='done': dataä¸ºå®Œæ•´ç­”æ¡ˆ
        """
        import asyncio
        
        try:
            print(f"\nğŸ’¬ æµå¼æŸ¥è¯¢: {question}")
            
            # æ‰§è¡Œæµå¼æŸ¥è¯¢
            response_stream = self.query_engine.query(question)
            
            # å¯¹äºCitationQueryEngineï¼Œæˆ‘ä»¬éœ€è¦å…ˆè·å–å®Œæ•´å“åº”ï¼Œç„¶åæ¨¡æ‹Ÿæµå¼è¾“å‡º
            # å› ä¸ºå¼•ç”¨éœ€è¦åœ¨å®Œæ•´ç­”æ¡ˆç”Ÿæˆåæ‰èƒ½æå–
            answer = str(response_stream)
            
            # æå–å¼•ç”¨æ¥æº
            sources = []
            if hasattr(response_stream, 'source_nodes') and response_stream.source_nodes:
                for i, node in enumerate(response_stream.source_nodes, 1):
                    source = {
                        'index': i,
                        'text': node.node.text,
                        'score': node.score if hasattr(node, 'score') else None,
                        'metadata': node.node.metadata,
                    }
                    sources.append(source)
            
            # æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼ˆé€å­—ç¬¦ï¼‰
            for char in answer:
                yield {'type': 'token', 'data': char}
                await asyncio.sleep(0.01)  # æ‰“å­—æœºæ•ˆæœ
            
            print(f"âœ… æµå¼æŸ¥è¯¢å®Œæˆï¼Œæ‰¾åˆ° {len(sources)} ä¸ªå¼•ç”¨æ¥æº")
            
            # è¿”å›å¼•ç”¨æ¥æºå’Œå®Œæ•´ç­”æ¡ˆ
            yield {'type': 'sources', 'data': sources}
            yield {'type': 'done', 'data': answer}
            
        except Exception as e:
            print(f"âŒ æµå¼æŸ¥è¯¢å¤±è´¥: {e}")
            raise
    
    def get_retriever(self):
        """è·å–æ£€ç´¢å™¨ï¼ˆç”¨äºé«˜çº§ç”¨æ³•ï¼‰"""
        return self.index.as_retriever(similarity_top_k=self.similarity_top_k)


class SimpleQueryEngine:
    """ç®€å•æŸ¥è¯¢å¼•æ“ï¼ˆä¸å¸¦å¼•ç”¨æº¯æºï¼Œç”¨äºå¿«é€ŸæŸ¥è¯¢ï¼‰"""
    
    def __init__(
        self,
        index_manager: IndexManager,
        api_key: Optional[str] = None,
        api_base: Optional[str] = None,
        model: Optional[str] = None,
        similarity_top_k: Optional[int] = None,
    ):
        """åˆå§‹åŒ–ç®€å•æŸ¥è¯¢å¼•æ“
        
        Args:
            index_manager: ç´¢å¼•ç®¡ç†å™¨
            api_key: DeepSeek APIå¯†é’¥
            api_base: APIç«¯ç‚¹
            model: æ¨¡å‹åç§°
            similarity_top_k: æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£æ•°é‡
        """
        self.index_manager = index_manager
        self.similarity_top_k = similarity_top_k or config.SIMILARITY_TOP_K
        
        # é…ç½®DeepSeek LLM
        self.api_key = api_key or config.DEEPSEEK_API_KEY
        self.model = model or config.LLM_MODEL
        
        if not self.api_key:
            raise ValueError("æœªè®¾ç½®DEEPSEEK_API_KEY")
        
        # ä½¿ç”¨å®˜æ–¹ DeepSeek é›†æˆ
        self.llm = DeepSeek(
            api_key=self.api_key,
            model=self.model,
            temperature=0.5,  # æé«˜æ¸©åº¦ä»¥å¢å¼ºæ¨ç†èƒ½åŠ›
            max_tokens=4096,
        )
        
        # è·å–ç´¢å¼•
        self.index = self.index_manager.get_index()
        
        # åˆ›å»ºæ ‡å‡†æŸ¥è¯¢å¼•æ“
        self.query_engine = self.index.as_query_engine(
            llm=self.llm,
            similarity_top_k=self.similarity_top_k,
        )
    
    def query(self, question: str) -> str:
        """æ‰§è¡Œç®€å•æŸ¥è¯¢
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            ç­”æ¡ˆæ–‡æœ¬
        """
        try:
            response = self.query_engine.query(question)
            return str(response)
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            raise


def format_sources(sources: List[dict]) -> str:
    """æ ¼å¼åŒ–å¼•ç”¨æ¥æºä¸ºå¯è¯»æ–‡æœ¬
    
    Args:
        sources: å¼•ç”¨æ¥æºåˆ—è¡¨
        
    Returns:
        æ ¼å¼åŒ–çš„æ–‡æœ¬
    """
    if not sources:
        return "ï¼ˆæ— å¼•ç”¨æ¥æºï¼‰"
    
    formatted = "\n\nğŸ“š å¼•ç”¨æ¥æºï¼š\n"
    for source in sources:
        formatted += f"\n[{source['index']}] "
        
        # æ·»åŠ æ–‡æ¡£ä¿¡æ¯
        metadata = source['metadata']
        if 'title' in metadata:
            formatted += f"{metadata['title']}"
        elif 'file_name' in metadata:
            formatted += f"{metadata['file_name']}"
        elif 'url' in metadata:
            formatted += f"{metadata['url']}"
        
        # æ·»åŠ ç›¸ä¼¼åº¦åˆ†æ•°
        if source['score'] is not None:
            formatted += f" (ç›¸ä¼¼åº¦: {source['score']:.2f})"
        
        # å®Œæ•´æ˜¾ç¤ºæ–‡æœ¬å†…å®¹ï¼Œä¸æˆªæ–­
        formatted += f"\n   {source['text']}"
    
    return formatted


def create_query_engine(
    index_manager: IndexManager,
    with_citation: bool = True
) -> QueryEngine | SimpleQueryEngine:
    """åˆ›å»ºæŸ¥è¯¢å¼•æ“ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Args:
        index_manager: ç´¢å¼•ç®¡ç†å™¨
        with_citation: æ˜¯å¦ä½¿ç”¨å¼•ç”¨æº¯æº
        
    Returns:
        QueryEngineæˆ–SimpleQueryEngineå¯¹è±¡
    """
    if with_citation:
        return QueryEngine(index_manager)
    else:
        return SimpleQueryEngine(index_manager)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    from llama_index.core import Document as LlamaDocument
    
    print("=== æµ‹è¯•æŸ¥è¯¢å¼•æ“ ===\n")
    
    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
    test_docs = [
        LlamaDocument(
            text="""ç³»ç»Ÿç§‘å­¦æ˜¯20ä¸–çºªä¸­æœŸå…´èµ·çš„ä¸€é—¨æ–°å…´å­¦ç§‘ï¼Œå®ƒç ”ç©¶ç³»ç»Ÿçš„ä¸€èˆ¬è§„å¾‹å’Œæ–¹æ³•ã€‚
            ç³»ç»Ÿç§‘å­¦åŒ…æ‹¬ç³»ç»Ÿè®ºã€æ§åˆ¶è®ºã€ä¿¡æ¯è®ºç­‰å¤šä¸ªåˆ†æ”¯ã€‚""",
            metadata={"title": "ç³»ç»Ÿç§‘å­¦æ¦‚è¿°", "source": "test"}
        ),
        LlamaDocument(
            text="""é’±å­¦æ£®ï¼ˆ1911-2009ï¼‰æ˜¯ä¸­å›½è‘—åç§‘å­¦å®¶ï¼Œè¢«èª‰ä¸º"ä¸­å›½èˆªå¤©ä¹‹çˆ¶"ã€‚
            ä»–åœ¨ç³»ç»Ÿå·¥ç¨‹å’Œç³»ç»Ÿç§‘å­¦é¢†åŸŸåšå‡ºäº†æ°å‡ºè´¡çŒ®ï¼Œæå‡ºäº†å¼€æ”¾çš„å¤æ‚å·¨ç³»ç»Ÿç†è®ºã€‚""",
            metadata={"title": "é’±å­¦æ£®ç”Ÿå¹³", "source": "test"}
        ),
        LlamaDocument(
            text="""ç³»ç»Ÿå·¥ç¨‹æ˜¯ä¸€ç§ç»„ç»‡ç®¡ç†æŠ€æœ¯ï¼Œç”¨äºè§£å†³å¤§è§„æ¨¡å¤æ‚ç³»ç»Ÿçš„è®¾è®¡å’Œå®æ–½é—®é¢˜ã€‚
            é’±å­¦æ£®å°†ç³»ç»Ÿå·¥ç¨‹å¼•å…¥ä¸­å›½ï¼Œå¹¶ç»“åˆä¸­å›½å®é™…è¿›è¡Œäº†åˆ›æ–°æ€§å‘å±•ã€‚""",
            metadata={"title": "ç³»ç»Ÿå·¥ç¨‹ç®€ä»‹", "source": "test"}
        ),
    ]
    
    # åˆ›å»ºç´¢å¼•
    index_manager = IndexManager(collection_name="test_query")
    index_manager.build_index(test_docs)
    
    # åˆ›å»ºæŸ¥è¯¢å¼•æ“
    query_engine = QueryEngine(index_manager)
    
    # æµ‹è¯•æŸ¥è¯¢
    question = "é’±å­¦æ£®åœ¨ç³»ç»Ÿç§‘å­¦é¢†åŸŸæœ‰ä»€ä¹ˆè´¡çŒ®ï¼Ÿ"
    answer, sources = query_engine.query(question)
    
    print(f"\né—®é¢˜: {question}")
    print(f"\nç­”æ¡ˆ:\n{answer}")
    print(format_sources(sources))
    
    # æ¸…ç†
    index_manager.clear_index()
    print("\nâœ… æµ‹è¯•å®Œæˆ")

