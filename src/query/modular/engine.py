"""
æ¨¡å—åŒ–æŸ¥è¯¢å¼•æ“ - æ ¸å¿ƒå¼•æ“æ¨¡å—
ModularQueryEngineç±»å®ç°
"""

from typing import List, Optional, Tuple, Dict, Any
from llama_index.core import VectorStoreIndex, Settings
from llama_index.core.query_engine import RetrieverQueryEngine
from src.config import config
from src.indexer import IndexManager
from src.logger import setup_logger
from src.response_formatter import ResponseFormatter
from src.observers.manager import ObserverManager
from src.observers.factory import create_observer_from_config
from src.query.modular.retriever_factory import create_retriever
from src.query.modular.postprocessor_factory import create_postprocessors
from src.query.modular.query_executor import execute_query
from src.query.modular.query_processor import QueryProcessor
from src.query.fallback import handle_fallback
from src.llms import create_deepseek_llm_for_query

logger = setup_logger('modular_query_engine')


class ModularQueryEngine:
    """æ¨¡å—åŒ–æŸ¥è¯¢å¼•æ“ï¼ˆå·¥å‚æ¨¡å¼ï¼‰"""
    
    SUPPORTED_STRATEGIES = ["vector", "bm25", "hybrid", "grep", "multi"]
    
    def __init__(
        self,
        index_manager: IndexManager,
        api_key: Optional[str] = None,
        model: Optional[str] = None,
        retrieval_strategy: Optional[str] = None,
        similarity_top_k: Optional[int] = None,
        enable_rerank: Optional[bool] = None,
        rerank_top_n: Optional[int] = None,
        reranker_type: Optional[str] = None,
        similarity_cutoff: Optional[float] = None,
        enable_markdown_formatting: bool = True,
        observer_manager: Optional[ObserverManager] = None,
        enable_auto_routing: Optional[bool] = None,
        **kwargs
    ):
        """åˆå§‹åŒ–æ¨¡å—åŒ–æŸ¥è¯¢å¼•æ“"""
        self.index_manager = index_manager
        self.index = index_manager.get_index()
        
        # é…ç½®å‚æ•°
        self.retrieval_strategy = retrieval_strategy or config.RETRIEVAL_STRATEGY
        self.similarity_top_k = similarity_top_k or config.SIMILARITY_TOP_K
        self.enable_rerank = enable_rerank if enable_rerank is not None else config.ENABLE_RERANK
        self.rerank_top_n = rerank_top_n or config.RERANK_TOP_N
        self.reranker_type = reranker_type or config.RERANKER_TYPE
        self.similarity_cutoff = similarity_cutoff or config.SIMILARITY_CUTOFF
        self.enable_auto_routing = enable_auto_routing if enable_auto_routing is not None else config.ENABLE_AUTO_ROUTING
        
        # éªŒè¯ç­–ç•¥
        if self.retrieval_strategy not in self.SUPPORTED_STRATEGIES:
            raise ValueError(
                f"ä¸æ”¯æŒçš„æ£€ç´¢ç­–ç•¥: {self.retrieval_strategy}. "
                f"æ”¯æŒçš„ç­–ç•¥: {self.SUPPORTED_STRATEGIES}"
            )
        
        # åˆå§‹åŒ–å“åº”æ ¼å¼åŒ–å™¨
        self.formatter = ResponseFormatter(enable_formatting=enable_markdown_formatting)
        
        # åˆå§‹åŒ–è§‚å¯Ÿå™¨ç®¡ç†å™¨
        if observer_manager is not None:
            self.observer_manager = observer_manager
            logger.info(f"âœ… ä½¿ç”¨æä¾›çš„è§‚å¯Ÿå™¨ç®¡ç†å™¨: {len(observer_manager.observers)} ä¸ªè§‚å¯Ÿå™¨")
        else:
            self.observer_manager = create_observer_from_config()
            logger.info(f"âœ… ä»é…ç½®åˆ›å»ºè§‚å¯Ÿå™¨ç®¡ç†å™¨: {len(self.observer_manager.observers)} ä¸ªè§‚å¯Ÿå™¨")
        
        # è·å–æ‰€æœ‰å›è°ƒå¤„ç†å™¨
        callback_handlers = self.observer_manager.get_callback_handlers()
        if callback_handlers:
            from llama_index.core.callbacks import CallbackManager
            Settings.callback_manager = CallbackManager(callback_handlers)
            logger.info(f"âœ… è®¾ç½® {len(callback_handlers)} ä¸ªå›è°ƒå¤„ç†å™¨åˆ° LlamaIndex")
        
        # é…ç½® LLMï¼ˆä½¿ç”¨å·¥å‚å‡½æ•°ï¼Œè‡ªç„¶è¯­è¨€åœºæ™¯ï¼‰
        self.api_key = api_key or config.DEEPSEEK_API_KEY
        self.model = model or config.LLM_MODEL
        if not self.api_key:
            raise ValueError("æœªè®¾ç½®DEEPSEEK_API_KEY")
        
        self.llm = create_deepseek_llm_for_query(
            api_key=self.api_key,
            model=self.model,
            max_tokens=4096,
        )
        
        # åˆå§‹åŒ–æŸ¥è¯¢å¤„ç†å™¨ï¼ˆæ ‡å‡†åŒ–æµç¨‹ï¼šæ„å›¾ç†è§£+æ”¹å†™ï¼‰
        self.query_processor = QueryProcessor(llm=self.llm)
        logger.info("âœ… æŸ¥è¯¢å¤„ç†å™¨å·²åˆå§‹åŒ–ï¼ˆæ ‡å‡†åŒ–æµç¨‹ï¼šæ„å›¾ç†è§£+æ”¹å†™ï¼‰")
        
        # å¦‚æœå¯ç”¨è‡ªåŠ¨è·¯ç”±ï¼Œåˆ›å»ºQueryRouter
        if self.enable_auto_routing:
            from src.routers.query_router import QueryRouter
            self.query_router = QueryRouter(
                index_manager=index_manager,
                llm=self.llm,
                enable_auto_routing=True,
            )
            logger.info("âœ… æŸ¥è¯¢è·¯ç”±å™¨å·²å¯ç”¨ï¼ˆè‡ªåŠ¨è·¯ç”±æ¨¡å¼ï¼‰")
        else:
            self.query_router = None
        
        # åˆ›å»ºæ£€ç´¢å™¨ï¼ˆå¦‚æœå¯ç”¨è‡ªåŠ¨è·¯ç”±ï¼Œretrieverä¼šåœ¨queryæ—¶åŠ¨æ€åˆ›å»ºï¼‰
        if not self.enable_auto_routing:
            self.retriever = create_retriever(
                self.index,
                self.retrieval_strategy,
                self.similarity_top_k
            )
        else:
            # è‡ªåŠ¨è·¯ç”±æ¨¡å¼ä¸‹ï¼Œretrieveråœ¨queryæ—¶åŠ¨æ€åˆ›å»º
            self.retriever = None
        
        # åˆ›å»ºåå¤„ç†å™¨
        self.postprocessors = create_postprocessors(
            self.index_manager,
            self.similarity_cutoff,
            self.enable_rerank,
            self.rerank_top_n,
            reranker_type=self.reranker_type,
        )
        
        # åˆ›å»ºæŸ¥è¯¢å¼•æ“ï¼ˆå¦‚æœå¯ç”¨è‡ªåŠ¨è·¯ç”±ï¼Œquery_engineåœ¨queryæ—¶åŠ¨æ€åˆ›å»ºï¼‰
        if not self.enable_auto_routing:
            self.query_engine = RetrieverQueryEngine.from_args(
                retriever=self.retriever,
                llm=self.llm,
                node_postprocessors=self.postprocessors,
            )
        else:
            # è‡ªåŠ¨è·¯ç”±æ¨¡å¼ä¸‹ï¼Œquery_engineåœ¨queryæ—¶åŠ¨æ€åˆ›å»º
            self.query_engine = None
        
        logger.info(f"âœ… æ¨¡å—åŒ–æŸ¥è¯¢å¼•æ“åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æ£€ç´¢ç­–ç•¥: {self.retrieval_strategy}")
        logger.info(f"   Top-K: {self.similarity_top_k}")
        logger.info(f"   é‡æ’åº: {'å¯ç”¨' if self.enable_rerank else 'ç¦ç”¨'}")
        logger.info(f"   ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_cutoff}")
    
    def query(
        self, 
        question: str, 
        collect_trace: bool = False
    ) -> Tuple[str, List[dict], Optional[str], Optional[Dict[str, Any]]]:
        """æ‰§è¡ŒæŸ¥è¯¢ï¼ˆå…¼å®¹ç°æœ‰APIï¼‰
        
        Returns:
            (ç­”æ¡ˆ, å¼•ç”¨æ¥æº, æ¨ç†é“¾å†…å®¹, è¿½è¸ªä¿¡æ¯)
        """
        
        # Step 1: æŸ¥è¯¢å¤„ç†ï¼ˆæ ‡å‡†åŒ–æµç¨‹ï¼šæ„å›¾ç†è§£+æ”¹å†™ï¼‰
        processed = self.query_processor.process(question)
        final_query = processed["final_query"]
        understanding = processed.get("understanding")
        
        logger.info(
            f"ğŸ“ æŸ¥è¯¢å¤„ç†å®Œæˆ: "
            f"åŸå§‹='{question[:50]}...', "
            f"æœ€ç»ˆ='{final_query[:50]}...', "
            f"å¤„ç†æ–¹å¼={processed['processing_method']}"
        )
        
        # å¦‚æœå¯ç”¨è‡ªåŠ¨è·¯ç”±ï¼ŒåŠ¨æ€åˆ›å»ºquery_engine
        if self.enable_auto_routing and self.query_router:
            # ä¼ é€’æ„å›¾ç†è§£ç»“æœç»™è·¯ç”±å™¨
            if understanding:
                retriever, routing_decision = self.query_router.route_with_understanding(
                    final_query,
                    understanding=understanding,
                    top_k=self.similarity_top_k
                )
            else:
                retriever, routing_decision = self.query_router.route(
                    final_query,
                    top_k=self.similarity_top_k
                )
            
            # åŠ¨æ€åˆ›å»ºquery_engine
            query_engine = RetrieverQueryEngine.from_args(
                retriever=retriever,
                llm=self.llm,
                node_postprocessors=self.postprocessors,
            )
            
            logger.info(
                f"ğŸ” ä½¿ç”¨æ£€ç´¢ç­–ç•¥: "
                f"ç­–ç•¥={routing_decision}, "
                f"åŸå› =è‡ªåŠ¨è·¯ç”±æ¨¡å¼ï¼Œæ ¹æ®æŸ¥è¯¢æ„å›¾åŠ¨æ€é€‰æ‹©"
            )
            answer, sources, reasoning_content, trace_info = execute_query(
                query_engine,
                self.formatter,
                self.observer_manager,
                final_query,  # ä½¿ç”¨æ”¹å†™åçš„æŸ¥è¯¢
                collect_trace
            )
        else:
            # ä½¿ç”¨å›ºå®šçš„query_engine
            logger.info(
                f"ğŸ” ä½¿ç”¨æ£€ç´¢ç­–ç•¥: "
                f"ç­–ç•¥={self.retrieval_strategy}, "
                f"åŸå› =å›ºå®šæ£€ç´¢æ¨¡å¼ï¼ˆåˆå§‹åŒ–æ—¶é…ç½®ï¼‰"
            )
            answer, sources, reasoning_content, trace_info = execute_query(
                self.query_engine,
                self.formatter,
                self.observer_manager,
                final_query,  # ä½¿ç”¨æ”¹å†™åçš„æŸ¥è¯¢
                collect_trace
            )
        
        # è®°å½•è¿½è¸ªä¿¡æ¯
        if collect_trace and trace_info:
            trace_info["original_query"] = question
            trace_info["processed_query"] = final_query
            trace_info["query_processing"] = processed
        
        # å¤„ç†å…œåº•é€»è¾‘ï¼ˆæ— æ¥æºã€ä½ç›¸ä¼¼åº¦æˆ–ç©ºç­”æ¡ˆæ—¶è§¦å‘ï¼‰
        # æ³¨æ„ï¼šä½¿ç”¨åŸå§‹æŸ¥è¯¢è¿›è¡Œå…œåº•å¤„ç†ï¼Œç¡®ä¿ç”¨æˆ·çœ‹åˆ°çš„æ˜¯åŸå§‹é—®é¢˜çš„ç­”æ¡ˆ
        answer, fallback_reason = handle_fallback(
            answer, sources, question, self.llm, self.similarity_cutoff
        )
        
        # å¦‚æœæ”¶é›†è¿½è¸ªä¿¡æ¯ï¼Œè®°å½•å…œåº•çŠ¶æ€
        if collect_trace and trace_info:
            trace_info['fallback_used'] = bool(fallback_reason)
            trace_info['fallback_reason'] = fallback_reason
        
        return answer, sources, reasoning_content, trace_info
    
    async def stream_query(self, question: str):
        """å¼‚æ­¥æµå¼æŸ¥è¯¢ï¼ˆç”¨äºWebåº”ç”¨ï¼‰"""
        raise NotImplementedError("æµå¼æŸ¥è¯¢æš‚æœªå®ç°")


def create_modular_query_engine(
    index_manager: IndexManager,
    strategy: Optional[str] = None,
    **kwargs
) -> ModularQueryEngine:
    """åˆ›å»ºæ¨¡å—åŒ–æŸ¥è¯¢å¼•æ“ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    return ModularQueryEngine(
        index_manager=index_manager,
        retrieval_strategy=strategy,
        **kwargs
    )
