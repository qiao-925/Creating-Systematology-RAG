"""
é…ç½®ç®¡ç†æ¨¡å—
ç®¡ç†APIå¯†é’¥ã€æ¨¡å‹é…ç½®ã€è·¯å¾„é…ç½®ç­‰
"""

import os
from pathlib import Path
from typing import Optional, Tuple
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å…¨å±€GPUè®¾å¤‡ä¿¡æ¯ï¼ˆé¡¹ç›®å¯åŠ¨æ—¶æ£€æµ‹ï¼‰
_GPU_DEVICE: Optional[str] = None
_GPU_AVAILABLE: bool = False
_GPU_DEVICE_NAME: Optional[str] = None


def detect_gpu_device() -> Tuple[bool, str, Optional[str]]:
    """æ£€æµ‹GPUè®¾å¤‡é…ç½®ï¼ˆç®€åŒ–ç‰ˆï¼‰
    
    Returns:
        (has_gpu, device, device_name)
    """
    global _GPU_AVAILABLE, _GPU_DEVICE, _GPU_DEVICE_NAME
    
    # å¦‚æœå·²ç»æ£€æµ‹è¿‡ï¼Œç›´æ¥è¿”å›ç¼“å­˜ç»“æœ
    if _GPU_DEVICE is not None:
        return _GPU_AVAILABLE, _GPU_DEVICE, _GPU_DEVICE_NAME
    
    print("ğŸ” æ£€æµ‹GPUè®¾å¤‡...")
    
    try:
        import torch
        if torch.cuda.is_available():
            _GPU_AVAILABLE = True
            _GPU_DEVICE = "cuda:0"
            _GPU_DEVICE_NAME = torch.cuda.get_device_name(0)
            print(f"âœ… ä½¿ç”¨GPU: {_GPU_DEVICE_NAME}")
        else:
            _GPU_AVAILABLE = False
            _GPU_DEVICE = "cpu"
            _GPU_DEVICE_NAME = None
            print("âš ï¸  ä½¿ç”¨CPUæ¨¡å¼")
    except:
        _GPU_AVAILABLE = False
        _GPU_DEVICE = "cpu"
        _GPU_DEVICE_NAME = None
        print("âš ï¸  ä½¿ç”¨CPUæ¨¡å¼")
    
    return _GPU_AVAILABLE, _GPU_DEVICE, _GPU_DEVICE_NAME


def get_device_status() -> dict:
    """è·å–å½“å‰è®¾å¤‡çŠ¶æ€æ‘˜è¦
    
    Returns:
        åŒ…å«è®¾å¤‡çŠ¶æ€çš„å­—å…¸ï¼š
        {
            "device": str,           # è®¾å¤‡å­—ç¬¦ä¸²
            "has_gpu": bool,         # æ˜¯å¦æœ‰GPU
            "device_name": str,      # GPUè®¾å¤‡åç§°ï¼ˆå¦‚æœæœ‰ï¼‰
            "is_gpu": bool,          # å½“å‰æ˜¯å¦ä½¿ç”¨GPU
        }
    """
    device = get_gpu_device()
    has_gpu, _, device_name = detect_gpu_device()
    
    return {
        "device": device,
        "has_gpu": has_gpu,
        "device_name": device_name,
        "is_gpu": device.startswith("cuda"),
    }


def get_gpu_device() -> str:
    """è·å–GPUè®¾å¤‡å­—ç¬¦ä¸²ï¼ˆGPUä¼˜å…ˆï¼ŒCPUå…œåº•ï¼‰
    
    Returns:
        è®¾å¤‡å­—ç¬¦ä¸² ("cuda:0" æˆ– "cpu")
    """
    if _GPU_DEVICE is None:
        # å¦‚æœè¿˜æ²¡æ£€æµ‹ï¼Œå…ˆæ£€æµ‹ä¸€æ¬¡
        detect_gpu_device()
    return _GPU_DEVICE or "cpu"


def is_gpu_available() -> bool:
    """æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨ï¼ˆå¿…é¡»åœ¨detect_gpu_device()ä¹‹åè°ƒç”¨ï¼‰
    
    Returns:
        æ˜¯å¦æœ‰GPUå¯ç”¨
    """
    if _GPU_DEVICE is None:
        # å¦‚æœè¿˜æ²¡æ£€æµ‹ï¼Œå…ˆæ£€æµ‹ä¸€æ¬¡
        detect_gpu_device()
    return _GPU_AVAILABLE


class Config:
    """åº”ç”¨é…ç½®ç±»"""
    
    def __init__(self):
        # é¡¹ç›®æ ¹ç›®å½•
        self.PROJECT_ROOT = Path(__file__).parent.parent
        
        # DeepSeek APIé…ç½®
        self.DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")
        self.DEEPSEEK_API_BASE = os.getenv("DEEPSEEK_API_BASE", "https://api.deepseek.com/v1")
        
        # æ¨¡å‹é…ç½®
        self.LLM_MODEL = os.getenv("LLM_MODEL", "deepseek-chat")
        self.EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "Qwen/Qwen3-Embedding-0.6B")
        
        # HuggingFaceé•œåƒé…ç½®
        self.HF_ENDPOINT = os.getenv("HF_ENDPOINT", "https://hf-mirror.com")
        self.HF_OFFLINE_MODE = os.getenv("HF_OFFLINE_MODE", "false").lower() == "true"
        
        # å‘é‡æ•°æ®åº“é…ç½®
        self.VECTOR_STORE_PATH = self._get_path("VECTOR_STORE_PATH", "vector_store")
        self.CHROMA_COLLECTION_NAME = os.getenv("CHROMA_COLLECTION_NAME", "default")
        
        # æ–‡æ¡£è·¯å¾„é…ç½®
        self.RAW_DATA_PATH = self._get_path("RAW_DATA_PATH", "data/raw")
        self.PROCESSED_DATA_PATH = self._get_path("PROCESSED_DATA_PATH", "data/processed")
        
        # ä¼šè¯å’Œæ—¥å¿—è·¯å¾„é…ç½®
        self.SESSIONS_PATH = self._get_path("SESSIONS_PATH", "sessions")
        self.ACTIVITY_LOG_PATH = self._get_path("ACTIVITY_LOG_PATH", "logs/activity")
        
        # GitHub é…ç½®
        self.GITHUB_REPOS_PATH = self._get_path("GITHUB_REPOS_PATH", "data/github_repos")
        self.GITHUB_METADATA_PATH = self._get_path("GITHUB_METADATA_PATH", "data/github_metadata.json")
        
        # ç´¢å¼•é…ç½®
        self.CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", "512"))
        self.CHUNK_OVERLAP = int(os.getenv("CHUNK_OVERLAP", "50"))
        self.SIMILARITY_TOP_K = int(os.getenv("SIMILARITY_TOP_K", "3"))
<<<<<<< Current (Your changes)
        self.SIMILARITY_THRESHOLD = float(os.getenv("SIMILARITY_THRESHOLD", "0.2"))  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼ä¼šå¯ç”¨æ¨ç†æ¨¡å¼
=======
        self.SIMILARITY_THRESHOLD = float(os.getenv("SIMILARITY_THRESHOLD", "0.5"))
>>>>>>> Incoming (Background Agent changes)
        
        # Embeddingæ€§èƒ½ä¼˜åŒ–é…ç½®
        self.EMBED_BATCH_SIZE = int(os.getenv("EMBED_BATCH_SIZE", "10"))
        self.EMBED_MAX_LENGTH = int(os.getenv("EMBED_MAX_LENGTH", "512"))
        
        # åº”ç”¨é…ç½®
        self.APP_TITLE = os.getenv("APP_TITLE", "ä¸»é¡µ")
        self.APP_PORT = int(os.getenv("APP_PORT", "8501"))
        
        # GitHubæ•°æ®æºé…ç½®ï¼ˆä»…æ”¯æŒå…¬å¼€ä»“åº“ï¼‰
        self.GITHUB_DEFAULT_BRANCH = os.getenv("GITHUB_DEFAULT_BRANCH", "main")
        
    def _get_path(self, env_var: str, default: str) -> Path:
        """è·å–è·¯å¾„é…ç½®ï¼Œæ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„"""
        path_str = os.getenv(env_var, default)
        path = Path(path_str)
        
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œåˆ™ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
        if not path.is_absolute():
            path = self.PROJECT_ROOT / path
            
        return path
    
    def ensure_directories(self):
        """ç¡®ä¿æ‰€æœ‰å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        directories = [
            self.VECTOR_STORE_PATH,
            self.RAW_DATA_PATH,
            self.PROCESSED_DATA_PATH,
            self.SESSIONS_PATH,
            self.ACTIVITY_LOG_PATH,
            self.GITHUB_REPOS_PATH,
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            
    def validate(self) -> tuple[bool, Optional[str]]:
        """éªŒè¯é…ç½®æ˜¯å¦å®Œæ•´
        
        Returns:
            (is_valid, error_message)
        """
        if not self.DEEPSEEK_API_KEY:
            return False, "æœªè®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡"
        
        if self.CHUNK_SIZE <= 0:
            return False, "CHUNK_SIZEå¿…é¡»å¤§äº0"
            
        if self.CHUNK_OVERLAP < 0:
            return False, "CHUNK_OVERLAPå¿…é¡»å¤§äºç­‰äº0"
            
        if self.CHUNK_OVERLAP >= self.CHUNK_SIZE:
            return False, "CHUNK_OVERLAPå¿…é¡»å°äºCHUNK_SIZE"
            
        return True, None
    
    def __repr__(self) -> str:
        """è¿”å›é…ç½®çš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰"""
        return f"""Config(
    PROJECT_ROOT={self.PROJECT_ROOT},
    DEEPSEEK_API_BASE={self.DEEPSEEK_API_BASE},
    LLM_MODEL={self.LLM_MODEL},
    EMBEDDING_MODEL={self.EMBEDDING_MODEL},
    HF_ENDPOINT={self.HF_ENDPOINT},
    HF_OFFLINE_MODE={self.HF_OFFLINE_MODE},
    VECTOR_STORE_PATH={self.VECTOR_STORE_PATH},
    SESSIONS_PATH={self.SESSIONS_PATH},
    ACTIVITY_LOG_PATH={self.ACTIVITY_LOG_PATH},
    GITHUB_METADATA_PATH={self.GITHUB_METADATA_PATH},
    CHUNK_SIZE={self.CHUNK_SIZE},
    CHUNK_OVERLAP={self.CHUNK_OVERLAP},
    SIMILARITY_TOP_K={self.SIMILARITY_TOP_K},
    EMBED_BATCH_SIZE={self.EMBED_BATCH_SIZE},
    EMBED_MAX_LENGTH={self.EMBED_MAX_LENGTH},
    GITHUB_DEFAULT_BRANCH={self.GITHUB_DEFAULT_BRANCH}
)"""


# å…¨å±€é…ç½®å®ä¾‹
config = Config()

# é¡¹ç›®å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æµ‹GPUï¼ˆåœ¨configæ¨¡å—åŠ è½½åï¼‰
# è¿™æ ·ç¡®ä¿æ‰€æœ‰å¿…è¦çš„æ¨¡å—éƒ½å·²å¯¼å…¥
try:
    print("=" * 60)
    print("ğŸš€ é¡¹ç›®å¯åŠ¨ - GPUè®¾å¤‡æ£€æµ‹")
    print("=" * 60)
    detect_gpu_device()
    print("=" * 60)
except Exception as e:
    # GPUæ£€æµ‹å¤±è´¥ä¸å½±å“é¡¹ç›®å¯åŠ¨ï¼Œä»…è®°å½•
    import traceback
    print(f"âš ï¸  é¡¹ç›®å¯åŠ¨æ—¶GPUæ£€æµ‹å¤±è´¥: {e}")
    traceback.print_exc()


if __name__ == "__main__":
    # æµ‹è¯•é…ç½®
    print("=== é…ç½®ä¿¡æ¯ ===")
    print(config)
    print("\n=== é…ç½®éªŒè¯ ===")
    is_valid, error_msg = config.validate()
    if is_valid:
        print("âœ… é…ç½®éªŒè¯é€šè¿‡")
        config.ensure_directories()
        print("âœ… ç›®å½•åˆ›å»ºæˆåŠŸ")
    else:
        print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {error_msg}")

