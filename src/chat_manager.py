"""
å¤šè½®å¯¹è¯ç®¡ç†æ¨¡å—
ç®¡ç†å¯¹è¯å†å²ã€ä¸Šä¸‹æ–‡è®°å¿†å’Œä¼šè¯æŒä¹…åŒ–
"""

import json
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any
from dataclasses import dataclass, asdict

from llama_index.core.memory import ChatMemoryBuffer
from llama_index.core.chat_engine import CondensePlusContextChatEngine
from llama_index.core.llms import ChatMessage, MessageRole
from llama_index.llms.openai import OpenAI

from src.config import config
from src.indexer import IndexManager


@dataclass
class ChatTurn:
    """å•è½®å¯¹è¯"""
    question: str
    answer: str
    sources: List[Dict[str, Any]]
    timestamp: str
    
    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: dict):
        """ä»å­—å…¸åˆ›å»º"""
        return cls(**data)


class ChatSession:
    """å¯¹è¯ä¼šè¯"""
    
    def __init__(self, session_id: Optional[str] = None):
        """åˆå§‹åŒ–å¯¹è¯ä¼šè¯
        
        Args:
            session_id: ä¼šè¯IDï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆ
        """
        self.session_id = session_id or self._generate_session_id()
        self.history: List[ChatTurn] = []
        self.created_at = datetime.now().isoformat()
        self.updated_at = self.created_at
    
    @staticmethod
    def _generate_session_id() -> str:
        """ç”Ÿæˆä¼šè¯ID"""
        return f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    def add_turn(self, question: str, answer: str, sources: List[dict]):
        """æ·»åŠ ä¸€è½®å¯¹è¯
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            answer: AIå›ç­”
            sources: å¼•ç”¨æ¥æº
        """
        turn = ChatTurn(
            question=question,
            answer=answer,
            sources=sources,
            timestamp=datetime.now().isoformat()
        )
        self.history.append(turn)
        self.updated_at = turn.timestamp
    
    def get_history(self, last_n: Optional[int] = None) -> List[ChatTurn]:
        """è·å–å¯¹è¯å†å²
        
        Args:
            last_n: è·å–æœ€è¿‘Nè½®å¯¹è¯ï¼ŒNoneè¡¨ç¤ºè·å–å…¨éƒ¨
            
        Returns:
            å¯¹è¯å†å²åˆ—è¡¨
        """
        if last_n is None:
            return self.history
        return self.history[-last_n:]
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.history = []
        self.updated_at = datetime.now().isoformat()
    
    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'session_id': self.session_id,
            'created_at': self.created_at,
            'updated_at': self.updated_at,
            'history': [turn.to_dict() for turn in self.history]
        }
    
    @classmethod
    def from_dict(cls, data: dict):
        """ä»å­—å…¸åˆ›å»º"""
        session = cls(session_id=data['session_id'])
        session.created_at = data['created_at']
        session.updated_at = data['updated_at']
        session.history = [ChatTurn.from_dict(turn) for turn in data['history']]
        return session
    
    def save(self, save_dir: Path):
        """ä¿å­˜ä¼šè¯åˆ°æ–‡ä»¶
        
        Args:
            save_dir: ä¿å­˜ç›®å½•
        """
        save_dir.mkdir(parents=True, exist_ok=True)
        file_path = save_dir / f"{self.session_id}.json"
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(self.to_dict(), f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ä¼šè¯å·²ä¿å­˜: {file_path}")
    
    @classmethod
    def load(cls, file_path: Path):
        """ä»æ–‡ä»¶åŠ è½½ä¼šè¯
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            ChatSessionå¯¹è±¡
        """
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return cls.from_dict(data)


class ChatManager:
    """å¯¹è¯ç®¡ç†å™¨"""
    
    def __init__(
        self,
        index_manager: IndexManager,
        api_key: Optional[str] = None,
        api_base: Optional[str] = None,
        model: Optional[str] = None,
        memory_token_limit: int = 3000,
        similarity_top_k: Optional[int] = None,
    ):
        """åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨
        
        Args:
            index_manager: ç´¢å¼•ç®¡ç†å™¨
            api_key: DeepSeek APIå¯†é’¥
            api_base: APIç«¯ç‚¹
            model: æ¨¡å‹åç§°
            memory_token_limit: è®°å¿†tokené™åˆ¶
            similarity_top_k: æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£æ•°é‡
        """
        self.index_manager = index_manager
        self.similarity_top_k = similarity_top_k or config.SIMILARITY_TOP_K
        
        # é…ç½®DeepSeek LLM
        self.api_key = api_key or config.DEEPSEEK_API_KEY
        self.api_base = api_base or config.DEEPSEEK_API_BASE
        self.model = model or config.LLM_MODEL
        
        if not self.api_key:
            raise ValueError("æœªè®¾ç½®DEEPSEEK_API_KEY")
        
        print(f"ğŸ¤– åˆå§‹åŒ–DeepSeek LLM (å¯¹è¯æ¨¡å¼): {self.model}")
        self.llm = OpenAI(
            api_key=self.api_key,
            api_base=self.api_base,
            model=self.model,
            temperature=0.3,  # å¯¹è¯æ¨¡å¼å¯ä»¥ç¨å¾®é«˜ä¸€ç‚¹æ¸©åº¦
        )
        
        # åˆ›å»ºè®°å¿†ç¼“å†²åŒº
        self.memory = ChatMemoryBuffer.from_defaults(
            token_limit=memory_token_limit,
        )
        
        # è·å–ç´¢å¼•
        self.index = self.index_manager.get_index()
        
        # åˆ›å»ºèŠå¤©å¼•æ“
        print("ğŸ’¬ åˆ›å»ºå¤šè½®å¯¹è¯å¼•æ“")
        self.chat_engine = CondensePlusContextChatEngine.from_defaults(
            retriever=self.index.as_retriever(similarity_top_k=self.similarity_top_k),
            llm=self.llm,
            memory=self.memory,
            context_prompt=(
                "ä½ æ˜¯ä¸€ä½ç³»ç»Ÿç§‘å­¦é¢†åŸŸçš„ä¸“å®¶åŠ©æ‰‹ã€‚"
                "è¯·åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
                "å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®åœ°è¯´æ˜ã€‚"
                "\n\nä¸Šä¸‹æ–‡ä¿¡æ¯:\n{context_str}\n\n"
                "è¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚"
            ),
        )
        
        # å½“å‰ä¼šè¯
        self.current_session: Optional[ChatSession] = None
        
        print("âœ… å¯¹è¯ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def start_session(self, session_id: Optional[str] = None) -> ChatSession:
        """å¼€å§‹æ–°ä¼šè¯
        
        Args:
            session_id: ä¼šè¯ID
            
        Returns:
            ChatSessionå¯¹è±¡
        """
        self.current_session = ChatSession(session_id=session_id)
        self.memory.reset()  # é‡ç½®è®°å¿†
        print(f"ğŸ†• æ–°ä¼šè¯å¼€å§‹: {self.current_session.session_id}")
        return self.current_session
    
    def load_session(self, file_path: Path):
        """åŠ è½½å·²æœ‰ä¼šè¯
        
        Args:
            file_path: ä¼šè¯æ–‡ä»¶è·¯å¾„
        """
        self.current_session = ChatSession.load(file_path)
        
        # æ¢å¤å¯¹è¯å†å²åˆ°è®°å¿†
        self.memory.reset()
        for turn in self.current_session.history:
            self.memory.put(ChatMessage(role=MessageRole.USER, content=turn.question))
            self.memory.put(ChatMessage(role=MessageRole.ASSISTANT, content=turn.answer))
        
        print(f"ğŸ“‚ ä¼šè¯å·²åŠ è½½: {self.current_session.session_id}")
        print(f"   åŒ…å« {len(self.current_session.history)} è½®å¯¹è¯")
    
    def chat(self, message: str) -> tuple[str, List[dict]]:
        """è¿›è¡Œå¯¹è¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            (å›ç­”, å¼•ç”¨æ¥æºåˆ—è¡¨)
        """
        if self.current_session is None:
            self.start_session()
        
        try:
            print(f"\nğŸ’¬ ç”¨æˆ·: {message}")
            
            # æ‰§è¡Œå¯¹è¯
            response = self.chat_engine.chat(message)
            
            # æå–ç­”æ¡ˆ
            answer = str(response)
            
            # æå–å¼•ç”¨æ¥æº
            sources = []
            if hasattr(response, 'source_nodes') and response.source_nodes:
                for i, node in enumerate(response.source_nodes, 1):
                    source = {
                        'index': i,
                        'text': node.node.text,
                        'score': node.score if hasattr(node, 'score') else None,
                        'metadata': node.node.metadata,
                    }
                    sources.append(source)
            
            # æ·»åŠ åˆ°ä¼šè¯å†å²
            self.current_session.add_turn(message, answer, sources)
            
            print(f"ğŸ¤– AI: {answer[:100]}...")
            print(f"ğŸ“š å¼•ç”¨æ¥æº: {len(sources)} ä¸ª")
            
            return answer, sources
            
        except Exception as e:
            print(f"âŒ å¯¹è¯å¤±è´¥: {e}")
            raise
    
    def get_current_session(self) -> Optional[ChatSession]:
        """è·å–å½“å‰ä¼šè¯"""
        return self.current_session
    
    def save_current_session(self, save_dir: Optional[Path] = None):
        """ä¿å­˜å½“å‰ä¼šè¯
        
        Args:
            save_dir: ä¿å­˜ç›®å½•ï¼Œé»˜è®¤ä¸ºé¡¹ç›®æ ¹ç›®å½•/sessions
        """
        if self.current_session is None:
            print("âš ï¸  æ²¡æœ‰æ´»åŠ¨ä¼šè¯éœ€è¦ä¿å­˜")
            return
        
        if save_dir is None:
            save_dir = config.PROJECT_ROOT / "sessions"
        
        self.current_session.save(save_dir)
    
    def reset_session(self):
        """é‡ç½®å½“å‰ä¼šè¯"""
        if self.current_session:
            self.current_session.clear_history()
        self.memory.reset()
        print("ğŸ”„ ä¼šè¯å·²é‡ç½®")


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    from llama_index.core import Document as LlamaDocument
    
    print("=== æµ‹è¯•å¤šè½®å¯¹è¯ç®¡ç†å™¨ ===\n")
    
    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
    test_docs = [
        LlamaDocument(
            text="ç³»ç»Ÿç§‘å­¦ç ”ç©¶ç³»ç»Ÿçš„ä¸€èˆ¬è§„å¾‹ï¼ŒåŒ…æ‹¬ç³»ç»Ÿè®ºã€æ§åˆ¶è®ºã€ä¿¡æ¯è®ºç­‰åˆ†æ”¯ã€‚",
            metadata={"title": "ç³»ç»Ÿç§‘å­¦", "source": "test"}
        ),
        LlamaDocument(
            text="é’±å­¦æ£®æå‡ºäº†å¼€æ”¾çš„å¤æ‚å·¨ç³»ç»Ÿç†è®ºï¼Œå¼ºè°ƒå®šæ€§ä¸å®šé‡ç›¸ç»“åˆçš„ç»¼åˆé›†æˆæ–¹æ³•ã€‚",
            metadata={"title": "é’±å­¦æ£®ç†è®º", "source": "test"}
        ),
    ]
    
    # åˆ›å»ºç´¢å¼•
    index_manager = IndexManager(collection_name="test_chat")
    index_manager.build_index(test_docs)
    
    # åˆ›å»ºå¯¹è¯ç®¡ç†å™¨
    chat_manager = ChatManager(index_manager)
    
    # å¼€å§‹ä¼šè¯
    session = chat_manager.start_session()
    
    # æ¨¡æ‹Ÿå¤šè½®å¯¹è¯
    questions = [
        "ä»€ä¹ˆæ˜¯ç³»ç»Ÿç§‘å­¦ï¼Ÿ",
        "å®ƒåŒ…æ‹¬å“ªäº›åˆ†æ”¯ï¼Ÿ",
        "é’±å­¦æ£®æœ‰ä»€ä¹ˆè´¡çŒ®ï¼Ÿ"
    ]
    
    for q in questions:
        answer, sources = chat_manager.chat(q)
        print(f"\né—®: {q}")
        print(f"ç­”: {answer}")
    
    # ä¿å­˜ä¼šè¯
    chat_manager.save_current_session()
    
    # æ¸…ç†
    index_manager.clear_index()
    print("\nâœ… æµ‹è¯•å®Œæˆ")

