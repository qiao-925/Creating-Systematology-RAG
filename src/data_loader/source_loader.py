"""
æ•°æ®åŠ è½½å™¨ç»Ÿä¸€å…¥å£æ¨¡å—
ä»æ•°æ®æºåŠ è½½æ–‡æ¡£çš„ç»Ÿä¸€æ¥å£
"""

import time
from typing import List, Optional

from llama_index.core.schema import Document as LlamaDocument

from src.data_source import DataSource
from src.data_parser import DocumentParser
from src.data_loader.processor import DocumentProcessor, safe_print
from src.logger import setup_logger

logger = setup_logger('data_loader')

# æ£€æŸ¥æ–°æ¶æ„æ˜¯å¦å¯ç”¨
try:
    from src.data_source import DataSource, GitHubSource, LocalFileSource, WebSource
    from src.data_parser import DocumentParser
    NEW_ARCHITECTURE_AVAILABLE = True
except ImportError:
    NEW_ARCHITECTURE_AVAILABLE = False


def load_documents_from_source(
    source: DataSource,
    clean: bool = True,
    show_progress: bool = True,
    cache_manager=None,
    task_id: Optional[str] = None
) -> List[LlamaDocument]:
    """ä»æ•°æ®æºåŠ è½½æ–‡æ¡£ï¼ˆç»Ÿä¸€å…¥å£å‡½æ•°ï¼‰
    
    æ–°æ¶æ„çš„ç»Ÿä¸€å…¥å£ï¼Œæ•´åˆæ•°æ®æ¥æºå±‚å’Œè§£æå±‚
    
    Args:
        source: æ•°æ®æºå¯¹è±¡ï¼ˆGitHubSource, LocalFileSource, WebSourceç­‰ï¼‰
        clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        cache_manager: ç¼“å­˜ç®¡ç†å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        task_id: ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œç”¨äºç¼“å­˜ï¼‰
        
    Returns:
        æ–‡æ¡£åˆ—è¡¨
    """
    if not NEW_ARCHITECTURE_AVAILABLE:
        logger.error("æ–°æ¶æ„æœªå¯ç”¨")
        return []
    
    try:
        total_start_time = time.time()
        
        # æ­¥éª¤1: ä»æ•°æ®æºè·å–æ–‡ä»¶è·¯å¾„
        if show_progress:
            safe_print(f"ğŸ” æ­£åœ¨ä»æ•°æ®æºè·å–æ–‡ä»¶è·¯å¾„...")
        
        source_start_time = time.time()
        source_files = source.get_files()
        source_elapsed = time.time() - source_start_time
        
        if not source_files:
            logger.warning(f"æ•°æ®æºæœªè¿”å›ä»»ä½•æ–‡ä»¶")
            if show_progress:
                safe_print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶")
            return []
        
        logger.info(f"æ•°æ®æºè¿”å› {len(source_files)} ä¸ªæ–‡ä»¶ (è€—æ—¶: {source_elapsed:.2f}s)")
        if show_progress:
            safe_print(f"âœ… æ‰¾åˆ° {len(source_files)} ä¸ªæ–‡ä»¶")
        
        # æ­¥éª¤2: æ„å»ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨å’Œå…ƒæ•°æ®æ˜ å°„
        logger.debug("æ„å»ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨å’Œå…ƒæ•°æ®æ˜ å°„")
        file_paths = [sf.path for sf in source_files]
        metadata_map = {}
        for sf in source_files:
            metadata_map[sf.path] = {
                **sf.metadata,
                'source_type': sf.source_type
            }
        logger.debug(f"å…ƒæ•°æ®æ˜ å°„åŒ…å« {len(metadata_map)} ä¸ªæ¡ç›®")
        
        # æ­¥éª¤3: ä½¿ç”¨è§£æå™¨è§£ææ–‡ä»¶
        if show_progress:
            safe_print(f"ğŸ“„ æ­£åœ¨è§£ææ–‡ä»¶...")
        
        parser_start_time = time.time()
        parser = DocumentParser()
        documents = parser.parse_files(
            file_paths, 
            metadata_map, 
            clean=clean,
            cache_manager=cache_manager,
            task_id=task_id
        )
        parser_elapsed = time.time() - parser_start_time
        
        if not documents:
            logger.warning(f"è§£æå™¨æœªè¿”å›ä»»ä½•æ–‡æ¡£ (è¾“å…¥æ–‡ä»¶æ•°: {len(file_paths)})")
            if show_progress:
                safe_print("âš ï¸  æœªèƒ½è§£æä»»ä½•æ–‡æ¡£")
            return []
        
        logger.info(f"è§£æå™¨è¿”å› {len(documents)} ä¸ªæ–‡æ¡£ (è€—æ—¶: {parser_elapsed:.2f}s)")
        
        # æ­¥éª¤4: å¯é€‰çš„æ–‡æœ¬æ¸…ç†
        clean_elapsed = 0.0
        if clean:
            logger.debug("å¼€å§‹æ–‡æœ¬æ¸…ç†")
            clean_start_time = time.time()
            processor = DocumentProcessor()
            cleaned_documents = []
            for doc in documents:
                cleaned_text = processor.clean_text(doc.text)
                cleaned_doc = LlamaDocument(
                    text=cleaned_text,
                    metadata=doc.metadata,
                    id_=doc.id_
                )
                cleaned_documents.append(cleaned_doc)
            documents = cleaned_documents
            clean_elapsed = time.time() - clean_start_time
        else:
            logger.debug("è·³è¿‡æ–‡æœ¬æ¸…ç†")
        
        total_elapsed = time.time() - total_start_time
        
        if show_progress:
            safe_print(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        
        success_rate = (len(documents) / len(source_files) * 100) if source_files else 0
        logger.info(
            f"æ–‡æ¡£åŠ è½½å®Œæˆ: "
            f"æºæ–‡ä»¶æ•°={len(source_files)}, "
            f"è§£ææ–‡æ¡£æ•°={len(documents)}, "
            f"æˆåŠŸç‡={success_rate:.1f}%, "
            f"æ€»è€—æ—¶={total_elapsed:.2f}s "
            f"(è·å–è·¯å¾„={source_elapsed:.2f}s, "
            f"è§£æ={parser_elapsed:.2f}s, "
            f"æ¸…ç†={clean_elapsed:.2f}s)"
        )
        
        return documents
        
    except Exception as e:
        logger.error(f"ä»æ•°æ®æºåŠ è½½æ–‡æ¡£å¤±è´¥: {e}")
        if show_progress:
            safe_print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        return []

