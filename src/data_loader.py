"""
æ•°æ®åŠ è½½å™¨æ¨¡å—
æ”¯æŒä»å¤šç§æ•°æ®æºåŠ è½½æ–‡æ¡£ï¼šMarkdownæ–‡ä»¶ã€ç½‘é¡µã€GitHubä»“åº“ç­‰
"""

import re
from pathlib import Path
from typing import List, Optional
from urllib.parse import urlparse

import requests
from bs4 import BeautifulSoup
from tqdm import tqdm
from llama_index.core import Document
from llama_index.core.schema import Document as LlamaDocument

try:
    from llama_index.readers.github import GithubRepositoryReader, GithubClient
except ImportError:
    GithubRepositoryReader = None
    GithubClient = None

from src.logger import setup_logger

# åˆ›å»ºæ—¥å¿—å™¨
logger = setup_logger('data_loader')


class MarkdownLoader:
    """Markdownæ–‡ä»¶åŠ è½½å™¨"""
    
    def __init__(self):
        self.supported_extensions = [".md", ".markdown"]
    
    def load_file(self, file_path: Path) -> Optional[LlamaDocument]:
        """åŠ è½½å•ä¸ªMarkdownæ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            LlamaDocumentå¯¹è±¡ï¼Œå¦‚æœåŠ è½½å¤±è´¥è¿”å›None
        """
        try:
            if not file_path.exists():
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
                
            if file_path.suffix.lower() not in self.supported_extensions:
                print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path.suffix}")
                return None
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–æ ‡é¢˜ä½œä¸ºæ–‡æ¡£æ ‡é¢˜ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            title = self._extract_title(content)
            if not title:
                title = file_path.stem
            
            # åˆ›å»ºDocumentå¯¹è±¡
            doc = LlamaDocument(
                text=content,
                metadata={
                    "file_path": str(file_path),
                    "file_name": file_path.name,
                    "title": title,
                    "source_type": "markdown",
                }
            )
            
            return doc
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None
    
    def load_directory(self, directory_path: Path, recursive: bool = True) -> List[LlamaDocument]:
        """åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰Markdownæ–‡ä»¶
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            recursive: æ˜¯å¦é€’å½’åŠ è½½å­ç›®å½•
            
        Returns:
            Documentå¯¹è±¡åˆ—è¡¨
        """
        documents = []
        
        if not directory_path.exists() or not directory_path.is_dir():
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨æˆ–ä¸æ˜¯æœ‰æ•ˆç›®å½•: {directory_path}")
            return documents
        
        # æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶
        pattern = "**/*" if recursive else "*"
        for ext in self.supported_extensions:
            for file_path in directory_path.glob(f"{pattern}{ext}"):
                if file_path.is_file():
                    doc = self.load_file(file_path)
                    if doc:
                        documents.append(doc)
                        print(f"âœ… å·²åŠ è½½: {file_path.name}")
        
        print(f"\nğŸ“š æ€»å…±åŠ è½½äº† {len(documents)} ä¸ªMarkdownæ–‡ä»¶")
        return documents
    
    def _extract_title(self, content: str) -> Optional[str]:
        """ä»Markdownå†…å®¹ä¸­æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜ï¼‰"""
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith('# '):
                return line[2:].strip()
        return None


class WebLoader:
    """ç½‘é¡µå†…å®¹åŠ è½½å™¨"""
    
    def __init__(self, timeout: int = 10):
        self.timeout = timeout
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
    
    def load_url(self, url: str) -> Optional[LlamaDocument]:
        """ä»URLåŠ è½½ç½‘é¡µå†…å®¹
        
        Args:
            url: ç½‘é¡µURL
            
        Returns:
            LlamaDocumentå¯¹è±¡ï¼Œå¦‚æœåŠ è½½å¤±è´¥è¿”å›None
        """
        try:
            # éªŒè¯URL
            parsed = urlparse(url)
            if not parsed.scheme or not parsed.netloc:
                print(f"âŒ æ— æ•ˆçš„URL: {url}")
                return None
            
            # å‘é€HTTPè¯·æ±‚
            response = requests.get(url, headers=self.headers, timeout=self.timeout)
            response.raise_for_status()
            
            # è§£æHTML
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
            for script in soup(["script", "style"]):
                script.decompose()
            
            # æå–æ–‡æœ¬å†…å®¹
            text = soup.get_text(separator='\n', strip=True)
            
            # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
            text = re.sub(r'\n\s*\n', '\n\n', text)
            
            # æå–æ ‡é¢˜
            title = soup.title.string if soup.title else parsed.netloc
            
            # åˆ›å»ºDocumentå¯¹è±¡
            doc = LlamaDocument(
                text=text,
                metadata={
                    "url": url,
                    "title": title,
                    "source_type": "web",
                    "domain": parsed.netloc,
                }
            )
            
            return doc
            
        except requests.RequestException as e:
            print(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥ {url}: {e}")
            return None
        except Exception as e:
            print(f"âŒ å¤„ç†ç½‘é¡µå¤±è´¥ {url}: {e}")
            return None
    
    def load_urls(self, urls: List[str]) -> List[LlamaDocument]:
        """æ‰¹é‡åŠ è½½å¤šä¸ªURL
        
        Args:
            urls: URLåˆ—è¡¨
            
        Returns:
            Documentå¯¹è±¡åˆ—è¡¨
        """
        documents = []
        
        for url in urls:
            doc = self.load_url(url)
            if doc:
                documents.append(doc)
                print(f"âœ… å·²åŠ è½½: {url}")
        
        print(f"\nğŸŒ æ€»å…±åŠ è½½äº† {len(documents)} ä¸ªç½‘é¡µ")
        return documents


class GithubLoader:
    """GitHubä»“åº“å†…å®¹åŠ è½½å™¨"""
    
    def __init__(self, github_token: Optional[str] = None):
        """åˆå§‹åŒ–GitHubåŠ è½½å™¨
        
        Args:
            github_token: GitHubè®¿é—®ä»¤ç‰Œï¼ˆå¯é€‰ï¼Œç”¨äºè®¿é—®ç§æœ‰ä»“åº“ï¼‰
        """
        if GithubRepositoryReader is None:
            raise ImportError(
                "éœ€è¦å®‰è£… llama-index-readers-github åŒ…ã€‚"
                "è¿è¡Œ: pip install llama-index-readers-github"
            )
        
        self.github_token = github_token
        self.github_client = GithubClient(github_token=github_token) if github_token else GithubClient()
    
    def load_repository(self, 
                       owner: str, 
                       repo: str, 
                       branch: Optional[str] = None,
                       show_progress: bool = True) -> List[LlamaDocument]:
        """ä»GitHubä»“åº“åŠ è½½æ–‡æ¡£
        
        Args:
            owner: ä»“åº“æ‰€æœ‰è€…
            repo: ä»“åº“åç§°
            branch: åˆ†æ”¯åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºä»“åº“é»˜è®¤åˆ†æ”¯ï¼‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            
        Returns:
            Documentå¯¹è±¡åˆ—è¡¨
        """
        try:
            branch = branch or "main"
            logger.info(f"å¼€å§‹åŠ è½½ GitHub ä»“åº“: {owner}/{repo}, åˆ†æ”¯: {branch}")
            
            if show_progress:
                print(f"ğŸ“¦ æ­£åœ¨ä» GitHub åŠ è½½ {owner}/{repo} (åˆ†æ”¯: {branch})...")
            
            # åˆ›å»º Reader
            reader = GithubRepositoryReader(
                github_client=self.github_client,
                owner=owner,
                repo=repo,
                use_parser=False,
                verbose=False,
            )
            
            # åŠ è½½æ–‡æ¡£
            documents = reader.load_data(branch=branch)
            
            if not documents:
                logger.warning(f"ä»“åº“ {owner}/{repo} æœªè¿”å›ä»»ä½•æ–‡æ¡£")
                print(f"âš ï¸  ä»“åº“ä¸ºç©ºæˆ–æ— å¯è¯»æ–‡ä»¶")
                return []
            
            # å¢å¼ºå…ƒæ•°æ®ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
            if show_progress:
                print(f"æ­£åœ¨å¤„ç† {len(documents)} ä¸ªæ–‡ä»¶...")
                iterator = tqdm(documents, desc="å¢å¼ºå…ƒæ•°æ®", unit="æ–‡ä»¶")
            else:
                iterator = documents
            
            for doc in iterator:
                if not doc.metadata:
                    doc.metadata = {}
                doc.metadata.update({
                    "source_type": "github",
                    "repository": f"{owner}/{repo}",
                    "branch": branch,
                })
            
            if show_progress:
                print(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡ä»¶")
            
            logger.info(f"æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡ä»¶ä» {owner}/{repo}")
            return documents
            
        except Exception as e:
            # è¯¦ç»†é”™è¯¯å¤„ç†
            error_msg = self._handle_error(e, owner, repo)
            logger.error(f"åŠ è½½å¤±è´¥ {owner}/{repo}: {error_msg}")
            return []
    
    def load_repositories(self, repo_configs: List[dict]) -> List[LlamaDocument]:
        """æ‰¹é‡åŠ è½½å¤šä¸ªGitHubä»“åº“
        
        Args:
            repo_configs: ä»“åº“é…ç½®åˆ—è¡¨ï¼Œæ¯ä¸ªé…ç½®åŒ…å« owner, repo, branch
            
        Returns:
            Documentå¯¹è±¡åˆ—è¡¨
        """
        all_documents = []
        
        for config in repo_configs:
            owner = config.get("owner")
            repo = config.get("repo")
            branch = config.get("branch")
            
            if not owner or not repo:
                print(f"âš ï¸  è·³è¿‡æ— æ•ˆé…ç½®: {config}")
                continue
            
            documents = self.load_repository(owner, repo, branch)
            all_documents.extend(documents)
        
        print(f"\nğŸ“š æ€»å…±ä» {len(repo_configs)} ä¸ªä»“åº“åŠ è½½äº† {len(all_documents)} ä¸ªæ–‡ä»¶")
        return all_documents
    
    def _handle_error(self, error: Exception, owner: str, repo: str) -> str:
        """ç»Ÿä¸€é”™è¯¯å¤„ç†
        
        Args:
            error: å¼‚å¸¸å¯¹è±¡
            owner: ä»“åº“æ‰€æœ‰è€…
            repo: ä»“åº“åç§°
            
        Returns:
            é”™è¯¯æè¿°å­—ç¬¦ä¸²
        """
        error_type = type(error).__name__
        error_str = str(error)
        
        # ç½‘ç»œç›¸å…³é”™è¯¯
        if isinstance(error, requests.Timeout):
            print(f"âŒ ç½‘ç»œè¶…æ—¶: {owner}/{repo}")
            print("   å»ºè®®ï¼š1) æ£€æŸ¥ç½‘ç»œè¿æ¥ 2) ç¨åé‡è¯•")
            return "ç½‘ç»œè¶…æ—¶"
        
        elif isinstance(error, requests.ConnectionError):
            print(f"âŒ ç½‘ç»œè¿æ¥å¤±è´¥")
            print("   å»ºè®®ï¼š1) æ£€æŸ¥ç½‘ç»œ 2) æ£€æŸ¥ä»£ç†è®¾ç½®")
            return "ç½‘ç»œè¿æ¥å¤±è´¥"
        
        # GitHub API é”™è¯¯ï¼ˆé€šè¿‡é”™è¯¯æ¶ˆæ¯åˆ¤æ–­ï¼‰
        elif "404" in error_str or "Not Found" in error_str:
            print(f"âŒ ä»“åº“ä¸å­˜åœ¨: {owner}/{repo}")
            print("   è¯·æ£€æŸ¥ï¼š1) ä»“åº“åæ‹¼å†™ 2) æ˜¯å¦ä¸ºç§æœ‰ä»“åº“ï¼ˆéœ€è¦Tokenï¼‰")
            return "ä»“åº“ä¸å­˜åœ¨(404)"
        
        elif "403" in error_str or "Forbidden" in error_str or "rate limit" in error_str.lower():
            print(f"âŒ è®¿é—®è¢«æ‹’ç»: {owner}/{repo}")
            print("   è¯·æ£€æŸ¥ï¼š1) Tokenæƒé™ 2) APIé™æµï¼ˆGitHubé™åˆ¶ï¼šæ¯å°æ—¶60æ¬¡ï¼‰")
            return "è®¿é—®è¢«æ‹’ç»(403)"
        
        elif "401" in error_str or "Unauthorized" in error_str or "Bad credentials" in error_str:
            print(f"âŒ è®¤è¯å¤±è´¥")
            print("   è¯·æ£€æŸ¥ï¼š1) Tokenæ˜¯å¦æ­£ç¡® 2) Tokenæ˜¯å¦è¿‡æœŸ")
            return "è®¤è¯å¤±è´¥(401)"
        
        # é€šç”¨é”™è¯¯
        else:
            print(f"âŒ æœªçŸ¥é”™è¯¯: {error_type}: {error}")
            print(f"   è¯·æŠ¥å‘Šæ­¤é—®é¢˜åˆ°é¡¹ç›® Issue")
            return f"{error_type}: {error_str}"


class DocumentProcessor:
    """æ–‡æ¡£é¢„å¤„ç†å™¨"""
    
    @staticmethod
    def clean_text(text: str) -> str:
        """æ¸…ç†æ–‡æœ¬å†…å®¹
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'[ \t]+', ' ', text)
        
        # ç§»é™¤è¡Œé¦–è¡Œå°¾ç©ºç™½
        lines = [line.strip() for line in text.split('\n')]
        
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œï¼ˆä¿ç•™æœ€å¤šä¸€ä¸ªç©ºè¡Œï¼Œå³æœ€å¤šä¸¤ä¸ªè¿ç»­æ¢è¡Œï¼‰
        cleaned_lines = []
        prev_empty = False
        for line in lines:
            if line:  # éç©ºè¡Œ
                cleaned_lines.append(line)
                prev_empty = False
            else:  # ç©ºè¡Œ
                if not prev_empty:  # åªä¿ç•™ç¬¬ä¸€ä¸ªç©ºè¡Œ
                    cleaned_lines.append(line)
                    prev_empty = True
                # è¿ç»­çš„ç©ºè¡Œè·³è¿‡
        
        text = '\n'.join(cleaned_lines)
        return text.strip()
    
    @staticmethod
    def enrich_metadata(document: LlamaDocument, additional_metadata: dict) -> LlamaDocument:
        """ä¸ºæ–‡æ¡£æ·»åŠ é¢å¤–çš„å…ƒæ•°æ®
        
        Args:
            document: åŸå§‹æ–‡æ¡£
            additional_metadata: è¦æ·»åŠ çš„å…ƒæ•°æ®
            
        Returns:
            æ›´æ–°åçš„æ–‡æ¡£
        """
        document.metadata.update(additional_metadata)
        return document
    
    @staticmethod
    def filter_by_length(documents: List[LlamaDocument], 
                        min_length: int = 50) -> List[LlamaDocument]:
        """è¿‡æ»¤æ‰å¤ªçŸ­çš„æ–‡æ¡£
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            min_length: æœ€å°é•¿åº¦
            
        Returns:
            è¿‡æ»¤åçš„æ–‡æ¡£åˆ—è¡¨
        """
        filtered = [doc for doc in documents if len(doc.text) >= min_length]
        
        removed_count = len(documents) - len(filtered)
        if removed_count > 0:
            print(f"âš ï¸  è¿‡æ»¤æ‰ {removed_count} ä¸ªè¿‡çŸ­çš„æ–‡æ¡£")
        
        return filtered


# ä¾¿æ·å‡½æ•°
def load_documents_from_directory(directory_path: str | Path, 
                                 recursive: bool = True,
                                 clean: bool = True) -> List[LlamaDocument]:
    """ä»ç›®å½•åŠ è½½æ‰€æœ‰Markdownæ–‡æ¡£ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Args:
        directory_path: ç›®å½•è·¯å¾„
        recursive: æ˜¯å¦é€’å½’åŠ è½½
        clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
        
    Returns:
        Documentå¯¹è±¡åˆ—è¡¨
    """
    directory_path = Path(directory_path)
    loader = MarkdownLoader()
    documents = loader.load_directory(directory_path, recursive=recursive)
    
    if clean:
        processor = DocumentProcessor()
        # Document.text æ˜¯åªè¯»å±æ€§ï¼Œéœ€è¦åˆ›å»ºæ–°çš„ Document å¯¹è±¡
        cleaned_documents = []
        for doc in documents:
            cleaned_text = processor.clean_text(doc.text)
            cleaned_doc = LlamaDocument(
                text=cleaned_text,
                metadata=doc.metadata,
                id_=doc.id_
            )
            cleaned_documents.append(cleaned_doc)
        return cleaned_documents
    
    return documents


def load_documents_from_urls(urls: List[str], clean: bool = True) -> List[LlamaDocument]:
    """ä»URLåˆ—è¡¨åŠ è½½æ–‡æ¡£ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Args:
        urls: URLåˆ—è¡¨
        clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
        
    Returns:
        Documentå¯¹è±¡åˆ—è¡¨
    """
    loader = WebLoader()
    documents = loader.load_urls(urls)
    
    if clean:
        processor = DocumentProcessor()
        # Document.text æ˜¯åªè¯»å±æ€§ï¼Œéœ€è¦åˆ›å»ºæ–°çš„ Document å¯¹è±¡
        cleaned_documents = []
        for doc in documents:
            cleaned_text = processor.clean_text(doc.text)
            cleaned_doc = LlamaDocument(
                text=cleaned_text,
                metadata=doc.metadata,
                id_=doc.id_
            )
            cleaned_documents.append(cleaned_doc)
        return cleaned_documents
    
    return documents


def load_documents_from_github(owner: str,
                               repo: str,
                               branch: Optional[str] = None,
                               github_token: Optional[str] = None,
                               clean: bool = True,
                               show_progress: bool = True) -> List[LlamaDocument]:
    """ä»GitHubä»“åº“åŠ è½½æ–‡æ¡£ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Args:
        owner: ä»“åº“æ‰€æœ‰è€…
        repo: ä»“åº“åç§°
        branch: åˆ†æ”¯åç§°ï¼ˆå¯é€‰ï¼‰
        github_token: GitHubè®¿é—®ä»¤ç‰Œï¼ˆå¯é€‰ï¼‰
        clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        
    Returns:
        Documentå¯¹è±¡åˆ—è¡¨
    """
    loader = GithubLoader(github_token=github_token)
    documents = loader.load_repository(owner, repo, branch, show_progress=show_progress)
    
    if clean and documents:
        processor = DocumentProcessor()
        cleaned_documents = []
        for doc in documents:
            cleaned_text = processor.clean_text(doc.text)
            cleaned_doc = LlamaDocument(
                text=cleaned_text,
                metadata=doc.metadata,
                id_=doc.id_
            )
            cleaned_documents.append(cleaned_doc)
        return cleaned_documents
    
    return documents


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    from src.config import config
    
    print("=== æµ‹è¯•MarkdownåŠ è½½å™¨ ===")
    documents = load_documents_from_directory(config.RAW_DATA_PATH)
    print(f"åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")
    
    if documents:
        print("\nç¬¬ä¸€ä¸ªæ–‡æ¡£é¢„è§ˆ:")
        print(f"æ ‡é¢˜: {documents[0].metadata.get('title')}")
        print(f"å†…å®¹é•¿åº¦: {len(documents[0].text)}")
        print(f"å†…å®¹é¢„è§ˆ: {documents[0].text[:200]}...")

