"""
æ•°æ®åŠ è½½å™¨æ¨¡å—
ä½¿ç”¨ LlamaIndex å®˜æ–¹ Reader ç»„ä»¶ï¼Œæ”¯æŒä»å¤šç§æ•°æ®æºåŠ è½½æ–‡æ¡£
"""

import os
import re
from pathlib import Path
from typing import List, Optional

from tqdm import tqdm
from llama_index.core import SimpleDirectoryReader
from llama_index.core.schema import Document as LlamaDocument

try:
    from llama_index.readers.web import SimpleWebPageReader
except ImportError:
    SimpleWebPageReader = None

try:
    from llama_index.readers.github import GithubRepositoryReader, GithubClient
except ImportError:
    GithubRepositoryReader = None
    GithubClient = None

try:
    from llama_index.readers.wikipedia import WikipediaReader
except ImportError:
    WikipediaReader = None

from src.logger import setup_logger

# åˆ›å»ºæ—¥å¿—å™¨
logger = setup_logger('data_loader')


def safe_print(text: str):
    """å®‰å…¨æ‰“å°ï¼ˆå¤„ç†ç¼–ç é—®é¢˜ï¼‰"""
    try:
        print(text)
    except UnicodeEncodeError:
        # åœ¨ Windows GBK ç¼–ç ä¸‹ï¼Œå›é€€åˆ° ASCII å‹å¥½çš„è¾“å‡º
        text = text.encode('ascii', 'replace').decode('ascii')
        print(text)


class DocumentProcessor:
    """æ–‡æ¡£é¢„å¤„ç†å™¨"""
    
    @staticmethod
    def clean_text(text: str) -> str:
        """æ¸…ç†æ–‡æœ¬å†…å®¹
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'[ \t]+', ' ', text)
        
        # ç§»é™¤è¡Œé¦–è¡Œå°¾ç©ºç™½
        lines = [line.strip() for line in text.split('\n')]
        
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œï¼ˆä¿ç•™æœ€å¤šä¸€ä¸ªç©ºè¡Œï¼Œå³æœ€å¤šä¸¤ä¸ªè¿ç»­æ¢è¡Œï¼‰
        cleaned_lines = []
        prev_empty = False
        for line in lines:
            if line:  # éç©ºè¡Œ
                cleaned_lines.append(line)
                prev_empty = False
            else:  # ç©ºè¡Œ
                if not prev_empty:  # åªä¿ç•™ç¬¬ä¸€ä¸ªç©ºè¡Œ
                    cleaned_lines.append(line)
                    prev_empty = True
                # è¿ç»­çš„ç©ºè¡Œè·³è¿‡
        
        text = '\n'.join(cleaned_lines)
        return text.strip()
    
    @staticmethod
    def enrich_metadata(document: LlamaDocument, additional_metadata: dict) -> LlamaDocument:
        """ä¸ºæ–‡æ¡£æ·»åŠ é¢å¤–çš„å…ƒæ•°æ®
        
        Args:
            document: åŸå§‹æ–‡æ¡£
            additional_metadata: è¦æ·»åŠ çš„å…ƒæ•°æ®
            
        Returns:
            æ›´æ–°åçš„æ–‡æ¡£
        """
        document.metadata.update(additional_metadata)
        return document
    
    @staticmethod
    def filter_by_length(documents: List[LlamaDocument], 
                        min_length: int = 50) -> List[LlamaDocument]:
        """è¿‡æ»¤æ‰å¤ªçŸ­çš„æ–‡æ¡£
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            min_length: æœ€å°é•¿åº¦
            
        Returns:
            è¿‡æ»¤åçš„æ–‡æ¡£åˆ—è¡¨
        """
        filtered = [doc for doc in documents if len(doc.text) >= min_length]
        
        removed_count = len(documents) - len(filtered)
        if removed_count > 0:
            safe_print(f"âš ï¸  è¿‡æ»¤æ‰ {removed_count} ä¸ªè¿‡çŸ­çš„æ–‡æ¡£")
        
        return filtered
    
    @staticmethod
    def extract_title_from_markdown(content: str) -> Optional[str]:
        """ä»Markdownå†…å®¹ä¸­æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜ï¼‰
        
        Args:
            content: Markdown æ–‡æœ¬å†…å®¹
            
        Returns:
            æå–çš„æ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å› None
        """
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith('# '):
                return line[2:].strip()
        return None


def load_documents_from_directory(directory_path: str | Path, 
                                 recursive: bool = True,
                                 clean: bool = True,
                                 required_exts: Optional[List[str]] = None) -> List[LlamaDocument]:
    """ä»ç›®å½•åŠ è½½æ‰€æœ‰æ–‡æ¡£ï¼ˆä½¿ç”¨å®˜æ–¹ SimpleDirectoryReaderï¼‰
    
    Args:
        directory_path: ç›®å½•è·¯å¾„
        recursive: æ˜¯å¦é€’å½’åŠ è½½
        clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
        required_exts: æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ï¼ˆé»˜è®¤ï¼š[".md", ".markdown"]ï¼‰
        
    Returns:
        Documentå¯¹è±¡åˆ—è¡¨
    """
    directory_path = Path(directory_path)
    required_exts = required_exts or [".md", ".markdown"]
    
    # éªŒè¯ç›®å½•
    if not directory_path.exists() or not directory_path.is_dir():
        safe_print(f"âŒ ç›®å½•ä¸å­˜åœ¨æˆ–ä¸æ˜¯æœ‰æ•ˆç›®å½•: {directory_path}")
        logger.error(f"ç›®å½•ä¸å­˜åœ¨: {directory_path}")
        return []
    
    try:
        logger.info(f"å¼€å§‹åŠ è½½ç›®å½•: {directory_path}, é€’å½’: {recursive}")
        
        # ä½¿ç”¨ SimpleDirectoryReader åŠ è½½æ–‡æ¡£
        reader = SimpleDirectoryReader(
            input_dir=str(directory_path),
            recursive=recursive,
            required_exts=required_exts,
            filename_as_id=True,
            errors='ignore',  # å¿½ç•¥ä¸å¯è¯»æ–‡ä»¶
        )
        
        documents = reader.load_data()
        
        if not documents:
            safe_print(f"âš ï¸  æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£ï¼ˆæ”¯æŒæ ¼å¼ï¼š{', '.join(required_exts)}ï¼‰")
            logger.warning(f"ç›®å½•ä¸ºç©º: {directory_path}")
            return []
        
        # å¢å¼ºå…ƒæ•°æ®
        for doc in documents:
            # æå–æ–‡ä»¶è·¯å¾„ä¿¡æ¯
            file_path = doc.metadata.get('file_path', '')
            file_name = doc.metadata.get('file_name', '')
            
            # ä¸º Markdown æ–‡ä»¶æå–æ ‡é¢˜
            if any(file_name.endswith(ext) for ext in ['.md', '.markdown']):
                title = DocumentProcessor.extract_title_from_markdown(doc.text)
                if not title:
                    title = Path(file_name).stem if file_name else "æœªå‘½å"
                
                doc.metadata.update({
                    "title": title,
                    "source_type": "markdown",
                })
            
            # ç¡®ä¿åŸºç¡€å…ƒæ•°æ®å­˜åœ¨
            if not doc.metadata.get('file_path'):
                doc.metadata['file_path'] = file_path
            if not doc.metadata.get('file_name'):
                doc.metadata['file_name'] = file_name
            
            # è¾“å‡ºåŠ è½½è¿›åº¦
            safe_print(f"âœ… å·²åŠ è½½: {file_name}")
        
        safe_print(f"\nğŸ“š æ€»å…±åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")
        logger.info(f"æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        
        # å¯é€‰çš„æ–‡æœ¬æ¸…ç†
        if clean:
            processor = DocumentProcessor()
            cleaned_documents = []
            for doc in documents:
                cleaned_text = processor.clean_text(doc.text)
                cleaned_doc = LlamaDocument(
                    text=cleaned_text,
                    metadata=doc.metadata,
                    id_=doc.id_
                )
                cleaned_documents.append(cleaned_doc)
            return cleaned_documents
        
        return documents
        
    except Exception as e:
        safe_print(f"âŒ åŠ è½½ç›®å½•å¤±è´¥: {e}")
        logger.error(f"åŠ è½½ç›®å½•å¤±è´¥ {directory_path}: {e}")
        return []


def load_documents_from_urls(urls: List[str], 
                            clean: bool = True) -> List[LlamaDocument]:
    """ä»URLåˆ—è¡¨åŠ è½½æ–‡æ¡£ï¼ˆä½¿ç”¨å®˜æ–¹ SimpleWebPageReaderï¼‰
    
    Args:
        urls: URLåˆ—è¡¨
        clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
        
    Returns:
        Documentå¯¹è±¡åˆ—è¡¨
    """
    if SimpleWebPageReader is None:
        safe_print("âŒ ç¼ºå°‘ä¾èµ–ï¼šllama-index-readers-web")
        safe_print("   å®‰è£…ï¼špip install llama-index-readers-web")
        logger.error("SimpleWebPageReader æœªå®‰è£…")
        return []
    
    if not urls:
        safe_print("âš ï¸  URL åˆ—è¡¨ä¸ºç©º")
        return []
    
    try:
        logger.info(f"å¼€å§‹åŠ è½½ {len(urls)} ä¸ªç½‘é¡µ")
        
        # ä½¿ç”¨ SimpleWebPageReader åŠ è½½ç½‘é¡µ
        reader = SimpleWebPageReader(html_to_text=True)
        documents = reader.load_data(urls)
        
        if not documents:
            safe_print("âš ï¸  æœªæˆåŠŸåŠ è½½ä»»ä½•ç½‘é¡µ")
            logger.warning("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•ç½‘é¡µ")
            return []
        
        # å¢å¼ºå…ƒæ•°æ®
        for i, doc in enumerate(documents):
            url = urls[i] if i < len(urls) else "unknown"
            
            # ç¡®ä¿æœ‰ source_type
            doc.metadata.update({
                "source_type": "web",
                "url": url,
            })
            
            safe_print(f"âœ… å·²åŠ è½½: {url}")
        
        safe_print(f"\nğŸŒ æ€»å…±åŠ è½½äº† {len(documents)} ä¸ªç½‘é¡µ")
        logger.info(f"æˆåŠŸåŠ è½½ {len(documents)} ä¸ªç½‘é¡µ")
        
        # å¯é€‰çš„æ–‡æœ¬æ¸…ç†
        if clean:
            processor = DocumentProcessor()
            cleaned_documents = []
            for doc in documents:
                cleaned_text = processor.clean_text(doc.text)
                cleaned_doc = LlamaDocument(
                    text=cleaned_text,
                    metadata=doc.metadata,
                    id_=doc.id_
                )
                cleaned_documents.append(cleaned_doc)
            return cleaned_documents
        
        return documents
        
    except Exception as e:
        safe_print(f"âŒ åŠ è½½ç½‘é¡µå¤±è´¥: {e}")
        logger.error(f"åŠ è½½ç½‘é¡µå¤±è´¥: {e}")
        return []


def load_documents_from_github(owner: str,
                               repo: str,
                               branch: Optional[str] = None,
                               github_token: Optional[str] = None,
                               clean: bool = True,
                               show_progress: bool = True,
                               filter_directories: Optional[List[str]] = None,
                               filter_file_extensions: Optional[List[str]] = None) -> List[LlamaDocument]:
    """ä»GitHubä»“åº“åŠ è½½æ–‡æ¡£ï¼ˆä½¿ç”¨å®˜æ–¹ GithubRepositoryReaderï¼‰
    
    Args:
        owner: ä»“åº“æ‰€æœ‰è€…
        repo: ä»“åº“åç§°
        branch: åˆ†æ”¯åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ mainï¼‰
        github_token: GitHubè®¿é—®ä»¤ç‰Œï¼ˆå¯é€‰ï¼Œæœªæä¾›åˆ™å°è¯•ä»ç¯å¢ƒå˜é‡ GITHUB_TOKEN è·å–ï¼‰
        clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        filter_directories: åªåŠ è½½æŒ‡å®šç›®å½•ï¼ˆåˆ—è¡¨æ ¼å¼ï¼Œå¦‚ ["docs", "examples"]ï¼‰
        filter_file_extensions: åªåŠ è½½æŒ‡å®šæ‰©å±•åï¼ˆåˆ—è¡¨æ ¼å¼ï¼Œå¦‚ [".md", ".py"]ï¼‰
                               é»˜è®¤æ’é™¤å›¾ç‰‡ã€äºŒè¿›åˆ¶ç­‰æ–‡ä»¶
        
    Returns:
        Documentå¯¹è±¡åˆ—è¡¨
        
    Notes:
        - å…¬å¼€ä»“åº“æ— éœ€ tokenï¼Œä½†é…ç½® token å¯æé«˜ API é™é¢ï¼ˆ60æ¬¡/å°æ—¶ â†’ 5000æ¬¡/å°æ—¶ï¼‰
        - filter å‚æ•°å†…éƒ¨ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºå®˜æ–¹ API è¦æ±‚çš„å…ƒç»„æ ¼å¼
        - é»˜è®¤ä¼šè¿‡æ»¤æ‰å›¾ç‰‡ã€å‹ç¼©åŒ…ç­‰äºŒè¿›åˆ¶æ–‡ä»¶
    """
    if GithubRepositoryReader is None or GithubClient is None:
        safe_print("âŒ ç¼ºå°‘ä¾èµ–ï¼šllama-index-readers-github")
        safe_print("   å®‰è£…ï¼špip install llama-index-readers-github")
        logger.error("GithubRepositoryReader æœªå®‰è£…")
        return []
    
    try:
        branch = branch or "main"
        logger.info(f"å¼€å§‹åŠ è½½ GitHub ä»“åº“: {owner}/{repo}, åˆ†æ”¯: {branch}")
        
        if show_progress:
            safe_print(f"ğŸ“¦ æ­£åœ¨ä» GitHub åŠ è½½ {owner}/{repo} (åˆ†æ”¯: {branch})...")
        
        # åˆ›å»º GitHub å®¢æˆ·ç«¯
        # GitHub Token æ˜¯ç”¨æˆ·çº§åˆ«çš„é…ç½®ï¼Œå¿…é¡»é€šè¿‡å‚æ•°ä¼ é€’
        if not github_token:
            error_msg = (
                "éœ€è¦æä¾› GitHub Tokenã€‚\n"
                "è¯·åœ¨ Web ç•Œé¢çš„ 'ğŸ”‘ GitHub Token é…ç½®' ä¸­ä¿å­˜æ‚¨çš„ Tokenã€‚\n"
                "è·å– Tokenï¼šhttps://github.com/settings/tokens\n"
                "æƒé™è®¾ç½®ï¼šå…¬å¼€ä»“åº“æ— éœ€å‹¾é€‰ä»»ä½•æƒé™ï¼Œç§æœ‰ä»“åº“å‹¾é€‰ 'repo'"
            )
            if show_progress:
                safe_print(f"âŒ {error_msg}")
            raise ValueError(error_msg)
        
        # ä½¿ç”¨ç”¨æˆ·æä¾›çš„ Token åˆ›å»ºå®¢æˆ·ç«¯
        github_client = GithubClient(github_token=github_token, verbose=False)
        if show_progress:
            safe_print(f"âœ… ä½¿ç”¨ç”¨æˆ·çš„ GitHub Tokenï¼ˆAPI é™é¢ï¼š5000æ¬¡/å°æ—¶ï¼‰")
        
        # å¦‚æœæœªæŒ‡å®šæ–‡ä»¶æ‰©å±•åï¼Œä½¿ç”¨é»˜è®¤çš„æ–‡æœ¬æ–‡ä»¶åˆ—è¡¨
        # æ³¨æ„ï¼šæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œfilter å‚æ•°æ ¼å¼ä¸ºå…ƒç»„ (åˆ—è¡¨, FilterType)
        if filter_file_extensions is None:
            # é»˜è®¤æ’é™¤å›¾ç‰‡ã€äºŒè¿›åˆ¶ç­‰æ–‡ä»¶
            filter_file_extensions = (
                ['.png', '.jpg', '.jpeg', '.gif', '.svg', '.ico', '.pdf', '.zip', '.tar', '.gz', 
                 '.exe', '.dll', '.so', '.dylib', '.bin', '.dat', '.pyc', '.pyo', '.lock'],
                GithubRepositoryReader.FilterType.EXCLUDE,
            )
        elif isinstance(filter_file_extensions, list):
            # å¦‚æœä¼ å…¥çš„æ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºå…ƒç»„æ ¼å¼ï¼ˆé»˜è®¤ä¸º INCLUDEï¼‰
            filter_file_extensions = (filter_file_extensions, GithubRepositoryReader.FilterType.INCLUDE)
        
        # filter_directories åŒæ ·éœ€è¦å…ƒç»„æ ¼å¼
        if filter_directories is not None and isinstance(filter_directories, list):
            filter_directories = (filter_directories, GithubRepositoryReader.FilterType.INCLUDE)
        
        # ä½¿ç”¨ GithubRepositoryReader åŠ è½½ä»“åº“
        reader = GithubRepositoryReader(
            github_client=github_client,
            owner=owner,
            repo=repo,
            use_parser=False,
            verbose=False,
            filter_directories=filter_directories,
            filter_file_extensions=filter_file_extensions,
        )
        
        # å°è¯•åŠ è½½æŒ‡å®šåˆ†æ”¯
        try:
            documents = reader.load_data(branch=branch)
        except Exception as e:
            error_str = str(e)
            # å¦‚æœæ˜¯ main åˆ†æ”¯ä¸å­˜åœ¨ï¼Œå°è¯• master
            if "404" in error_str and branch == "main":
                logger.info("main åˆ†æ”¯ä¸å­˜åœ¨ï¼Œå°è¯• master åˆ†æ”¯")
                if show_progress:
                    safe_print("âš ï¸  main åˆ†æ”¯ä¸å­˜åœ¨ï¼Œå°è¯• master åˆ†æ”¯...")
                branch = "master"
                documents = reader.load_data(branch=branch)
            else:
                raise
        
        if not documents:
            logger.warning(f"ä»“åº“ {owner}/{repo} æ²¡æœ‰æ–‡æ¡£")
            if show_progress:
                safe_print(f"âš ï¸  ä»“åº“ä¸ºç©ºæˆ–æ²¡æœ‰æ”¯æŒçš„æ–‡ä»¶ç±»å‹")
            return []
        
        if show_progress:
            safe_print(f"æ‰¾åˆ° {len(documents)} ä¸ªæ–‡ä»¶")
        
        # å¢å¼ºå…ƒæ•°æ®å¹¶æ˜¾ç¤ºè¿›åº¦
        iterator = tqdm(documents, desc="å¤„ç†æ–‡ä»¶", unit="ä¸ª") if show_progress else documents
        
        processed_docs = []
        for doc in iterator:
            # è·å–æ–‡ä»¶è·¯å¾„
            file_path = doc.metadata.get('file_path', '')
            file_name = doc.metadata.get('file_name', file_path.split('/')[-1] if file_path else 'unknown')
            
            # å¢å¼ºå…ƒæ•°æ®
            doc.metadata.update({
                "source_type": "github",
                "repository": f"{owner}/{repo}",
                "branch": branch,
                "url": f"https://github.com/{owner}/{repo}/blob/{branch}/{file_path}",
            })
            
            # ç¡®ä¿åŸºç¡€å…ƒæ•°æ®å­˜åœ¨
            if not doc.metadata.get('file_name'):
                doc.metadata['file_name'] = file_name
            
            processed_docs.append(doc)
        
        if show_progress:
            safe_print(f"âœ… æˆåŠŸåŠ è½½ {len(processed_docs)} ä¸ªæ–‡ä»¶")
        
        logger.info(f"æˆåŠŸåŠ è½½ {len(processed_docs)} ä¸ªæ–‡ä»¶ä» {owner}/{repo}")
        
        # å¯é€‰çš„æ–‡æœ¬æ¸…ç†
        if clean:
            processor = DocumentProcessor()
            cleaned_documents = []
            for doc in processed_docs:
                cleaned_text = processor.clean_text(doc.text)
                cleaned_doc = LlamaDocument(
                    text=cleaned_text,
                    metadata=doc.metadata,
                    id_=doc.id_
                )
                cleaned_documents.append(cleaned_doc)
            return cleaned_documents
        
        return processed_docs
        
    except Exception as e:
        error_msg = _handle_github_error(e, owner, repo, show_progress)
        # å®‰å…¨è®°å½•æ—¥å¿—ï¼ˆå¤„ç† Unicode ç¼–ç é—®é¢˜ï¼‰
        try:
            logger.error(f"åŠ è½½å¤±è´¥ {owner}/{repo}: {error_msg}")
        except UnicodeEncodeError:
            # å¦‚æœç¼–ç å¤±è´¥ï¼Œä½¿ç”¨ ASCII å®‰å…¨çš„æ ¼å¼
            safe_error_msg = error_msg.encode('ascii', 'replace').decode('ascii')
            logger.error(f"åŠ è½½å¤±è´¥ {owner}/{repo}: {safe_error_msg}")
        return []


def sync_github_repository(
    owner: str,
    repo: str,
    branch: str,
    metadata_manager,
    github_token: Optional[str] = None,
    show_progress: bool = True,
    filter_directories: Optional[List[str]] = None,
    filter_file_extensions: Optional[List[str]] = None
) -> tuple:
    """å¢é‡åŒæ­¥ GitHub ä»“åº“
    
    Args:
        owner: ä»“åº“æ‰€æœ‰è€…
        repo: ä»“åº“åç§°
        branch: åˆ†æ”¯åç§°
        metadata_manager: å…ƒæ•°æ®ç®¡ç†å™¨å®ä¾‹
        github_token: GitHubè®¿é—®ä»¤ç‰Œï¼ˆå¯é€‰ï¼‰
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        filter_directories: åªåŠ è½½æŒ‡å®šç›®å½•ï¼ˆå¯é€‰ï¼‰
        filter_file_extensions: åªåŠ è½½æŒ‡å®šæ‰©å±•åï¼ˆå¯é€‰ï¼‰
        
    Returns:
        (æ‰€æœ‰æ–‡æ¡£åˆ—è¡¨, FileChangeå¯¹è±¡)
    """
    from src.metadata_manager import FileChange
    
    # 1. åŠ è½½å½“å‰ä»“åº“çš„æ‰€æœ‰æ–‡æ¡£
    documents = load_documents_from_github(
        owner=owner,
        repo=repo,
        branch=branch,
        github_token=github_token,
        clean=True,
        show_progress=show_progress,
        filter_directories=filter_directories,
        filter_file_extensions=filter_file_extensions
    )
    
    if not documents:
        logger.warning(f"æœªèƒ½åŠ è½½ä»»ä½•æ–‡æ¡£ä» {owner}/{repo}")
        return [], FileChange()
    
    # 2. æ£€æµ‹å˜æ›´
    if show_progress:
        safe_print(f"\nğŸ” æ­£åœ¨æ£€æµ‹å˜æ›´...")
    
    changes = metadata_manager.detect_changes(owner, repo, branch, documents)
    
    if show_progress:
        if changes.has_changes():
            safe_print(f"ğŸ“Š æ£€æµ‹ç»“æœ: {changes.summary()}")
        else:
            safe_print(f"âœ… æ²¡æœ‰æ£€æµ‹åˆ°å˜æ›´")
    
    return documents, changes


def _handle_github_error(error: Exception, owner: str, repo: str, show_progress: bool = True) -> str:
    """ç»Ÿä¸€ GitHub é”™è¯¯å¤„ç†
    
    Args:
        error: å¼‚å¸¸å¯¹è±¡
        owner: ä»“åº“æ‰€æœ‰è€…
        repo: ä»“åº“åç§°
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†é”™è¯¯æç¤º
        
    Returns:
        é”™è¯¯æè¿°å­—ç¬¦ä¸²ï¼ˆASCII å®‰å…¨ï¼‰
    """
    error_type = type(error).__name__
    error_str = str(error)
    
    # å¤„ç† UnicodeEncodeErrorï¼šå®‰å…¨è½¬æ¢é”™è¯¯æ¶ˆæ¯
    try:
        # å°è¯•ä½¿ç”¨åŸå§‹é”™è¯¯æ¶ˆæ¯
        _ = error_str.encode('ascii')
    except UnicodeEncodeError:
        # å¦‚æœåŒ…å«é ASCII å­—ç¬¦ï¼Œè¿›è¡Œè½¬æ¢
        error_str = error_str.encode('ascii', 'replace').decode('ascii')
    
    if not show_progress:
        return f"{error_type}: {error_str}"
    
    # GitHub API é”™è¯¯
    if "404" in error_str or "Not Found" in error_str:
        safe_print(f"âŒ ä»“åº“ä¸å­˜åœ¨: {owner}/{repo}")
        safe_print("   è¯·æ£€æŸ¥ï¼š1) ä»“åº“åæ‹¼å†™ 2) æ˜¯å¦ä¸ºç§æœ‰ä»“åº“ï¼ˆéœ€è¦Tokenï¼‰")
        return "ä»“åº“ä¸å­˜åœ¨(404)"
    
    elif "403" in error_str or "Forbidden" in error_str or "rate limit" in error_str.lower():
        safe_print(f"âŒ è®¿é—®è¢«æ‹’ç»: {owner}/{repo}")
        safe_print("   è¯·æ£€æŸ¥ï¼š1) Tokenæƒé™ 2) APIé™æµï¼ˆGitHubé™åˆ¶ï¼šæ¯å°æ—¶60æ¬¡ï¼Œæœ‰Tokenä¸º5000æ¬¡ï¼‰")
        safe_print("   å»ºè®®ï¼šé…ç½® GITHUB_TOKEN ç¯å¢ƒå˜é‡ä»¥æé«˜é™é¢")
        return "è®¿é—®è¢«æ‹’ç»(403)"
    
    elif "401" in error_str or "Unauthorized" in error_str or "Bad credentials" in error_str:
        safe_print(f"âŒ è®¤è¯å¤±è´¥")
        safe_print("   è¯·æ£€æŸ¥ï¼š1) Tokenæ˜¯å¦æ­£ç¡® 2) Tokenæ˜¯å¦è¿‡æœŸ")
        return "è®¤è¯å¤±è´¥(401)"
    
    # ç½‘ç»œç›¸å…³é”™è¯¯
    elif "timeout" in error_str.lower() or "timed out" in error_str.lower():
        safe_print(f"âŒ ç½‘ç»œè¶…æ—¶: {owner}/{repo}")
        safe_print("   å»ºè®®ï¼š1) æ£€æŸ¥ç½‘ç»œè¿æ¥ 2) ç¨åé‡è¯•")
        return "ç½‘ç»œè¶…æ—¶"
    
    elif "connection" in error_str.lower():
        safe_print(f"âŒ ç½‘ç»œè¿æ¥å¤±è´¥")
        safe_print("   å»ºè®®ï¼š1) æ£€æŸ¥ç½‘ç»œ 2) æ£€æŸ¥ä»£ç†è®¾ç½®")
        return "ç½‘ç»œè¿æ¥å¤±è´¥"
    
    # é€šç”¨é”™è¯¯
    else:
        safe_print(f"âŒ åŠ è½½å¤±è´¥: {error_type}: {error}")
        safe_print(f"   å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·æŠ¥å‘Šåˆ°é¡¹ç›® Issue")
        return f"{error_type}: {error_str}"


def parse_github_url(url: str) -> Optional[dict]:
    """è§£æ GitHub URL è·å–ä»“åº“ä¿¡æ¯
    
    æ”¯æŒçš„æ ¼å¼ï¼š
    - https://github.com/owner/repo
    - github.com/owner/repo
    - http://github.com/owner/repo
    - https://github.com/owner/repo/tree/branch
    
    Args:
        url: GitHub URL
        
    Returns:
        åŒ…å« owner, repo, branch çš„å­—å…¸ï¼Œè§£æå¤±è´¥è¿”å› None
    """
    from urllib.parse import urlparse
    
    try:
        # æ¸…ç† URL
        url = url.strip()
        
        # å¦‚æœæ²¡æœ‰åè®®ï¼Œè‡ªåŠ¨æ·»åŠ  https://
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        
        # è§£æ URL
        parsed = urlparse(url)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ GitHub
        if 'github.com' not in parsed.netloc:
            logger.warning(f"ä¸æ˜¯æœ‰æ•ˆçš„ GitHub URL: {url}")
            return None
        
        # è§£æè·¯å¾„: /owner/repo æˆ– /owner/repo/tree/branch
        path_parts = [p for p in parsed.path.split('/') if p]
        
        if len(path_parts) < 2:
            logger.warning(f"URL è·¯å¾„ä¸å®Œæ•´: {url}")
            return None
        
        owner = path_parts[0]
        repo = path_parts[1]
        
        # ç§»é™¤ .git åç¼€ï¼ˆå¦‚æœæœ‰ï¼‰
        if repo.endswith('.git'):
            repo = repo[:-4]
        
        # æå–åˆ†æ”¯ï¼ˆå¦‚æœ URL ä¸­åŒ…å« /tree/branchï¼‰
        branch = None
        if len(path_parts) >= 4 and path_parts[2] == 'tree':
            branch = path_parts[3]
        
        result = {
            'owner': owner,
            'repo': repo,
            'branch': branch or 'main'  # é»˜è®¤ä½¿ç”¨ main åˆ†æ”¯
        }
        
        logger.info(f"è§£æ GitHub URL æˆåŠŸ: {result}")
        return result
        
    except Exception as e:
        logger.error(f"è§£æ GitHub URL å¤±è´¥: {e}")
        return None


def load_documents_from_github_url(
    github_url: str,
    github_token: Optional[str] = None,
    clean: bool = True,
    show_progress: bool = True
) -> List[LlamaDocument]:
    """ä» GitHub URL åŠ è½½æ–‡æ¡£ï¼ˆéœ€è¦æä¾› Tokenï¼‰
    
    Args:
        github_url: GitHub ä»“åº“ URLï¼ˆå¦‚ï¼šhttps://github.com/owner/repoï¼‰
        github_token: GitHub Tokenï¼ˆå¿…éœ€ï¼‰
        clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        
    Returns:
        Documentå¯¹è±¡åˆ—è¡¨
        
    Examples:
        >>> docs = load_documents_from_github_url(
        ...     "https://github.com/microsoft/TypeScript",
        ...     github_token="ghp_xxxx"
        ... )
    
    Note:
        - GitHub Token æ˜¯å¿…éœ€çš„ï¼Œæ— æ³•ä½¿ç”¨åŒ¿åè®¿é—®
        - åœ¨ Web ç•Œé¢ä¸­ï¼ŒToken ä»ç”¨æˆ·æ•°æ®ä¸­è‡ªåŠ¨è·å–
        - è·å– Tokenï¼šhttps://github.com/settings/tokens
    """
    # è§£æ URL
    repo_info = parse_github_url(github_url)
    if not repo_info:
        logger.error(f"æ— æ³•è§£æ GitHub URL: {github_url}")
        safe_print(f"âŒ æ— æ³•è§£æ GitHub URL: {github_url}")
        return []
    
    # Token å¿…é¡»æä¾›
    if not github_token:
        error_msg = (
            "éœ€è¦æä¾› GitHub Tokenã€‚\n"
            "è¯·åœ¨ Web ç•Œé¢çš„ 'ğŸ”‘ GitHub Token é…ç½®' ä¸­ä¿å­˜æ‚¨çš„ Tokenã€‚\n"
            "è·å– Tokenï¼šhttps://github.com/settings/tokens"
        )
        if show_progress:
            safe_print(f"âŒ {error_msg}")
        raise ValueError(error_msg)
    
    # è°ƒç”¨åŸæœ‰å‡½æ•°åŠ è½½æ–‡æ¡£
    return load_documents_from_github(
        owner=repo_info['owner'],
        repo=repo_info['repo'],
        branch=repo_info['branch'],
        github_token=github_token,
        clean=clean,
        show_progress=show_progress
    )


def load_documents_from_wikipedia(
    pages: List[str],
    lang: str = "zh",
    auto_suggest: bool = True,
    clean: bool = True,
    show_progress: bool = True
) -> List[LlamaDocument]:
    """ä»ç»´åŸºç™¾ç§‘åŠ è½½æ–‡æ¡£ï¼ˆä½¿ç”¨å®˜æ–¹ WikipediaReaderï¼‰
    
    Args:
        pages: ç»´åŸºç™¾ç§‘é¡µé¢æ ‡é¢˜åˆ—è¡¨
        lang: è¯­è¨€ä»£ç ï¼ˆzh=ä¸­æ–‡, en=è‹±æ–‡ï¼‰
        auto_suggest: è‡ªåŠ¨çº æ­£é¡µé¢æ ‡é¢˜æ‹¼å†™
        clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        
    Returns:
        Documentå¯¹è±¡åˆ—è¡¨
        
    Examples:
        >>> docs = load_documents_from_wikipedia(["é’±å­¦æ£®", "ç³»ç»Ÿç§‘å­¦"], lang="zh")
        >>> docs = load_documents_from_wikipedia(["Systems science"], lang="en")
    """
    if WikipediaReader is None:
        safe_print("âŒ ç¼ºå°‘ä¾èµ–ï¼šllama-index-readers-wikipedia")
        safe_print("   å®‰è£…ï¼špip install llama-index-readers-wikipedia wikipedia")
        logger.error("WikipediaReader æœªå®‰è£…")
        return []
    
    if not pages:
        safe_print("âš ï¸  é¡µé¢åˆ—è¡¨ä¸ºç©º")
        return []
    
    try:
        if show_progress:
            safe_print(f"ğŸ“– æ­£åœ¨ä»ç»´åŸºç™¾ç§‘åŠ è½½ {len(pages)} ä¸ªé¡µé¢ï¼ˆè¯­è¨€: {lang}ï¼‰...")
        
        logger.info(f"å¼€å§‹åŠ è½½ç»´åŸºç™¾ç§‘é¡µé¢: {pages}, è¯­è¨€: {lang}")
        
        # ä½¿ç”¨ WikipediaReader åŠ è½½é¡µé¢
        reader = WikipediaReader()
        
        # æ‰¹é‡åŠ è½½é¡µé¢
        documents = []
        iterator = tqdm(pages, desc="åŠ è½½ç»´åŸºç™¾ç§‘", unit="é¡µ") if show_progress else pages
        
        for page_title in iterator:
            try:
                page_docs = reader.load_data(
                    pages=[page_title],
                    lang=lang,
                    auto_suggest=auto_suggest
                )
                
                if page_docs:
                    documents.extend(page_docs)
                    if show_progress:
                        safe_print(f"âœ… å·²åŠ è½½: {page_title}")
                else:
                    if show_progress:
                        safe_print(f"âš ï¸  æœªæ‰¾åˆ°é¡µé¢: {page_title}")
                    logger.warning(f"ç»´åŸºç™¾ç§‘é¡µé¢æœªæ‰¾åˆ°: {page_title}")
                    
            except Exception as e:
                error_msg = str(e)
                if "does not match any pages" in error_msg or "Page id" in error_msg:
                    if show_progress:
                        safe_print(f"âš ï¸  é¡µé¢ä¸å­˜åœ¨: {page_title}")
                    logger.warning(f"ç»´åŸºç™¾ç§‘é¡µé¢ä¸å­˜åœ¨: {page_title}")
                else:
                    if show_progress:
                        safe_print(f"âŒ åŠ è½½å¤±è´¥: {page_title} - {error_msg}")
                    logger.error(f"åŠ è½½ç»´åŸºç™¾ç§‘é¡µé¢å¤±è´¥ {page_title}: {e}")
        
        if not documents:
            if show_progress:
                safe_print("âš ï¸  æœªæˆåŠŸåŠ è½½ä»»ä½•ç»´åŸºç™¾ç§‘é¡µé¢")
            logger.warning("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•ç»´åŸºç™¾ç§‘é¡µé¢")
            return []
        
        # å¢å¼ºå…ƒæ•°æ®ï¼šæ ‡è¯†æ¥æº
        for doc in documents:
            # è·å–é¡µé¢æ ‡é¢˜ï¼ˆä»å…ƒæ•°æ®æˆ–æ–‡æœ¬ä¸­æå–ï¼‰
            page_title = doc.metadata.get('title', 'Unknown')
            
            # æ„å»ºç»´åŸºç™¾ç§‘ URL
            # æ³¨æ„ï¼šURL ä¸­çš„æ ‡é¢˜éœ€è¦æ›¿æ¢ç©ºæ ¼ä¸ºä¸‹åˆ’çº¿
            url_title = page_title.replace(' ', '_')
            wikipedia_url = f"https://{lang}.wikipedia.org/wiki/{url_title}"
            
            # å¢å¼ºå…ƒæ•°æ®
            doc.metadata.update({
                "source_type": "wikipedia",
                "language": lang,
                "wikipedia_url": wikipedia_url,
            })
            
            # ç¡®ä¿æœ‰æ ‡é¢˜
            if not doc.metadata.get('title'):
                doc.metadata['title'] = page_title
        
        if show_progress:
            safe_print(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªç»´åŸºç™¾ç§‘é¡µé¢")
        
        logger.info(f"æˆåŠŸåŠ è½½ {len(documents)} ä¸ªç»´åŸºç™¾ç§‘é¡µé¢")
        
        # å¯é€‰çš„æ–‡æœ¬æ¸…ç†
        if clean:
            processor = DocumentProcessor()
            cleaned_documents = []
            for doc in documents:
                cleaned_text = processor.clean_text(doc.text)
                cleaned_doc = LlamaDocument(
                    text=cleaned_text,
                    metadata=doc.metadata,
                    id_=doc.id_
                )
                cleaned_documents.append(cleaned_doc)
            return cleaned_documents
        
        return documents
        
    except Exception as e:
        safe_print(f"âŒ åŠ è½½ç»´åŸºç™¾ç§‘å¤±è´¥: {e}")
        logger.error(f"åŠ è½½ç»´åŸºç™¾ç§‘å¤±è´¥: {e}")
        return []


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    from src.config import config
    
    safe_print("=== æµ‹è¯•æ–‡æ¡£åŠ è½½å™¨ ===")
    documents = load_documents_from_directory(config.RAW_DATA_PATH)
    safe_print(f"åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")
    
    if documents:
        safe_print("\nç¬¬ä¸€ä¸ªæ–‡æ¡£é¢„è§ˆ:")
        safe_print(f"æ ‡é¢˜: {documents[0].metadata.get('title')}")
        safe_print(f"å†…å®¹é•¿åº¦: {len(documents[0].text)}")
        safe_print(f"å†…å®¹é¢„è§ˆ: {documents[0].text[:200]}...")
