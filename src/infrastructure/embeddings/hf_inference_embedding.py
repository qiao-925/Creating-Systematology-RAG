"""
Hugging Face Inference API Embeddingé€‚é…å™¨ï¼šæ”¯æŒé€šè¿‡HF Inference Providersè°ƒç”¨embeddingæ¨¡å‹

ä¸»è¦åŠŸèƒ½ï¼š
- HFInferenceEmbeddingç±»ï¼šHugging Face Inference APIé€‚é…å™¨ï¼Œå®ç°BaseEmbeddingæ¥å£
- get_query_embedding()ï¼šé€šè¿‡HF Inference APIç”ŸæˆæŸ¥è¯¢å‘é‡
- get_text_embeddings()ï¼šé€šè¿‡HF Inference APIæ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡

ç‰¹æ€§ï¼š
- ä½¿ç”¨å®˜æ–¹huggingface_hub SDK
- æ”¯æŒæŒ‰é‡ä»˜è´¹ï¼ˆPROç”¨æˆ·æ¯æœˆæœ‰$2.00å…è´¹é¢åº¦ï¼‰
- ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
"""

import os
from typing import List, Optional
import time
import asyncio

from huggingface_hub import InferenceClient

from src.infrastructure.embeddings.base import BaseEmbedding
from src.infrastructure.config import config
from src.infrastructure.logger import get_logger

logger = get_logger('hf_inference_embedding')


class HFInferenceEmbedding(BaseEmbedding):
    """Hugging Face Inference API Embedding é€‚é…å™¨
    
    ä½¿ç”¨ Hugging Face Inference Providers æœåŠ¡è°ƒç”¨ embedding æ¨¡å‹
    æ”¯æŒæŒ‰é‡ä»˜è´¹ï¼ŒPRO ç”¨æˆ·æ¯æœˆæœ‰ $2.00 å…è´¹é¢åº¦
    """
    
    def __init__(
        self,
        model_name: str = "BAAI/bge-base-zh-v1.5",
        api_key: Optional[str] = None,
    ):
        """åˆå§‹åŒ– HF Inference API Embedding
        
        Args:
            model_name: Hugging Face æ¨¡å‹åç§°ï¼ˆé»˜è®¤ BAAI/bge-base-zh-v1.5ï¼‰
            api_key: Hugging Face API Tokenï¼ˆä»ç¯å¢ƒå˜é‡ HF_TOKEN æˆ–é…ç½®è¯»å–ï¼‰
        """
        self.model_name = model_name
        self._dimension: Optional[int] = None
        
        # è·å– API keyï¼ˆä¼˜å…ˆçº§ï¼šå‚æ•° > ç¯å¢ƒå˜é‡ > é…ç½®ï¼‰
        self.api_key = api_key or os.getenv("HF_TOKEN") or getattr(config, 'HF_TOKEN', None)
        
        if not self.api_key:
            raise ValueError(
                "HF_TOKEN æœªè®¾ç½®ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ HF_TOKEN æˆ–é…ç½®ä¸­çš„ HF_TOKENã€‚"
                "è·å– Token: https://huggingface.co/settings/tokens"
            )
        
        # åˆå§‹åŒ–å®˜æ–¹ SDKï¼ˆä½¿ç”¨æ–°æ¨¡å¼ï¼‰
        self.client = InferenceClient(
            provider="hf-inference",
            api_key=self.api_key,
        )
        
        logger.info(f"ğŸ“¡ åˆå§‹åŒ– Hugging Face Inference API Embedding: {self.model_name}")
    
    def _get_default_dimension(self, model_name: str) -> int:
        """æ ¹æ®æ¨¡å‹åç§°è·å–é»˜è®¤ç»´åº¦"""
        model_lower = model_name.lower()
        if "qwen" in model_lower and ("0.6b" in model_lower or "8b" in model_lower):
            return 1024
        elif "bge" in model_lower:
            return 768 if "base" in model_lower else 384
        return 384  # é€šç”¨é»˜è®¤å€¼
    
    def _make_request(self, texts: List[str], retry_count: int = 0) -> List[List[float]]:
        """å‘èµ· API è¯·æ±‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        ä½¿ç”¨ HuggingFace Inference API çš„ feature_extraction æ–¹æ³•ç”Ÿæˆå‘é‡ã€‚
        æ³¨æ„ï¼šfeature_extraction ä¸€æ¬¡åªèƒ½å¤„ç†ä¸€ä¸ªæ–‡æœ¬ï¼Œéœ€è¦é€ä¸ªå¤„ç†ã€‚
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            retry_count: å½“å‰é‡è¯•æ¬¡æ•°
            
        Returns:
            å‘é‡åˆ—è¡¨
            
        Raises:
            RuntimeError: API è°ƒç”¨å¤±è´¥
        """
        if retry_count > 0:
            logger.warning(f"âš ï¸  é‡è¯•è¯·æ±‚ ({retry_count}/3): æ¨¡å‹={self.model_name}, æ–‡æœ¬æ•°é‡={len(texts)}")
        else:
            logger.debug(f"ğŸ“¤ HF Inference API è¯·æ±‚: æ¨¡å‹={self.model_name}, æ–‡æœ¬æ•°é‡={len(texts)}")
        
        try:
            results = []
            total = len(texts)
            
            # feature_extraction ä¸€æ¬¡åªèƒ½å¤„ç†ä¸€ä¸ªæ–‡æœ¬ï¼Œé€ä¸ªå¤„ç†
            for idx, text in enumerate(texts):
                embedding = self.client.feature_extraction(
                    text,
                    model=self.model_name,
                )
                
                # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
                if isinstance(embedding, list):
                    results.append(embedding)
                elif hasattr(embedding, '__iter__') and not isinstance(embedding, str):
                    results.append(list(embedding))
                else:
                    results.append([float(embedding)])
                
                # æ‰¹é‡å¤„ç†æ—¶æ˜¾ç¤ºè¿›åº¦
                if total > 1 and (idx + 1) % 10 == 0:
                    logger.debug(f"   è¿›åº¦: {idx + 1}/{total}")
            
            if total > 1:
                logger.debug(f"ğŸ“¥ æ‰¹é‡å¤„ç†å®Œæˆ: {len(results)}/{total} ä¸ªæ–‡æœ¬")
            
            return results
                    
        except Exception as e:
            # ç»Ÿä¸€é”™è¯¯å¤„ç†ï¼šå…¨éƒ¨é‡è¯•
            return self._handle_request_error(e, texts, retry_count)
    
    def _handle_request_error(
        self,
        error: Exception,
        texts: List[str],
        retry_count: int
    ) -> List[List[float]]:
        """å¤„ç† API è¯·æ±‚é”™è¯¯ï¼ˆç»Ÿä¸€é‡è¯•ç­–ç•¥ï¼‰
        
        Args:
            error: æ•è·çš„å¼‚å¸¸
            texts: è¯·æ±‚çš„æ–‡æœ¬åˆ—è¡¨
            retry_count: å½“å‰é‡è¯•æ¬¡æ•°
            
        Returns:
            å‘é‡åˆ—è¡¨ï¼ˆé‡è¯•æˆåŠŸæ—¶ï¼‰
            
        Raises:
            RuntimeError: é‡è¯•æ¬¡æ•°ç”¨å°½
        """
        max_retries = 3
        
        if retry_count < max_retries:
            wait_time = (retry_count + 1) * 1.0
            logger.warning(
                f"âŒ API è¯·æ±‚å¤±è´¥: {error.__class__.__name__}: {str(error)}ã€‚"
                f"{wait_time:.1f}ç§’åé‡è¯• ({retry_count + 1}/{max_retries})"
            )
            time.sleep(wait_time)
            return self._make_request(texts, retry_count + 1)
        else:
            logger.error(f"âŒ API è°ƒç”¨å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰")
            raise RuntimeError(
                f"Hugging Face Inference API è°ƒç”¨å¤±è´¥ï¼ˆæ¨¡å‹: {self.model_name}ï¼‰: {error}"
            ) from error
    
    def get_query_embedding(self, query: str) -> List[float]:
        """ç”ŸæˆæŸ¥è¯¢å‘é‡"""
        embeddings = self.get_text_embeddings([query])
        return embeddings[0]
    
    def get_text_embeddings(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡
        
        æ”¯æŒæ‰¹é‡å¤„ç†ï¼Œè‡ªåŠ¨åˆ†æ‰¹ä»¥é¿å…å•æ¬¡è¯·æ±‚è¿‡å¤§ã€‚
        ç”±äº feature_extraction ä¸€æ¬¡åªèƒ½å¤„ç†ä¸€ä¸ªæ–‡æœ¬ï¼Œå†…éƒ¨ä¼šé€ä¸ªå¤„ç†ã€‚
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            å‘é‡åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æœ¬å¯¹åº”ä¸€ä¸ªå‘é‡
        """
        if not texts:
            return []
        
        # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š 100 ä¸ªæ–‡æœ¬
        batch_size = 100
        total_batches = (len(texts) + batch_size - 1) // batch_size
        all_embeddings = []
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            if total_batches > 1:
                logger.debug(f"å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)} ä¸ªæ–‡æœ¬)")
            
            batch_embeddings = self._make_request(batch)
            all_embeddings.extend(batch_embeddings)
        
        return all_embeddings
    
    def get_embedding_dimension(self) -> int:
        """è·å–å‘é‡ç»´åº¦ï¼ˆç¡®ä¿æ€»æ˜¯è¿”å›æœ‰æ•ˆå€¼ï¼‰"""
        if self._dimension is None:
            self._dimension = self._get_default_dimension(self.model_name)
            logger.debug(f"ä½¿ç”¨é»˜è®¤ç»´åº¦: {self._dimension}")
            try:
                test_embedding = self.get_query_embedding("test")
                detected_dim = len(test_embedding)
                if detected_dim != self._dimension:
                    logger.info(f"ğŸ”„ æ£€æµ‹åˆ°å®é™…ç»´åº¦ {detected_dim}ï¼Œæ›´æ–°é»˜è®¤å€¼ {self._dimension}")
                    self._dimension = detected_dim
            except Exception as e:
                logger.warning(f"âš ï¸  æ— æ³•é€šè¿‡APIè·å–ç»´åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
        return self._dimension
    
    def get_model_name(self) -> str:
        """è·å–æ¨¡å‹åç§°"""
        return self.model_name
    
    def get_llama_index_embedding(self):
        """è·å–LlamaIndexå…¼å®¹çš„Embeddingé€‚é…å™¨
        
        Returns:
            LlamaIndexå…¼å®¹çš„é€‚é…å™¨åŒ…è£…å™¨ï¼ˆç»§æ‰¿è‡ªLlamaIndex BaseEmbeddingï¼‰
            
        Raises:
            ImportError: å¦‚æœæ— æ³•å¯¼å…¥LlamaIndex BaseEmbedding
        """
        # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…æ¨¡å—åŠ è½½æ—¶å‡ºé”™
        # ä¼˜å…ˆç›´æ¥å¯¼å…¥ BaseEmbeddingï¼ˆè€Œä¸æ˜¯é€šè¿‡ HuggingFaceEmbedding è·å–ï¼‰
        LlamaBaseEmbedding = None
        try:
            from llama_index.core.embeddings.base import BaseEmbedding as LlamaBaseEmbedding
            logger.debug("âœ… æˆåŠŸå¯¼å…¥ llama_index.core.embeddings.base.BaseEmbedding")
        except ImportError:
            try:
                from llama_index.embeddings.base import BaseEmbedding as LlamaBaseEmbedding
                logger.debug("âœ… æˆåŠŸå¯¼å…¥ llama_index.embeddings.base.BaseEmbedding")
            except ImportError:
                # å¦‚æœç›´æ¥å¯¼å…¥å¤±è´¥ï¼Œå°è¯•é€šè¿‡ HuggingFaceEmbedding çš„ MRO æ‰¾åˆ° BaseEmbedding
                try:
                    from llama_index.embeddings.huggingface import HuggingFaceEmbedding
                    # é€šè¿‡ MRO æ‰¾åˆ° BaseEmbeddingï¼ˆè€Œä¸æ˜¯ç›´æ¥å– __bases__[0]ï¼‰
                    for base_class in HuggingFaceEmbedding.__mro__:
                        if base_class.__name__ == 'BaseEmbedding' and 'embeddings' in base_class.__module__:
                            LlamaBaseEmbedding = base_class
                            logger.debug(f"âœ… é€šè¿‡MROæ‰¾åˆ°BaseEmbedding: {base_class.__module__}.{base_class.__name__}")
                            break
                    
                    if LlamaBaseEmbedding is None:
                        raise ImportError("æ— æ³•åœ¨ HuggingFaceEmbedding çš„ MRO ä¸­æ‰¾åˆ° BaseEmbedding")
                except (ImportError, AttributeError) as e:
                    # å¦‚æœéƒ½å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯è€Œä¸æ˜¯è¿”å›ä¸å…¼å®¹çš„å¯¹è±¡
                    error_msg = (
                        "æ— æ³•å¯¼å…¥LlamaIndex BaseEmbeddingã€‚"
                        "è¯·ç¡®ä¿å·²å®‰è£… llama-index æˆ– llama-index-coreã€‚"
                        f"é”™è¯¯è¯¦æƒ…: {e}"
                    )
                    logger.error(error_msg)
                    raise ImportError(error_msg) from e
        
        # éªŒè¯è·å–åˆ°çš„ç¡®å®æ˜¯ BaseEmbeddingï¼ˆä¸æ˜¯ MultiModalEmbedding æˆ–å…¶ä»–ï¼‰
        if LlamaBaseEmbedding and LlamaBaseEmbedding.__name__ != 'BaseEmbedding':
            error_msg = (
                f"è·å–åˆ°çš„åŸºç±»ä¸æ˜¯ BaseEmbeddingï¼Œè€Œæ˜¯ {LlamaBaseEmbedding.__name__}ã€‚"
                f"è¿™å¯èƒ½å¯¼è‡´é€‚é…å™¨éœ€è¦å®ç°é¢å¤–çš„æŠ½è±¡æ–¹æ³•ã€‚"
            )
            logger.warning(error_msg)
        
        # åŠ¨æ€åˆ›å»ºç»§æ‰¿LlamaBaseEmbeddingçš„é€‚é…å™¨ç±»
        class LlamaIndexEmbeddingAdapter(LlamaBaseEmbedding):
            """LlamaIndexå…¼å®¹çš„Embeddingé€‚é…å™¨åŒ…è£…å™¨"""
            
            def __init__(self, embedding: HFInferenceEmbedding):
                # å…ˆè°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ï¼ˆPydantic æ¨¡å‹éœ€è¦å…ˆåˆå§‹åŒ–ï¼‰
                model_name = embedding.get_model_name()
                try:
                    # å°è¯•ä½¿ç”¨ model_name å‚æ•°åˆå§‹åŒ–
                    super().__init__(model_name=model_name)
                except (TypeError, AttributeError) as e:
                    try:
                        # å°è¯•æ— å‚æ•°åˆå§‹åŒ–
                        super().__init__()
                    except Exception as init_error:
                        # å¦‚æœçˆ¶ç±»åˆå§‹åŒ–å¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­
                        logger.debug(f"çˆ¶ç±»åˆå§‹åŒ–å¤±è´¥: {init_error}")
                        # å³ä½¿åˆå§‹åŒ–å¤±è´¥ï¼Œä¹Ÿç»§ç»­ï¼ˆå¯èƒ½ä¸éœ€è¦å‚æ•°ï¼‰
                        pass
                
                # çˆ¶ç±»åˆå§‹åŒ–åå†è®¾ç½®å±æ€§ï¼ˆä½¿ç”¨ object.__setattr__ ç»•è¿‡ Pydantic éªŒè¯ï¼‰
                # è¿™æ ·å¯ä»¥é¿å… Pydantic çš„å­—æ®µéªŒè¯é—®é¢˜
                object.__setattr__(self, '_embedding', embedding)
                # model_name å¯èƒ½å·²ç»åœ¨ super().__init__() ä¸­è®¾ç½®äº†ï¼Œå¦‚æœæ²¡æœ‰åˆ™è®¾ç½®
                if not hasattr(self, 'model_name') or self.model_name != model_name:
                    try:
                        self.model_name = model_name
                    except (AttributeError, ValueError):
                        # å¦‚æœ Pydantic ä¸å…è®¸ç›´æ¥è®¾ç½®ï¼Œä½¿ç”¨ object.__setattr__
                        object.__setattr__(self, 'model_name', model_name)
            
            def _get_query_embedding(self, query: str) -> List[float]:
                """ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼ŒåŒæ­¥ï¼‰"""
                return self._embedding.get_query_embedding(query)
            
            def _get_text_embedding(self, text: str) -> List[float]:
                """ç”Ÿæˆå•ä¸ªæ–‡æœ¬å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼ŒåŒæ­¥ï¼‰"""
                embeddings = self._embedding.get_text_embeddings([text])
                return embeddings[0] if embeddings else []
            
            def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:
                """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼ŒåŒæ­¥ï¼‰"""
                return self._embedding.get_text_embeddings(texts)
            
            async def _aget_query_embedding(self, query: str) -> List[float]:
                """ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼Œå¼‚æ­¥ï¼‰"""
                # å¼‚æ­¥åŒ…è£…åŒæ­¥è°ƒç”¨
                return await asyncio.to_thread(self._embedding.get_query_embedding, query)
            
            async def _aget_text_embedding(self, text: str) -> List[float]:
                """ç”Ÿæˆå•ä¸ªæ–‡æœ¬å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼Œå¼‚æ­¥ï¼‰"""
                # å¼‚æ­¥åŒ…è£…åŒæ­¥è°ƒç”¨
                embeddings = await asyncio.to_thread(self._embedding.get_text_embeddings, [text])
                return embeddings[0] if embeddings else []
            
            async def _aget_text_embeddings(self, texts: List[str]) -> List[List[float]]:
                """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼Œå¼‚æ­¥ï¼‰"""
                # å¼‚æ­¥åŒ…è£…åŒæ­¥è°ƒç”¨
                return await asyncio.to_thread(self._embedding.get_text_embeddings, texts)
            
            def get_query_embedding(self, query: str) -> List[float]:
                """ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå…¼å®¹LlamaIndexæ¥å£ï¼‰"""
                return self._get_query_embedding(query)
            
            def get_text_embedding(self, text: str) -> List[float]:
                """ç”Ÿæˆå•ä¸ªæ–‡æœ¬å‘é‡ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå…¼å®¹LlamaIndexæ¥å£ï¼‰"""
                return self._get_text_embedding(text)
            
            def get_text_embedding_batch(self, texts: List[str], **kwargs) -> List[List[float]]:
                """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå…¼å®¹LlamaIndexæ¥å£ï¼‰
                
                Args:
                    texts: æ–‡æœ¬åˆ—è¡¨
                    **kwargs: é¢å¤–å‚æ•°ï¼ˆå¦‚ show_progressï¼‰ï¼Œä¼šè¢«å¿½ç•¥
                """
                return self._get_text_embeddings(texts)
        
        try:
            adapter = LlamaIndexEmbeddingAdapter(self)
        except TypeError as e:
            # å¦‚æœåˆ›å»ºé€‚é…å™¨å¤±è´¥ï¼ˆå¯èƒ½æ˜¯æŠ½è±¡æ–¹æ³•æœªå®ç°ï¼‰ï¼Œæä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_msg = (
                f"æ— æ³•åˆ›å»ºLlamaIndexé€‚é…å™¨: {e}ã€‚"
                f"è¿™å¯èƒ½æ˜¯å› ä¸ºåŸºç±» {LlamaBaseEmbedding.__name__} æœ‰æœªå®ç°çš„æŠ½è±¡æ–¹æ³•ã€‚"
                f"è¯·æ£€æŸ¥æ˜¯å¦éœ€è¦å®ç°é¢å¤–çš„æŠ½è±¡æ–¹æ³•ã€‚"
            )
            logger.error(error_msg)
            raise TypeError(error_msg) from e
        
        # éªŒè¯é€‚é…å™¨ç¡®å®æ˜¯BaseEmbeddingçš„å®ä¾‹
        if not isinstance(adapter, LlamaBaseEmbedding):
            error_msg = (
                f"åˆ›å»ºçš„é€‚é…å™¨ä¸æ˜¯LlamaIndex BaseEmbeddingçš„å®ä¾‹ã€‚"
                f"ç±»å‹: {type(adapter)}, æœŸæœ›: {LlamaBaseEmbedding}"
            )
            logger.error(error_msg)
            raise TypeError(error_msg)
        
        logger.debug(f"âœ… æˆåŠŸåˆ›å»ºLlamaIndexé€‚é…å™¨: {type(adapter)}")
        return adapter


class _SimpleAdapter:
    """ç®€å•çš„é€‚é…å™¨åŒ…è£…å™¨ï¼ˆå½“æ— æ³•å¯¼å…¥LlamaIndex BaseEmbeddingæ—¶ä½¿ç”¨ï¼‰"""
    
    def __init__(self, embedding: HFInferenceEmbedding):
        self._embedding = embedding
        self.model_name = embedding.get_model_name()
    
    def get_query_embedding(self, query: str) -> List[float]:
        return self._embedding.get_query_embedding(query)
    
    def get_text_embedding(self, text: str) -> List[float]:
        embeddings = self._embedding.get_text_embeddings([text])
        return embeddings[0] if embeddings else []
    
    def _get_query_embedding(self, query: str) -> List[float]:
        """ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼‰"""
        return self._embedding.get_query_embedding(query)
    
    def _get_text_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆå•ä¸ªæ–‡æœ¬å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼‰"""
        embeddings = self._embedding.get_text_embeddings([text])
        return embeddings[0] if embeddings else []
    
    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼‰"""
        return self._embedding.get_text_embeddings(texts)
    
    def get_query_embedding(self, query: str) -> List[float]:
        """ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå…¼å®¹LlamaIndexæ¥å£ï¼‰"""
        return self._get_query_embedding(query)
    
    def get_text_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆå•ä¸ªæ–‡æœ¬å‘é‡ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå…¼å®¹LlamaIndexæ¥å£ï¼‰"""
        return self._get_text_embedding(text)
    
    def get_text_embedding_batch(self, texts: List[str], **kwargs) -> List[List[float]]:
        """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå…¼å®¹LlamaIndexæ¥å£ï¼‰
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            **kwargs: é¢å¤–å‚æ•°ï¼ˆå¦‚ show_progressï¼‰ï¼Œä¼šè¢«å¿½ç•¥
        """
        return self._get_text_embeddings(texts)
