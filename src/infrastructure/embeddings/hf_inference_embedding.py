"""
Hugging Face Inference API Embeddingé€‚é…å™¨ï¼šæ”¯æŒé€šè¿‡HF Inference Providersè°ƒç”¨embeddingæ¨¡å‹

ä¸»è¦åŠŸèƒ½ï¼š
- HFInferenceEmbeddingç±»ï¼šHugging Face Inference APIé€‚é…å™¨ï¼Œå®ç°BaseEmbeddingæ¥å£
- get_query_embedding()ï¼šé€šè¿‡HF Inference APIç”ŸæˆæŸ¥è¯¢å‘é‡
- get_text_embeddings()ï¼šé€šè¿‡HF Inference APIæ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡

ç‰¹æ€§ï¼š
- ä½¿ç”¨ç›´æ¥HTTPè¯·æ±‚ï¼ˆrequestsï¼‰è°ƒç”¨HF Inference APIï¼Œæé«˜é€æ˜åº¦å’Œå¯è°ƒè¯•æ€§
- æ”¯æŒæŒ‰é‡ä»˜è´¹ï¼ˆPROç”¨æˆ·æ¯æœˆæœ‰$2.00å…è´¹é¢åº¦ï¼‰
- ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
"""

import os
from typing import List, Optional
import time
import asyncio
import threading
import json
import weakref
from concurrent.futures import ThreadPoolExecutor

import requests
from requests.exceptions import RequestException

from src.infrastructure.embeddings.base import BaseEmbedding
from src.infrastructure.config import config
from src.infrastructure.logger import get_logger

logger = get_logger('hf_inference_embedding')

# å…¨å±€çº¿ç¨‹æ± æ‰§è¡Œå™¨ï¼Œç”¨äº asyncio.to_thread()
# ä½¿ç”¨å¼±å¼•ç”¨é›†åˆè·Ÿè¸ªæ‰€æœ‰ HFInferenceEmbedding å®ä¾‹ï¼Œä»¥ä¾¿åœ¨é€€å‡ºæ—¶æ¸…ç†
_global_executor: Optional[ThreadPoolExecutor] = None
_embedding_instances: weakref.WeakSet = weakref.WeakSet()


def _get_or_create_executor() -> ThreadPoolExecutor:
    """è·å–æˆ–åˆ›å»ºå…¨å±€çº¿ç¨‹æ± æ‰§è¡Œå™¨
    
    Returns:
        ThreadPoolExecutor: å…¨å±€çº¿ç¨‹æ± æ‰§è¡Œå™¨
    """
    global _global_executor
    if _global_executor is None:
        # åˆ›å»ºçº¿ç¨‹æ± ï¼Œæœ€å¤§çº¿ç¨‹æ•°ä¸º CPU æ ¸å¿ƒæ•°çš„ 2 å€
        max_workers = min(32, (os.cpu_count() or 1) * 2)
        _global_executor = ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="hf_embedding")
        logger.debug(f"åˆ›å»ºå…¨å±€çº¿ç¨‹æ± æ‰§è¡Œå™¨: max_workers={max_workers}")
    return _global_executor


def cleanup_hf_embedding_resources() -> None:
    """æ¸…ç†æ‰€æœ‰ HFInferenceEmbedding èµ„æºå’Œçº¿ç¨‹æ± 
    
    åº”è¯¥åœ¨åº”ç”¨é€€å‡ºæ—¶è°ƒç”¨æ­¤å‡½æ•°ï¼Œç¡®ä¿æ‰€æœ‰çº¿ç¨‹å’Œè¿æ¥è¢«æ­£ç¡®å…³é—­ã€‚
    """
    global _global_executor
    
    logger.info("ğŸ”§ å¼€å§‹æ¸…ç† Hugging Face Embedding èµ„æº...")
    
    # 1. å…³é—­æ‰€æœ‰ HFInferenceEmbedding å®ä¾‹
    instances_to_close = list(_embedding_instances)
    if instances_to_close:
        logger.info(f"å…³é—­ {len(instances_to_close)} ä¸ª HFInferenceEmbedding å®ä¾‹...")
        for instance in instances_to_close:
            try:
                instance.close()
            except Exception as e:
                logger.warning(f"å…³é—­ HFInferenceEmbedding å®ä¾‹æ—¶å‡ºé”™: {e}")
    
    # 2. å…³é—­å…¨å±€çº¿ç¨‹æ± æ‰§è¡Œå™¨
    if _global_executor is not None:
        try:
            logger.info("å…³é—­å…¨å±€çº¿ç¨‹æ± æ‰§è¡Œå™¨...")
            _global_executor.shutdown(wait=True, timeout=5.0)
            logger.info("âœ… å…¨å±€çº¿ç¨‹æ± æ‰§è¡Œå™¨å·²å…³é—­")
        except Exception as e:
            logger.warning(f"å…³é—­çº¿ç¨‹æ± æ‰§è¡Œå™¨æ—¶å‡ºé”™: {e}")
        finally:
            _global_executor = None
    
    logger.info("âœ… Hugging Face Embedding èµ„æºæ¸…ç†å®Œæˆ")


class TimeMonitor:
    """æ—¶é—´ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºå®æ—¶è®°å½•æ“ä½œè€—æ—¶
    
    ä½¿ç”¨åå°çº¿ç¨‹æ¯ç§’æ‰“å°ä¸€æ¬¡å·²èŠ±è´¹æ—¶é—´ï¼Œå¸®åŠ©ç›‘æ§é•¿æ—¶é—´è¿è¡Œçš„æ“ä½œã€‚
    """
    
    def __init__(
        self,
        logger_instance,
        message_template: str,
        interval: float = 5.0
    ):
        """åˆå§‹åŒ–æ—¶é—´ç›‘æ§å™¨
        
        Args:
            logger_instance: logger å®ä¾‹
            message_template: æ—¥å¿—æ¶ˆæ¯æ¨¡æ¿ï¼Œæ”¯æŒ {elapsed} å ä½ç¬¦
            interval: æ‰“å°é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤5.0ç§’
        """
        self.logger = logger_instance
        self.message_template = message_template
        self.interval = interval
        self.start_time: Optional[float] = None
        self.stop_event = threading.Event()
        self.thread: Optional[threading.Thread] = None
    
    def __enter__(self):
        """è¿›å…¥ä¸Šä¸‹æ–‡ï¼Œå¼€å§‹ç›‘æ§"""
        self.start_time = time.time()
        self.stop_event.clear()
        
        # åˆ›å»ºå¹¶å¯åŠ¨åå°çº¿ç¨‹
        self.thread = threading.Thread(
            target=self._log_elapsed_time,
            daemon=True  # è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹ï¼Œä¸»çº¿ç¨‹é€€å‡ºæ—¶è‡ªåŠ¨ç»“æŸ
        )
        self.thread.start()
        
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """é€€å‡ºä¸Šä¸‹æ–‡ï¼Œåœæ­¢ç›‘æ§"""
        # åœæ­¢åå°çº¿ç¨‹
        if self.thread and self.thread.is_alive():
            self.stop_event.set()
            # ç­‰å¾…çº¿ç¨‹ç»“æŸï¼Œæœ€å¤šç­‰å¾…2ç§’
            self.thread.join(timeout=2.0)
            # å¦‚æœçº¿ç¨‹ä»åœ¨è¿è¡Œï¼Œå¼ºåˆ¶ç»ˆæ­¢ï¼ˆdaemon çº¿ç¨‹ä¼šåœ¨ä¸»çº¿ç¨‹é€€å‡ºæ—¶è‡ªåŠ¨ç»ˆæ­¢ï¼‰
            if self.thread.is_alive():
                self.logger.debug("TimeMonitor çº¿ç¨‹ä»åœ¨è¿è¡Œï¼Œå°†åœ¨ä¸»çº¿ç¨‹é€€å‡ºæ—¶è‡ªåŠ¨ç»ˆæ­¢")
        
        # è®¡ç®—æ€»è€—æ—¶
        if self.start_time is not None:
            total_elapsed = time.time() - self.start_time
            # å¦‚æœæ€»è€—æ—¶å¤§äº0.1ç§’ï¼Œæ‰“å°æœ€ç»ˆæ—¥å¿—
            if total_elapsed >= 0.1:
                final_message = self.message_template.format(elapsed=int(total_elapsed))
                self.logger.info(f"{final_message} (æ€»è®¡)")
        
        return False  # ä¸æŠ‘åˆ¶å¼‚å¸¸
    
    def _log_elapsed_time(self):
        """åå°çº¿ç¨‹å‡½æ•°ï¼Œæ¯5ç§’æ‰“å°ä¸€æ¬¡å·²èŠ±è´¹æ—¶é—´"""
        last_logged_interval = -1
        
        while not self.stop_event.is_set():
            if self.start_time is None:
                break
            
            elapsed = time.time() - self.start_time
            current_interval = int(elapsed / self.interval)  # æŒ‰é—´éš”è®¡ç®—
            
            # åªåœ¨é—´éš”å˜åŒ–æ—¶æ‰“å°ï¼Œé¿å…é‡å¤
            if current_interval > last_logged_interval and current_interval > 0:
                try:
                    elapsed_seconds = int(elapsed)
                    message = self.message_template.format(elapsed=elapsed_seconds)
                    self.logger.info(message)
                    last_logged_interval = current_interval
                except Exception as e:
                    # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­ç›‘æ§
                    self.logger.debug(f"æ—¶é—´ç›‘æ§æ—¥å¿—æ ¼å¼åŒ–å¤±è´¥: {e}")
            
            # ç­‰å¾…é—´éš”æ—¶é—´æˆ–ç›´åˆ°åœæ­¢äº‹ä»¶è¢«è®¾ç½®
            self.stop_event.wait(timeout=self.interval)


class HFInferenceEmbedding(BaseEmbedding):
    """Hugging Face Inference API Embedding é€‚é…å™¨
    
    ä½¿ç”¨ Hugging Face Inference Providers æœåŠ¡è°ƒç”¨ embedding æ¨¡å‹
    æ”¯æŒæŒ‰é‡ä»˜è´¹ï¼ŒPRO ç”¨æˆ·æ¯æœˆæœ‰ $2.00 å…è´¹é¢åº¦
    """
    
    def __init__(
        self,
        model_name: str = "BAAI/bge-base-zh-v1.5",
        api_key: Optional[str] = None,
    ):
        """åˆå§‹åŒ– HF Inference API Embedding
        
        Args:
            model_name: Hugging Face æ¨¡å‹åç§°ï¼ˆé»˜è®¤ BAAI/bge-base-zh-v1.5ï¼‰
            api_key: Hugging Face API Tokenï¼ˆä»ç¯å¢ƒå˜é‡ HF_TOKEN æˆ–é…ç½®è¯»å–ï¼‰
        """
        self.model_name = model_name
        self._dimension: Optional[int] = None
        self._closed = False
        self._active_requests: set = set()  # è·Ÿè¸ªæ­£åœ¨è¿›è¡Œçš„è¯·æ±‚
        
        # è·å– API keyï¼ˆä¼˜å…ˆçº§ï¼šå‚æ•° > ç¯å¢ƒå˜é‡ > é…ç½®ï¼‰
        self.api_key = api_key or os.getenv("HF_TOKEN") or getattr(config, 'HF_TOKEN', None)
        
        if not self.api_key:
            raise ValueError(
                "HF_TOKEN æœªè®¾ç½®ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ HF_TOKEN æˆ–é…ç½®ä¸­çš„ HF_TOKENã€‚"
                "è·å– Token: https://huggingface.co/settings/tokens"
            )
        
        # æ„å»º API URL å’Œ headersï¼ˆä½¿ç”¨ç›´æ¥ HTTP è¯·æ±‚ï¼‰
        self.api_url = f"https://router.huggingface.co/hf-inference/models/{self.model_name}/pipeline/feature-extraction"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        
        # æ³¨å†Œåˆ°å…¨å±€å®ä¾‹é›†åˆï¼Œä»¥ä¾¿åœ¨é€€å‡ºæ—¶æ¸…ç†
        _embedding_instances.add(self)
        
        logger.info(f"ğŸ“¡ åˆå§‹åŒ– Hugging Face Inference API Embedding: {self.model_name}")
    
    def _get_default_dimension(self, model_name: str) -> int:
        """æ ¹æ®æ¨¡å‹åç§°è·å–é»˜è®¤ç»´åº¦"""
        model_lower = model_name.lower()
        if "qwen" in model_lower and ("0.6b" in model_lower or "8b" in model_lower):
            return 1024
        elif "bge" in model_lower:
            return 768 if "base" in model_lower else 384
        return 384  # é€šç”¨é»˜è®¤å€¼
    
    def _make_request(self, texts: List[str], retry_count: int = 0) -> List[List[float]]:
        """å‘èµ· API è¯·æ±‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        ä½¿ç”¨ HuggingFace Inference API çš„ feature_extraction æ–¹æ³•ç”Ÿæˆå‘é‡ã€‚
        æ³¨æ„ï¼šfeature_extraction ä¸€æ¬¡åªèƒ½å¤„ç†ä¸€ä¸ªæ–‡æœ¬ï¼Œéœ€è¦é€ä¸ªå¤„ç†ã€‚
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            retry_count: å½“å‰é‡è¯•æ¬¡æ•°
            
        Returns:
            å‘é‡åˆ—è¡¨
            
        Raises:
            RuntimeError: API è°ƒç”¨å¤±è´¥æˆ–å®ä¾‹å·²å…³é—­
        """
        # æ£€æŸ¥å®ä¾‹æ˜¯å¦å·²å…³é—­
        if self._closed:
            raise RuntimeError(f"HFInferenceEmbedding å®ä¾‹å·²å…³é—­ï¼Œæ— æ³•ç»§ç»­è¯·æ±‚")
        
        if retry_count > 0:
            logger.warning(f"âš ï¸  é‡è¯•è¯·æ±‚ ({retry_count}/3): æ¨¡å‹={self.model_name}, æ–‡æœ¬æ•°é‡={len(texts)}")
        else:
            logger.debug(f"ğŸ“¤ HF Inference API è¯·æ±‚: æ¨¡å‹={self.model_name}, æ–‡æœ¬æ•°é‡={len(texts)}")
        
        # åˆ›å»ºè¯·æ±‚æ ‡è¯†ç¬¦ç”¨äºè·Ÿè¸ª
        request_id = id(texts)
        self._active_requests.add(request_id)
        
        try:
            # æ‰¹æ¬¡æ€»æ—¶é—´ç›‘æ§
            with TimeMonitor(
                logger,
                f"â±ï¸  HF Inference API è°ƒç”¨è¿›è¡Œä¸­: å·²èŠ±è´¹ {{elapsed}} ç§’ (æ¨¡å‹={self.model_name}, æ–‡æœ¬æ•°é‡={len(texts)})"
            ):
                try:
                    results = []
                    total = len(texts)
                    
                    # feature_extraction ä¸€æ¬¡åªèƒ½å¤„ç†ä¸€ä¸ªæ–‡æœ¬ï¼Œé€ä¸ªå¤„ç†
                    for idx, text in enumerate(texts):
                        # æ¯ä¸ªæ–‡æœ¬å¤„ç†æ—¶é—´ç›‘æ§
                        with TimeMonitor(
                            logger,
                            f"â±ï¸  å¤„ç†æ–‡æœ¬ {idx + 1}/{total}: å·²èŠ±è´¹ {{elapsed}} ç§’"
                        ):
                            # æ„å»ºè¯·æ±‚ payload
                            payload = {"inputs": text}
                            
                            # è®°å½•è¯·æ±‚ä¿¡æ¯ï¼ˆcurl å‘½ä»¤æ ¼å¼ï¼‰
                            logger.info(f"ğŸ“¤ å‘é€ HTTP è¯·æ±‚:")
                            logger.info(f"   URL: {self.api_url}")
                            logger.info(f"   Method: POST")
                            logger.info(f"   Headers: {json.dumps({k: v if k != 'Authorization' else 'Bearer ***' for k, v in self.headers.items()}, ensure_ascii=False, indent=2)}")
                            logger.info(f"   Payload: {json.dumps(payload, ensure_ascii=False, indent=2)}")
                            
                            # ç”Ÿæˆ curl å‘½ä»¤ï¼ˆç”¨äºè°ƒè¯•ï¼Œéšè—å¯†é’¥ï¼‰
                            curl_command = (
                                f"curl -X POST '{self.api_url}' \\\n"
                                f"  -H 'Authorization: Bearer $HF_TOKEN' \\\n"
                                f"  -H 'Content-Type: application/json' \\\n"
                                f"  -d '{json.dumps(payload, ensure_ascii=False)}'"
                            )
                            logger.info(f"   ğŸ“‹ curl å‘½ä»¤ (ä½¿ç”¨ç¯å¢ƒå˜é‡ HF_TOKEN):\n{curl_command}")
                            
                            # æ£€æŸ¥æ˜¯å¦å·²å…³é—­ï¼ˆåœ¨è¯·æ±‚å‰å†æ¬¡æ£€æŸ¥ï¼‰
                            if self._closed:
                                raise RuntimeError("HFInferenceEmbedding å®ä¾‹å·²å…³é—­ï¼Œè¯·æ±‚è¢«å–æ¶ˆ")
                            
                            # ä½¿ç”¨ç›´æ¥ HTTP è¯·æ±‚è°ƒç”¨ API
                            request_start = time.time()
                            try:
                                response = requests.post(
                                    self.api_url,
                                    headers=self.headers,
                                    json=payload,
                                    timeout=30,
                                )
                            except requests.exceptions.RequestException as e:
                                # å¦‚æœå·²å…³é—­ï¼Œä¸é‡è¯•
                                if self._closed:
                                    raise RuntimeError("HFInferenceEmbedding å®ä¾‹å·²å…³é—­ï¼Œè¯·æ±‚è¢«å–æ¶ˆ") from e
                                raise
                            request_elapsed = time.time() - request_start
                            
                            # è®°å½•å“åº”ä¿¡æ¯
                            logger.info(f"ğŸ“¥ æ”¶åˆ° HTTP å“åº”:")
                            logger.info(f"   çŠ¶æ€ç : {response.status_code}")
                            logger.info(f"   å“åº”æ—¶é—´: {request_elapsed:.2f} ç§’")
                            logger.info(f"   Headers: {dict(response.headers)}")
                            
                            response.raise_for_status()  # è‡ªåŠ¨å¤„ç† HTTP é”™è¯¯
                            
                            # è§£æå“åº”
                            try:
                                result = response.json()
                                # è®°å½•å“åº”æ•°æ®ï¼ˆé™åˆ¶é•¿åº¦ï¼Œé¿å…æ—¥å¿—è¿‡é•¿ï¼‰
                                result_str = json.dumps(result, ensure_ascii=False)
                                if len(result_str) > 1000:
                                    logger.info(f"   å“åº”æ•°æ® (å‰1000å­—ç¬¦): {result_str[:1000]}...")
                                    logger.info(f"   å“åº”æ•°æ®é•¿åº¦: {len(result_str)} å­—ç¬¦")
                                    if isinstance(result, list) and len(result) > 0:
                                        logger.info(f"   å‘é‡ç»´åº¦: {len(result)}")
                                        logger.info(f"   å‘é‡å‰5ä¸ªå€¼: {result[:5]}")
                                        logger.info(f"   å‘é‡å5ä¸ªå€¼: {result[-5:]}")
                                else:
                                    logger.info(f"   å“åº”æ•°æ®: {result_str}")
                                
                                # å¤„ç†å“åº”æ ¼å¼å¹¶è½¬æ¢ä¸ºåˆ—è¡¨
                                if isinstance(result, list):
                                    # ç›´æ¥æ˜¯å‘é‡åˆ—è¡¨
                                    embedding = [float(x) for x in result]
                                elif isinstance(result, dict):
                                    # å¯èƒ½æ˜¯åŒ…è£…åœ¨å­—å…¸ä¸­çš„æ ¼å¼
                                    if "embeddings" in result:
                                        embedding = [float(x) for x in result["embeddings"]]
                                    elif "output" in result:
                                        embedding = [float(x) for x in result["output"]]
                                    else:
                                        # å°è¯•ç›´æ¥ä½¿ç”¨ç¬¬ä¸€ä¸ªå€¼
                                        first_key = next(iter(result.values()))
                                        if isinstance(first_key, list):
                                            embedding = [float(x) for x in first_key]
                                        else:
                                            embedding = [float(first_key)]
                                else:
                                    # å•ä¸ªå€¼æˆ–å…¶ä»–æ ¼å¼
                                    embedding = [float(result)] if not isinstance(result, list) else [float(x) for x in result]
                                
                                results.append(embedding)
                                
                                # æ‰¹é‡å¤„ç†æ—¶æ˜¾ç¤ºè¿›åº¦
                                if total > 1 and (idx + 1) % 10 == 0:
                                    logger.debug(f"   è¿›åº¦: {idx + 1}/{total}")
                            except json.JSONDecodeError as e:
                                logger.error(f"   âŒ JSON è§£æå¤±è´¥: {e}")
                                logger.error(f"   å“åº”æ–‡æœ¬: {response.text[:500]}")
                                raise
                    
                    if total > 1:
                        logger.debug(f"ğŸ“¥ æ‰¹é‡å¤„ç†å®Œæˆ: {len(results)}/{total} ä¸ªæ–‡æœ¬")
                    
                    return results
                            
                except RequestException as e:
                    # ç»Ÿä¸€é”™è¯¯å¤„ç†ï¼šå…¨éƒ¨é‡è¯•
                    return self._handle_request_error(e, texts, retry_count)
                except Exception as e:
                    # å¤„ç†å…¶ä»–å¼‚å¸¸ï¼ˆå¦‚ JSON è§£æé”™è¯¯ç­‰ï¼‰
                    return self._handle_request_error(e, texts, retry_count)
        finally:
            # ç§»é™¤è¯·æ±‚è·Ÿè¸ª
            self._active_requests.discard(request_id)
    
    def _handle_request_error(
        self,
        error: Exception,
        texts: List[str],
        retry_count: int
    ) -> List[List[float]]:
        """å¤„ç† API è¯·æ±‚é”™è¯¯ï¼ˆç»Ÿä¸€é‡è¯•ç­–ç•¥ï¼‰
        
        Args:
            error: æ•è·çš„å¼‚å¸¸
            texts: è¯·æ±‚çš„æ–‡æœ¬åˆ—è¡¨
            retry_count: å½“å‰é‡è¯•æ¬¡æ•°
            
        Returns:
            å‘é‡åˆ—è¡¨ï¼ˆé‡è¯•æˆåŠŸæ—¶ï¼‰
            
        Raises:
            RuntimeError: é‡è¯•æ¬¡æ•°ç”¨å°½
        """
        max_retries = 3
        
        # æ„å»ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_details = str(error)
        if isinstance(error, RequestException):
            if hasattr(error, 'response') and error.response is not None:
                try:
                    error_body = error.response.text[:200]  # é™åˆ¶é•¿åº¦
                    error_details = f"HTTP {error.response.status_code}: {error_body}"
                except Exception:
                    error_details = f"HTTP {error.response.status_code}: {str(error)}"
        
        if retry_count < max_retries:
            wait_time = (retry_count + 1) * 1.0
            logger.warning(
                f"âŒ API è¯·æ±‚å¤±è´¥: {error.__class__.__name__}: {error_details}ã€‚"
                f"{wait_time:.1f}ç§’åé‡è¯• ({retry_count + 1}/{max_retries})"
            )
            time.sleep(wait_time)
            return self._make_request(texts, retry_count + 1)
        else:
            logger.error(f"âŒ API è°ƒç”¨å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {error_details}")
            raise RuntimeError(
                f"Hugging Face Inference API è°ƒç”¨å¤±è´¥ï¼ˆæ¨¡å‹: {self.model_name}ï¼‰: {error_details}"
            ) from error
    
    def get_query_embedding(self, query: str) -> List[float]:
        """ç”ŸæˆæŸ¥è¯¢å‘é‡"""
        embeddings = self.get_text_embeddings([query])
        return embeddings[0]
    
    def get_text_embeddings(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡
        
        æ”¯æŒæ‰¹é‡å¤„ç†ï¼Œè‡ªåŠ¨åˆ†æ‰¹ä»¥é¿å…å•æ¬¡è¯·æ±‚è¿‡å¤§ã€‚
        ç”±äº feature_extraction ä¸€æ¬¡åªèƒ½å¤„ç†ä¸€ä¸ªæ–‡æœ¬ï¼Œå†…éƒ¨ä¼šé€ä¸ªå¤„ç†ã€‚
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            å‘é‡åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æœ¬å¯¹åº”ä¸€ä¸ªå‘é‡
        """
        if not texts:
            return []
        
        # åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š 100 ä¸ªæ–‡æœ¬
        batch_size = 100
        total_batches = (len(texts) + batch_size - 1) // batch_size
        all_embeddings = []
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            if total_batches > 1:
                logger.debug(f"å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)} ä¸ªæ–‡æœ¬)")
            
            batch_embeddings = self._make_request(batch)
            all_embeddings.extend(batch_embeddings)
        
        return all_embeddings
    
    def get_embedding_dimension(self) -> int:
        """è·å–å‘é‡ç»´åº¦ï¼ˆç¡®ä¿æ€»æ˜¯è¿”å›æœ‰æ•ˆå€¼ï¼‰"""
        if self._dimension is None:
            self._dimension = self._get_default_dimension(self.model_name)
            logger.debug(f"ä½¿ç”¨é»˜è®¤ç»´åº¦: {self._dimension}")
            try:
                test_embedding = self.get_query_embedding("test")
                detected_dim = len(test_embedding)
                if detected_dim != self._dimension:
                    logger.info(f"ğŸ”„ æ£€æµ‹åˆ°å®é™…ç»´åº¦ {detected_dim}ï¼Œæ›´æ–°é»˜è®¤å€¼ {self._dimension}")
                    self._dimension = detected_dim
            except Exception as e:
                logger.warning(f"âš ï¸  æ— æ³•é€šè¿‡APIè·å–ç»´åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
        return self._dimension
    
    def get_model_name(self) -> str:
        """è·å–æ¨¡å‹åç§°"""
        return self.model_name
    
    def close(self) -> None:
        """å…³é—­å®ä¾‹ï¼Œæ¸…ç†èµ„æº
        
        åœæ­¢æ‰€æœ‰æ­£åœ¨è¿›è¡Œçš„è¯·æ±‚ï¼Œæ¸…ç†çº¿ç¨‹å’Œè¿æ¥ã€‚
        åº”è¯¥åœ¨åº”ç”¨é€€å‡ºæ—¶è°ƒç”¨æ­¤æ–¹æ³•ã€‚
        """
        if self._closed:
            return
        
        logger.info(f"ğŸ”§ å¼€å§‹å…³é—­ HFInferenceEmbedding å®ä¾‹: {self.model_name}")
        self._closed = True
        
        # ç­‰å¾…æ­£åœ¨è¿›è¡Œçš„è¯·æ±‚å®Œæˆï¼ˆæœ€å¤šç­‰å¾…5ç§’ï¼‰
        if self._active_requests:
            logger.debug(f"ç­‰å¾… {len(self._active_requests)} ä¸ªæ­£åœ¨è¿›è¡Œçš„è¯·æ±‚å®Œæˆ...")
            start_wait = time.time()
            while self._active_requests and (time.time() - start_wait) < 5.0:
                time.sleep(0.1)
            
            if self._active_requests:
                logger.warning(f"âš ï¸  ä»æœ‰ {len(self._active_requests)} ä¸ªè¯·æ±‚æœªå®Œæˆï¼Œå¼ºåˆ¶å…³é—­")
        
        # æ¸…ç†å¼•ç”¨
        self._active_requests.clear()
        logger.info(f"âœ… HFInferenceEmbedding å®ä¾‹å·²å…³é—­: {self.model_name}")
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿èµ„æºè¢«æ¸…ç†"""
        if not self._closed:
            try:
                self.close()
            except Exception:
                pass  # ææ„å‡½æ•°ä¸­ä¸åº”è¯¥æŠ›å‡ºå¼‚å¸¸
    
    def get_llama_index_embedding(self):
        """è·å–LlamaIndexå…¼å®¹çš„Embeddingé€‚é…å™¨
        
        Returns:
            LlamaIndexå…¼å®¹çš„é€‚é…å™¨åŒ…è£…å™¨ï¼ˆç»§æ‰¿è‡ªLlamaIndex BaseEmbeddingï¼‰
            
        Raises:
            ImportError: å¦‚æœæ— æ³•å¯¼å…¥LlamaIndex BaseEmbedding
        """
        # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…æ¨¡å—åŠ è½½æ—¶å‡ºé”™
        # ä¼˜å…ˆç›´æ¥å¯¼å…¥ BaseEmbeddingï¼ˆè€Œä¸æ˜¯é€šè¿‡ HuggingFaceEmbedding è·å–ï¼‰
        LlamaBaseEmbedding = None
        try:
            from llama_index.core.embeddings.base import BaseEmbedding as LlamaBaseEmbedding
            logger.debug("âœ… æˆåŠŸå¯¼å…¥ llama_index.core.embeddings.base.BaseEmbedding")
        except ImportError:
            try:
                from llama_index.embeddings.base import BaseEmbedding as LlamaBaseEmbedding
                logger.debug("âœ… æˆåŠŸå¯¼å…¥ llama_index.embeddings.base.BaseEmbedding")
            except ImportError:
                # å¦‚æœç›´æ¥å¯¼å…¥å¤±è´¥ï¼Œå°è¯•é€šè¿‡ HuggingFaceEmbedding çš„ MRO æ‰¾åˆ° BaseEmbedding
                try:
                    from llama_index.embeddings.huggingface import HuggingFaceEmbedding
                    # é€šè¿‡ MRO æ‰¾åˆ° BaseEmbeddingï¼ˆè€Œä¸æ˜¯ç›´æ¥å– __bases__[0]ï¼‰
                    for base_class in HuggingFaceEmbedding.__mro__:
                        if base_class.__name__ == 'BaseEmbedding' and 'embeddings' in base_class.__module__:
                            LlamaBaseEmbedding = base_class
                            logger.debug(f"âœ… é€šè¿‡MROæ‰¾åˆ°BaseEmbedding: {base_class.__module__}.{base_class.__name__}")
                            break
                    
                    if LlamaBaseEmbedding is None:
                        raise ImportError("æ— æ³•åœ¨ HuggingFaceEmbedding çš„ MRO ä¸­æ‰¾åˆ° BaseEmbedding")
                except (ImportError, AttributeError) as e:
                    # å¦‚æœéƒ½å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯è€Œä¸æ˜¯è¿”å›ä¸å…¼å®¹çš„å¯¹è±¡
                    error_msg = (
                        "æ— æ³•å¯¼å…¥LlamaIndex BaseEmbeddingã€‚"
                        "è¯·ç¡®ä¿å·²å®‰è£… llama-index æˆ– llama-index-coreã€‚"
                        f"é”™è¯¯è¯¦æƒ…: {e}"
                    )
                    logger.error(error_msg)
                    raise ImportError(error_msg) from e
        
        # éªŒè¯è·å–åˆ°çš„ç¡®å®æ˜¯ BaseEmbeddingï¼ˆä¸æ˜¯ MultiModalEmbedding æˆ–å…¶ä»–ï¼‰
        if LlamaBaseEmbedding and LlamaBaseEmbedding.__name__ != 'BaseEmbedding':
            error_msg = (
                f"è·å–åˆ°çš„åŸºç±»ä¸æ˜¯ BaseEmbeddingï¼Œè€Œæ˜¯ {LlamaBaseEmbedding.__name__}ã€‚"
                f"è¿™å¯èƒ½å¯¼è‡´é€‚é…å™¨éœ€è¦å®ç°é¢å¤–çš„æŠ½è±¡æ–¹æ³•ã€‚"
            )
            logger.warning(error_msg)
        
        # åŠ¨æ€åˆ›å»ºç»§æ‰¿LlamaBaseEmbeddingçš„é€‚é…å™¨ç±»
        class LlamaIndexEmbeddingAdapter(LlamaBaseEmbedding):
            """LlamaIndexå…¼å®¹çš„Embeddingé€‚é…å™¨åŒ…è£…å™¨"""
            
            def __init__(self, embedding: HFInferenceEmbedding):
                # å…ˆè°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ï¼ˆPydantic æ¨¡å‹éœ€è¦å…ˆåˆå§‹åŒ–ï¼‰
                model_name = embedding.get_model_name()
                try:
                    # å°è¯•ä½¿ç”¨ model_name å‚æ•°åˆå§‹åŒ–
                    super().__init__(model_name=model_name)
                except (TypeError, AttributeError) as e:
                    try:
                        # å°è¯•æ— å‚æ•°åˆå§‹åŒ–
                        super().__init__()
                    except Exception as init_error:
                        # å¦‚æœçˆ¶ç±»åˆå§‹åŒ–å¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­
                        logger.debug(f"çˆ¶ç±»åˆå§‹åŒ–å¤±è´¥: {init_error}")
                        # å³ä½¿åˆå§‹åŒ–å¤±è´¥ï¼Œä¹Ÿç»§ç»­ï¼ˆå¯èƒ½ä¸éœ€è¦å‚æ•°ï¼‰
                        pass
                
                # çˆ¶ç±»åˆå§‹åŒ–åå†è®¾ç½®å±æ€§ï¼ˆä½¿ç”¨ object.__setattr__ ç»•è¿‡ Pydantic éªŒè¯ï¼‰
                # è¿™æ ·å¯ä»¥é¿å… Pydantic çš„å­—æ®µéªŒè¯é—®é¢˜
                object.__setattr__(self, '_embedding', embedding)
                # model_name å¯èƒ½å·²ç»åœ¨ super().__init__() ä¸­è®¾ç½®äº†ï¼Œå¦‚æœæ²¡æœ‰åˆ™è®¾ç½®
                if not hasattr(self, 'model_name') or self.model_name != model_name:
                    try:
                        self.model_name = model_name
                    except (AttributeError, ValueError):
                        # å¦‚æœ Pydantic ä¸å…è®¸ç›´æ¥è®¾ç½®ï¼Œä½¿ç”¨ object.__setattr__
                        object.__setattr__(self, 'model_name', model_name)
            
            def _get_query_embedding(self, query: str) -> List[float]:
                """ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼ŒåŒæ­¥ï¼‰"""
                return self._embedding.get_query_embedding(query)
            
            def _get_text_embedding(self, text: str) -> List[float]:
                """ç”Ÿæˆå•ä¸ªæ–‡æœ¬å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼ŒåŒæ­¥ï¼‰"""
                embeddings = self._embedding.get_text_embeddings([text])
                return embeddings[0] if embeddings else []
            
            def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:
                """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼ŒåŒæ­¥ï¼‰"""
                return self._embedding.get_text_embeddings(texts)
            
            async def _aget_query_embedding(self, query: str) -> List[float]:
                """ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼Œå¼‚æ­¥ï¼‰"""
                # ä½¿ç”¨è‡ªå®šä¹‰çº¿ç¨‹æ± æ‰§è¡Œå™¨ï¼Œç¡®ä¿å¯ä»¥æ­£ç¡®å…³é—­
                executor = _get_or_create_executor()
                loop = asyncio.get_event_loop()
                return await loop.run_in_executor(executor, self._embedding.get_query_embedding, query)
            
            async def _aget_text_embedding(self, text: str) -> List[float]:
                """ç”Ÿæˆå•ä¸ªæ–‡æœ¬å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼Œå¼‚æ­¥ï¼‰"""
                # ä½¿ç”¨è‡ªå®šä¹‰çº¿ç¨‹æ± æ‰§è¡Œå™¨ï¼Œç¡®ä¿å¯ä»¥æ­£ç¡®å…³é—­
                executor = _get_or_create_executor()
                loop = asyncio.get_event_loop()
                embeddings = await loop.run_in_executor(executor, self._embedding.get_text_embeddings, [text])
                return embeddings[0] if embeddings else []
            
            async def _aget_text_embeddings(self, texts: List[str]) -> List[List[float]]:
                """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼Œå¼‚æ­¥ï¼‰"""
                # ä½¿ç”¨è‡ªå®šä¹‰çº¿ç¨‹æ± æ‰§è¡Œå™¨ï¼Œç¡®ä¿å¯ä»¥æ­£ç¡®å…³é—­
                executor = _get_or_create_executor()
                loop = asyncio.get_event_loop()
                return await loop.run_in_executor(executor, self._embedding.get_text_embeddings, texts)
            
            def get_query_embedding(self, query: str) -> List[float]:
                """ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå…¼å®¹LlamaIndexæ¥å£ï¼‰"""
                return self._get_query_embedding(query)
            
            def get_text_embedding(self, text: str) -> List[float]:
                """ç”Ÿæˆå•ä¸ªæ–‡æœ¬å‘é‡ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå…¼å®¹LlamaIndexæ¥å£ï¼‰"""
                return self._get_text_embedding(text)
            
            def get_text_embedding_batch(self, texts: List[str], **kwargs) -> List[List[float]]:
                """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå…¼å®¹LlamaIndexæ¥å£ï¼‰
                
                Args:
                    texts: æ–‡æœ¬åˆ—è¡¨
                    **kwargs: é¢å¤–å‚æ•°ï¼ˆå¦‚ show_progressï¼‰ï¼Œä¼šè¢«å¿½ç•¥
                """
                return self._get_text_embeddings(texts)
        
        try:
            adapter = LlamaIndexEmbeddingAdapter(self)
        except TypeError as e:
            # å¦‚æœåˆ›å»ºé€‚é…å™¨å¤±è´¥ï¼ˆå¯èƒ½æ˜¯æŠ½è±¡æ–¹æ³•æœªå®ç°ï¼‰ï¼Œæä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_msg = (
                f"æ— æ³•åˆ›å»ºLlamaIndexé€‚é…å™¨: {e}ã€‚"
                f"è¿™å¯èƒ½æ˜¯å› ä¸ºåŸºç±» {LlamaBaseEmbedding.__name__} æœ‰æœªå®ç°çš„æŠ½è±¡æ–¹æ³•ã€‚"
                f"è¯·æ£€æŸ¥æ˜¯å¦éœ€è¦å®ç°é¢å¤–çš„æŠ½è±¡æ–¹æ³•ã€‚"
            )
            logger.error(error_msg)
            raise TypeError(error_msg) from e
        
        # éªŒè¯é€‚é…å™¨ç¡®å®æ˜¯BaseEmbeddingçš„å®ä¾‹
        if not isinstance(adapter, LlamaBaseEmbedding):
            error_msg = (
                f"åˆ›å»ºçš„é€‚é…å™¨ä¸æ˜¯LlamaIndex BaseEmbeddingçš„å®ä¾‹ã€‚"
                f"ç±»å‹: {type(adapter)}, æœŸæœ›: {LlamaBaseEmbedding}"
            )
            logger.error(error_msg)
            raise TypeError(error_msg)
        
        logger.debug(f"âœ… æˆåŠŸåˆ›å»ºLlamaIndexé€‚é…å™¨: {type(adapter)}")
        return adapter


class _SimpleAdapter:
    """ç®€å•çš„é€‚é…å™¨åŒ…è£…å™¨ï¼ˆå½“æ— æ³•å¯¼å…¥LlamaIndex BaseEmbeddingæ—¶ä½¿ç”¨ï¼‰"""
    
    def __init__(self, embedding: HFInferenceEmbedding):
        self._embedding = embedding
        self.model_name = embedding.get_model_name()
    
    def get_query_embedding(self, query: str) -> List[float]:
        return self._embedding.get_query_embedding(query)
    
    def get_text_embedding(self, text: str) -> List[float]:
        embeddings = self._embedding.get_text_embeddings([text])
        return embeddings[0] if embeddings else []
    
    def _get_query_embedding(self, query: str) -> List[float]:
        """ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼‰"""
        return self._embedding.get_query_embedding(query)
    
    def _get_text_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆå•ä¸ªæ–‡æœ¬å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼‰"""
        embeddings = self._embedding.get_text_embeddings([text])
        return embeddings[0] if embeddings else []
    
    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆLlamaIndexæ¥å£ï¼Œç§æœ‰æ–¹æ³•ï¼‰"""
        return self._embedding.get_text_embeddings(texts)
    
    def get_query_embedding(self, query: str) -> List[float]:
        """ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå…¼å®¹LlamaIndexæ¥å£ï¼‰"""
        return self._get_query_embedding(query)
    
    def get_text_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆå•ä¸ªæ–‡æœ¬å‘é‡ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå…¼å®¹LlamaIndexæ¥å£ï¼‰"""
        return self._get_text_embedding(text)
    
    def get_text_embedding_batch(self, texts: List[str], **kwargs) -> List[List[float]]:
        """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆå…¬å…±æ–¹æ³•ï¼Œå…¼å®¹LlamaIndexæ¥å£ï¼‰
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            **kwargs: é¢å¤–å‚æ•°ï¼ˆå¦‚ show_progressï¼‰ï¼Œä¼šè¢«å¿½ç•¥
        """
        return self._get_text_embeddings(texts)
