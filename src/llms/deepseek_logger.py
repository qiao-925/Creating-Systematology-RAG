"""
DeepSeek LLM æ—¥å¿—åŒ…è£…å™¨
æ‹¦æˆª DeepSeek API è°ƒç”¨ï¼Œè®°å½•è¯·æ±‚ä½“å’Œè¿”å›å€¼
"""

import json
from typing import Any, Optional, Dict, List
from llama_index.core.llms import CompletionResponse, ChatResponse, LLMMetadata
from llama_index.llms.deepseek import DeepSeek

from src.logger import setup_logger

logger = setup_logger('deepseek_logger')


class DeepSeekLogger:
    """DeepSeek LLM åŒ…è£…å™¨ï¼Œè®°å½•æ‰€æœ‰ API è°ƒç”¨
    
    åŒ…è£… DeepSeek å®ä¾‹ï¼Œæ‹¦æˆª complete å’Œ chat æ–¹æ³•ï¼Œ
    åœ¨è°ƒç”¨å‰åè®°å½•è¯·æ±‚å‚æ•°å’Œå“åº”ç»“æœã€‚
    """
    
    def __init__(self, deepseek_instance: DeepSeek):
        """åˆå§‹åŒ–æ—¥å¿—åŒ…è£…å™¨
        
        Args:
            deepseek_instance: DeepSeek å®ä¾‹
        """
        self._llm = deepseek_instance
        
        # ç›´æ¥æ›¿æ¢æ–¹æ³•ï¼Œè€Œä¸æ˜¯ä¾èµ– __getattr__
        # è¿™æ ·ç¡®ä¿å³ä½¿æ–¹æ³•å·²å­˜åœ¨ä¹Ÿä¼šè¢«æ‹¦æˆª
        self.complete = self._complete_with_logging
        self.chat = self._chat_with_logging
        self.stream_complete = self._stream_complete_with_logging
        self.stream_chat = self._stream_chat_with_logging
        
        logger.info("DeepSeek æ—¥å¿—åŒ…è£…å™¨å·²åˆå§‹åŒ–")
    
    def __getattr__(self, name: str) -> Any:
        """ä»£ç†æ‰€æœ‰å…¶ä»–å±æ€§å’Œæ–¹æ³•åˆ°åŸå§‹ DeepSeek å®ä¾‹"""
        # å¯¹äºæœªæ‹¦æˆªçš„æ–¹æ³•ï¼Œç›´æ¥ä»£ç†åˆ°åŸå§‹å®ä¾‹
        return getattr(self._llm, name)
    
    def _complete_with_logging(self, prompt: str, **kwargs) -> CompletionResponse:
        """åŒ…è£… complete æ–¹æ³•ï¼Œè®°å½•è¯·æ±‚å’Œå“åº”
        
        Args:
            prompt: æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            CompletionResponse: å®Œæˆå“åº”
        """
        # æ„å»ºè¯·æ±‚ä½“
        request_body = {
            "prompt": prompt,
            **kwargs
        }
        
        # è®°å½•è¯·æ±‚
        logger.info("=" * 80)
        logger.info("ğŸ”µ DeepSeek API è°ƒç”¨ - complete")
        logger.info("-" * 80)
        logger.info(f"ğŸ“¤ è¯·æ±‚ä½“:")
        logger.info(f"   æ¨¡å‹: {self._llm.model}")
        logger.info(f"   æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
        logger.info(f"   æç¤ºè¯å†…å®¹: {prompt[:500]}{'...' if len(prompt) > 500 else ''}")
        if kwargs:
            logger.info(f"   å…¶ä»–å‚æ•°: {json.dumps(kwargs, ensure_ascii=False, indent=2)}")
        logger.info("-" * 80)
        
        try:
            # è°ƒç”¨åŸå§‹æ–¹æ³•
            response = self._llm.complete(prompt, **kwargs)
            
            # è®°å½•å“åº”
            response_text = response.text if hasattr(response, 'text') else str(response)
            logger.info(f"ğŸ“¥ å“åº”ä½“:")
            logger.info(f"   å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
            logger.info(f"   å“åº”å†…å®¹: {response_text[:1000]}{'...' if len(response_text) > 1000 else ''}")
            
            # è®°å½•å…ƒæ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            if hasattr(response, 'raw') and response.raw:
                logger.debug(f"   åŸå§‹å“åº”: {json.dumps(response.raw, ensure_ascii=False, indent=2)}")
            
            logger.info("=" * 80)
            
            return response
            
        except Exception as e:
            logger.error(f"âŒ DeepSeek API è°ƒç”¨å¤±è´¥:")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error("=" * 80)
            raise
    
    def _chat_with_logging(self, messages, **kwargs) -> ChatResponse:
        """åŒ…è£… chat æ–¹æ³•ï¼Œè®°å½•è¯·æ±‚å’Œå“åº”
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ChatResponse: èŠå¤©å“åº”
        """
        # æ„å»ºè¯·æ±‚ä½“
        request_body = {
            "messages": messages,
            **kwargs
        }
        
        # è®°å½•è¯·æ±‚
        logger.info("=" * 80)
        logger.info("ğŸ”µ DeepSeek API è°ƒç”¨ - chat")
        logger.info("-" * 80)
        logger.info(f"ğŸ“¤ è¯·æ±‚ä½“:")
        logger.info(f"   æ¨¡å‹: {self._llm.model}")
        logger.info(f"   æ¶ˆæ¯æ•°é‡: {len(messages)}")
        for i, msg in enumerate(messages):
            # å¤„ç† ChatMessage å¯¹è±¡æˆ–å­—å…¸
            if hasattr(msg, 'role') and hasattr(msg, 'content'):
                role = msg.role.value if hasattr(msg.role, 'value') else str(msg.role)
                content = msg.content
            elif isinstance(msg, dict):
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')
            else:
                role = 'unknown'
                content = str(msg)
            logger.info(f"   æ¶ˆæ¯ {i+1} ({role}): {content[:200]}{'...' if len(content) > 200 else ''}")
        if kwargs:
            logger.info(f"   å…¶ä»–å‚æ•°: {json.dumps(kwargs, ensure_ascii=False, indent=2)}")
        logger.info("-" * 80)
        
        try:
            # è°ƒç”¨åŸå§‹æ–¹æ³•
            response = self._llm.chat(messages, **kwargs)
            
            # è®°å½•å“åº”
            response_message = response.message if hasattr(response, 'message') else None
            response_text = response_message.content if response_message and hasattr(response_message, 'content') else str(response)
            
            logger.info(f"ğŸ“¥ å“åº”ä½“:")
            logger.info(f"   å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
            logger.info(f"   å“åº”å†…å®¹: {response_text[:1000]}{'...' if len(response_text) > 1000 else ''}")
            
            # è®°å½•å…ƒæ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            if hasattr(response, 'raw') and response.raw:
                logger.debug(f"   åŸå§‹å“åº”: {json.dumps(response.raw, ensure_ascii=False, indent=2)}")
            
            logger.info("=" * 80)
            
            return response
            
        except Exception as e:
            logger.error(f"âŒ DeepSeek API è°ƒç”¨å¤±è´¥:")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error("=" * 80)
            raise
    
    def _stream_complete_with_logging(self, prompt: str, **kwargs):
        """åŒ…è£… stream_complete æ–¹æ³•ï¼Œè®°å½•è¯·æ±‚å’Œå“åº”æµ
        
        Args:
            prompt: æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields:
            CompletionResponse: æµå¼å®Œæˆå“åº”
        """
        # è®°å½•è¯·æ±‚
        logger.info("=" * 80)
        logger.info("ğŸ”µ DeepSeek API è°ƒç”¨ - stream_complete")
        logger.info("-" * 80)
        logger.info(f"ğŸ“¤ è¯·æ±‚ä½“:")
        logger.info(f"   æ¨¡å‹: {self._llm.model}")
        logger.info(f"   æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
        logger.info(f"   æç¤ºè¯å†…å®¹: {prompt[:500]}{'...' if len(prompt) > 500 else ''}")
        if kwargs:
            logger.info(f"   å…¶ä»–å‚æ•°: {json.dumps(kwargs, ensure_ascii=False, indent=2)}")
        logger.info("-" * 80)
        
        try:
            # è°ƒç”¨åŸå§‹æ–¹æ³•å¹¶æ”¶é›†å“åº”
            full_response = ""
            for chunk in self._llm.stream_complete(prompt, **kwargs):
                chunk_text = chunk.text if hasattr(chunk, 'text') else str(chunk)
                full_response += chunk_text
                yield chunk
            
            # è®°å½•å®Œæ•´å“åº”
            logger.info(f"ğŸ“¥ å“åº”ä½“ï¼ˆæµå¼ï¼‰:")
            logger.info(f"   å“åº”é•¿åº¦: {len(full_response)} å­—ç¬¦")
            logger.info(f"   å“åº”å†…å®¹: {full_response[:1000]}{'...' if len(full_response) > 1000 else ''}")
            logger.info("=" * 80)
            
        except Exception as e:
            logger.error(f"âŒ DeepSeek API è°ƒç”¨å¤±è´¥:")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error("=" * 80)
            raise
    
    def _stream_chat_with_logging(self, messages, **kwargs):
        """åŒ…è£… stream_chat æ–¹æ³•ï¼Œè®°å½•è¯·æ±‚å’Œå“åº”æµ
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields:
            ChatResponse: æµå¼èŠå¤©å“åº”
        """
        # è®°å½•è¯·æ±‚
        logger.info("=" * 80)
        logger.info("ğŸ”µ DeepSeek API è°ƒç”¨ - stream_chat")
        logger.info("-" * 80)
        logger.info(f"ğŸ“¤ è¯·æ±‚ä½“:")
        logger.info(f"   æ¨¡å‹: {self._llm.model}")
        logger.info(f"   æ¶ˆæ¯æ•°é‡: {len(messages)}")
        for i, msg in enumerate(messages):
            # å¤„ç† ChatMessage å¯¹è±¡æˆ–å­—å…¸
            if hasattr(msg, 'role') and hasattr(msg, 'content'):
                role = msg.role.value if hasattr(msg.role, 'value') else str(msg.role)
                content = msg.content
            elif isinstance(msg, dict):
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')
            else:
                role = 'unknown'
                content = str(msg)
            logger.info(f"   æ¶ˆæ¯ {i+1} ({role}): {content[:200]}{'...' if len(content) > 200 else ''}")
        if kwargs:
            logger.info(f"   å…¶ä»–å‚æ•°: {json.dumps(kwargs, ensure_ascii=False, indent=2)}")
        logger.info("-" * 80)
        
        try:
            # è°ƒç”¨åŸå§‹æ–¹æ³•å¹¶æ”¶é›†å“åº”
            full_response = ""
            for chunk in self._llm.stream_chat(messages, **kwargs):
                chunk_message = chunk.message if hasattr(chunk, 'message') else None
                chunk_text = chunk_message.content if chunk_message and hasattr(chunk_message, 'content') else str(chunk)
                full_response += chunk_text
                yield chunk
            
            # è®°å½•å®Œæ•´å“åº”
            logger.info(f"ğŸ“¥ å“åº”ä½“ï¼ˆæµå¼ï¼‰:")
            logger.info(f"   å“åº”é•¿åº¦: {len(full_response)} å­—ç¬¦")
            logger.info(f"   å“åº”å†…å®¹: {full_response[:1000]}{'...' if len(full_response) > 1000 else ''}")
            logger.info("=" * 80)
            
        except Exception as e:
            logger.error(f"âŒ DeepSeek API è°ƒç”¨å¤±è´¥:")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error("=" * 80)
            raise


def wrap_deepseek(deepseek_instance: DeepSeek) -> DeepSeekLogger:
    """åŒ…è£… DeepSeek å®ä¾‹ï¼Œæ·»åŠ æ—¥å¿—è®°å½•åŠŸèƒ½
    
    Args:
        deepseek_instance: DeepSeek å®ä¾‹
        
    Returns:
        åŒ…è£…åçš„ DeepSeekLogger å®ä¾‹
    """
    return DeepSeekLogger(deepseek_instance)

