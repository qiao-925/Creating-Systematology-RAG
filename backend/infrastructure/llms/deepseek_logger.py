"""
DeepSeek LLM æ—¥å¿—åŒ…è£…å™¨
æ‹¦æˆª DeepSeek API è°ƒç”¨ï¼Œè®°å½•è¯·æ±‚ä½“å’Œè¿”å›å€¼
"""

import json
import time
from typing import Any, Optional, Dict, List
from llama_index.core.llms import CompletionResponse, ChatResponse, LLMMetadata
from llama_index.llms.deepseek import DeepSeek

from backend.infrastructure.logger import get_logger
from backend.infrastructure.llms.reasoning import clean_messages_for_api

logger = get_logger('deepseek_logger')


class DeepSeekLogger:
    """DeepSeek LLM åŒ…è£…å™¨ï¼Œè®°å½•æ‰€æœ‰ API è°ƒç”¨
    
    åŒ…è£… DeepSeek å®ä¾‹ï¼Œæ‹¦æˆª complete å’Œ chat æ–¹æ³•ï¼Œ
    åœ¨è°ƒç”¨å‰åè®°å½•è¯·æ±‚å‚æ•°å’Œå“åº”ç»“æœã€‚
    """
    
    def __init__(self, deepseek_instance: DeepSeek):
        """åˆå§‹åŒ–æ—¥å¿—åŒ…è£…å™¨
        
        Args:
            deepseek_instance: DeepSeek å®ä¾‹
        """
        self._llm = deepseek_instance
        
        # ç›´æ¥æ›¿æ¢æ–¹æ³•ï¼Œè€Œä¸æ˜¯ä¾èµ– __getattr__
        # è¿™æ ·ç¡®ä¿å³ä½¿æ–¹æ³•å·²å­˜åœ¨ä¹Ÿä¼šè¢«æ‹¦æˆª
        self.complete = self._complete_with_logging
        self.chat = self._chat_with_logging
        self.stream_complete = self._stream_complete_with_logging
        self.stream_chat = self._stream_chat_with_logging
        
        logger.info("DeepSeek æ—¥å¿—åŒ…è£…å™¨å·²åˆå§‹åŒ–")
    
    def __getattr__(self, name: str) -> Any:
        """ä»£ç†æ‰€æœ‰å…¶ä»–å±æ€§å’Œæ–¹æ³•åˆ°åŸå§‹ DeepSeek å®ä¾‹"""
        # å¯¹äºæœªæ‹¦æˆªçš„æ–¹æ³•ï¼Œç›´æ¥ä»£ç†åˆ°åŸå§‹å®ä¾‹
        return getattr(self._llm, name)
    
    def _complete_with_logging(self, prompt: str, **kwargs) -> CompletionResponse:
        """åŒ…è£… complete æ–¹æ³•ï¼Œè®°å½•è¯·æ±‚å’Œå“åº”
        
        Args:
            prompt: æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            CompletionResponse: å®Œæˆå“åº”
        """
        # æ„å»ºè¯·æ±‚ä½“
        request_body = {
            "prompt": prompt,
            **kwargs
        }
        
        # è®°å½•è¯·æ±‚
        logger.info("=" * 80)
        logger.info("ğŸ”µ DeepSeek API è°ƒç”¨ - complete")
        logger.info("-" * 80)
        logger.info(f"ğŸ“¤ è¯·æ±‚ä½“:")
        logger.info(f"   æ¨¡å‹: {self._llm.model}")
        logger.info(f"   æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
        logger.info(f"   æç¤ºè¯å†…å®¹: {prompt[:500]}{'...' if len(prompt) > 500 else ''}")
        if kwargs:
            logger.info(f"   å…¶ä»–å‚æ•°: {json.dumps(kwargs, ensure_ascii=False, indent=2)}")
        logger.info("-" * 80)
        
        try:
            # è°ƒç”¨åŸå§‹æ–¹æ³•
            response = self._llm.complete(prompt, **kwargs)
            
            # è®°å½•å“åº”
            response_text = response.text if hasattr(response, 'text') else str(response)
            logger.info(f"ğŸ“¥ å“åº”ä½“:")
            logger.info(f"   å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
            logger.info(f"   å“åº”å†…å®¹: {response_text[:1000]}{'...' if len(response_text) > 1000 else ''}")
            
            # è®°å½•å…ƒæ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            if hasattr(response, 'raw') and response.raw:
                try:
                    # å°è¯•åºåˆ—åŒ–åŸå§‹å“åº”ï¼ˆå¦‚æœæ˜¯å­—å…¸æˆ–å¯åºåˆ—åŒ–å¯¹è±¡ï¼‰
                    if isinstance(response.raw, dict):
                        logger.debug(f"   åŸå§‹å“åº”: {json.dumps(response.raw, ensure_ascii=False, indent=2)}")
                    else:
                        logger.debug(f"   åŸå§‹å“åº”ç±»å‹: {type(response.raw)}")
                except (TypeError, ValueError):
                    # å¦‚æœæ— æ³•åºåˆ—åŒ–ï¼ˆå¦‚ ChatCompletion å¯¹è±¡ï¼‰ï¼Œåªè®°å½•ç±»å‹
                    logger.debug(f"   åŸå§‹å“åº”ç±»å‹: {type(response.raw)}ï¼ˆæ— æ³•åºåˆ—åŒ–ï¼‰")
            
            logger.info("=" * 80)
            
            return response
            
        except Exception as e:
            logger.error(f"âŒ DeepSeek API è°ƒç”¨å¤±è´¥:")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error("=" * 80)
            raise
    
    def _chat_with_logging(self, messages, **kwargs) -> ChatResponse:
        """åŒ…è£… chat æ–¹æ³•ï¼Œè®°å½•è¯·æ±‚å’Œå“åº”
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ChatResponse: èŠå¤©å“åº”
        """
        # æ„å»ºè¯·æ±‚ä½“
        request_body = {
            "messages": messages,
            **kwargs
        }
        
        # è®°å½•è¯·æ±‚
        logger.info("=" * 80)
        logger.info("ğŸ”µ DeepSeek API è°ƒç”¨ - chat")
        logger.info("-" * 80)
        logger.info(f"ğŸ“¤ è¯·æ±‚ä½“:")
        logger.info(f"   æ¨¡å‹: {self._llm.model}")
        logger.info(f"   æ¶ˆæ¯æ•°é‡: {len(messages)}")
        for i, msg in enumerate(messages):
            # å¤„ç† ChatMessage å¯¹è±¡æˆ–å­—å…¸
            if hasattr(msg, 'role') and hasattr(msg, 'content'):
                role = msg.role.value if hasattr(msg.role, 'value') else str(msg.role)
                content = msg.content
            elif isinstance(msg, dict):
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')
            else:
                role = 'unknown'
                content = str(msg)
            logger.info(f"   æ¶ˆæ¯ {i+1} ({role}): {content[:200]}{'...' if len(content) > 200 else ''}")
        if kwargs:
            logger.info(f"   å…¶ä»–å‚æ•°: {json.dumps(kwargs, ensure_ascii=False, indent=2)}")
        logger.info("-" * 80)
        
        try:
            # æ¸…ç†æ¶ˆæ¯ï¼Œç¡®ä¿ä¸åŒ…å« reasoning_contentï¼ˆç¬¦åˆ DeepSeek API è¦æ±‚ï¼‰
            cleaned_messages = clean_messages_for_api(messages)
            
            # è°ƒç”¨åŸå§‹æ–¹æ³•ï¼ˆä½¿ç”¨æ¸…ç†åçš„æ¶ˆæ¯ï¼‰
            response = self._llm.chat(cleaned_messages, **kwargs)
            
            # è®°å½•å“åº”
            response_message = response.message if hasattr(response, 'message') else None
            response_text = response_message.content if response_message and hasattr(response_message, 'content') else str(response)
            
            # æå–æ¨ç†é“¾å†…å®¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            reasoning_content = None
            if response_message and hasattr(response_message, 'reasoning_content'):
                reasoning_content = response_message.reasoning_content
            
            logger.info(f"ğŸ“¥ å“åº”ä½“:")
            logger.info(f"   å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
            logger.info(f"   å“åº”å†…å®¹: {response_text[:1000]}{'...' if len(response_text) > 1000 else ''}")
            
            # è®°å½•æ¨ç†é“¾å†…å®¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if reasoning_content:
                logger.info(f"ğŸ§  æ¨ç†é“¾å†…å®¹:")
                logger.info(f"   æ¨ç†é“¾é•¿åº¦: {len(reasoning_content)} å­—ç¬¦")
                logger.info(f"   æ¨ç†é“¾å†…å®¹: {reasoning_content[:1000]}{'...' if len(reasoning_content) > 1000 else ''}")
            
            # è®°å½•å…ƒæ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            if hasattr(response, 'raw') and response.raw:
                try:
                    # å°è¯•åºåˆ—åŒ–åŸå§‹å“åº”ï¼ˆå¦‚æœæ˜¯å­—å…¸æˆ–å¯åºåˆ—åŒ–å¯¹è±¡ï¼‰
                    if isinstance(response.raw, dict):
                        logger.info(f"   åŸå§‹å“åº” keys: {list(response.raw.keys())}")
                        # æ£€æŸ¥ choices ä¸­æ˜¯å¦æœ‰ reasoning_content
                        if 'choices' in response.raw and response.raw['choices']:
                            choice = response.raw['choices'][0]
                            if isinstance(choice, dict) and 'message' in choice:
                                msg = choice['message']
                                if isinstance(msg, dict):
                                    logger.info(f"   message keys: {list(msg.keys())}")
                                    if 'reasoning_content' in msg:
                                        logger.info(f"   âœ… æ‰¾åˆ° reasoning_contentï¼ˆé•¿åº¦: {len(msg['reasoning_content']) if msg['reasoning_content'] else 0}ï¼‰")
                                    else:
                                        logger.warning(f"   âš ï¸ message ä¸­æ²¡æœ‰ reasoning_content å­—æ®µ")
                        logger.debug(f"   åŸå§‹å“åº”: {json.dumps(response.raw, ensure_ascii=False, indent=2)}")
                    else:
                        logger.debug(f"   åŸå§‹å“åº”ç±»å‹: {type(response.raw)}")
                except (TypeError, ValueError) as e:
                    # å¦‚æœæ— æ³•åºåˆ—åŒ–ï¼ˆå¦‚ Mock å¯¹è±¡ï¼‰ï¼Œåªè®°å½•ç±»å‹
                    logger.debug(f"   åŸå§‹å“åº”ç±»å‹: {type(response.raw)}ï¼ˆæ— æ³•åºåˆ—åŒ–: {e}ï¼‰")
            
            logger.info("=" * 80)
            
            return response
            
        except Exception as e:
            logger.error(f"âŒ DeepSeek API è°ƒç”¨å¤±è´¥:")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error("=" * 80)
            raise
    
    def _stream_complete_with_logging(self, prompt: str, **kwargs):
        """åŒ…è£… stream_complete æ–¹æ³•ï¼Œè®°å½•è¯·æ±‚å’Œå“åº”æµ
        
        Args:
            prompt: æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields:
            CompletionResponse: æµå¼å®Œæˆå“åº”
        """
        # è®°å½•è¯·æ±‚
        logger.info("=" * 80)
        logger.info("ğŸ”µ DeepSeek API è°ƒç”¨ - stream_complete")
        logger.info("-" * 80)
        logger.info(f"ğŸ“¤ è¯·æ±‚ä½“:")
        logger.info(f"   æ¨¡å‹: {self._llm.model}")
        logger.info(f"   æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
        logger.info(f"   æç¤ºè¯å†…å®¹: {prompt[:500]}{'...' if len(prompt) > 500 else ''}")
        if kwargs:
            logger.info(f"   å…¶ä»–å‚æ•°: {json.dumps(kwargs, ensure_ascii=False, indent=2)}")
        logger.info("-" * 80)
        
        try:
            # è°ƒç”¨åŸå§‹æ–¹æ³•å¹¶æ”¶é›†å“åº”
            full_response = ""
            for chunk in self._llm.stream_complete(prompt, **kwargs):
                chunk_text = chunk.text if hasattr(chunk, 'text') else str(chunk)
                full_response += chunk_text
                yield chunk
            
            # è®°å½•å®Œæ•´å“åº”
            logger.info(f"ğŸ“¥ å“åº”ä½“ï¼ˆæµå¼ï¼‰:")
            logger.info(f"   å“åº”é•¿åº¦: {len(full_response)} å­—ç¬¦")
            logger.info(f"   å“åº”å†…å®¹: {full_response[:1000]}{'...' if len(full_response) > 1000 else ''}")
            logger.info("=" * 80)
            
        except Exception as e:
            logger.error(f"âŒ DeepSeek API è°ƒç”¨å¤±è´¥:")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error("=" * 80)
            raise
    
    def _stream_chat_with_logging(self, messages, **kwargs):
        """åŒ…è£… stream_chat æ–¹æ³•ï¼Œè®°å½•è¯·æ±‚å’Œå“åº”æµ
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields:
            ChatResponse: æµå¼èŠå¤©å“åº”
        """
        # è®°å½•è¯·æ±‚
        logger.info("=" * 80)
        logger.info("ğŸ”µ DeepSeek API è°ƒç”¨ - stream_chat")
        logger.info("-" * 80)
        logger.info(f"ğŸ“¤ è¯·æ±‚ä½“:")
        logger.info(f"   æ¨¡å‹: {self._llm.model}")
        logger.info(f"   æ¶ˆæ¯æ•°é‡: {len(messages)}")
        for i, msg in enumerate(messages):
            # å¤„ç† ChatMessage å¯¹è±¡æˆ–å­—å…¸
            if hasattr(msg, 'role') and hasattr(msg, 'content'):
                role = msg.role.value if hasattr(msg.role, 'value') else str(msg.role)
                content = msg.content
            elif isinstance(msg, dict):
                role = msg.get('role', 'unknown')
                content = msg.get('content', '')
            else:
                role = 'unknown'
                content = str(msg)
            logger.info(f"   æ¶ˆæ¯ {i+1} ({role}): {content[:200]}{'...' if len(content) > 200 else ''}")
        if kwargs:
            logger.info(f"   å…¶ä»–å‚æ•°: {json.dumps(kwargs, ensure_ascii=False, indent=2)}")
        logger.info("-" * 80)
        
        try:
            # æ¸…ç†æ¶ˆæ¯ï¼Œç¡®ä¿ä¸åŒ…å« reasoning_contentï¼ˆç¬¦åˆ DeepSeek API è¦æ±‚ï¼‰
            cleaned_messages = clean_messages_for_api(messages)
            
            # è°ƒç”¨åŸå§‹æ–¹æ³•å¹¶æ”¶é›†å“åº”ï¼ˆä½¿ç”¨æ¸…ç†åçš„æ¶ˆæ¯ï¼‰
            full_response = ""
            full_reasoning = ""
            last_chunk_time = time.time()
            chunk_count = 0
            for chunk in self._llm.stream_chat(cleaned_messages, **kwargs):
                chunk_count += 1
                current_time = time.time()
                time_since_last = current_time - last_chunk_time
                last_chunk_time = current_time
                
                # ç«‹å³ yield chunkï¼Œç¡®ä¿å‰ç«¯å°½å¿«æ”¶åˆ°æ•°æ®
                yield chunk
                
                # åœ¨ yield ä¹‹åå¤„ç†æ—¥å¿—å’Œå†…å®¹ç´¯ç§¯ï¼ˆä¸é˜»å¡å‰ç«¯æ¥æ”¶ï¼‰
                # è®°å½•æ¯ä¸ª chunk çš„åˆ°è¾¾æ—¶é—´ï¼ˆä»…åœ¨å‰å‡ ä¸ªå’Œé—´éš”è¾ƒé•¿æ—¶è®°å½•ï¼‰
                if chunk_count <= 5 or time_since_last > 0.1:
                    logger.debug(f"ğŸ“¦ Chunk #{chunk_count} åˆ°è¾¾ï¼Œé—´éš”: {time_since_last*1000:.1f}ms")
                chunk_message = chunk.message if hasattr(chunk, 'message') else None
                if chunk_message:
                    # å¤„ç†æ¨ç†é“¾å†…å®¹ï¼ˆæµå¼ï¼‰
                    if hasattr(chunk_message, 'reasoning_content') and chunk_message.reasoning_content:
                        reasoning_str = str(chunk_message.reasoning_content) if chunk_message.reasoning_content else ""
                        if reasoning_str:
                            full_reasoning += reasoning_str
                    # å¤„ç†æ™®é€šå†…å®¹ï¼ˆæµå¼ï¼‰
                    if hasattr(chunk_message, 'content') and chunk_message.content:
                        content_str = str(chunk_message.content) if chunk_message.content else ""
                        if content_str:
                            full_response += content_str
                else:
                    # å¤„ç† deltaï¼ˆæµå¼å“åº”ï¼‰
                    if hasattr(chunk, 'delta'):
                        delta = chunk.delta
                        if hasattr(delta, 'reasoning_content') and delta.reasoning_content:
                            reasoning_str = str(delta.reasoning_content) if delta.reasoning_content else ""
                            if reasoning_str:
                                full_reasoning += reasoning_str
                        if hasattr(delta, 'content') and delta.content:
                            content_str = str(delta.content) if delta.content else ""
                            if content_str:
                                full_response += content_str
                    else:
                        # é™çº§å¤„ç†
                        chunk_text = str(chunk)
                        full_response += chunk_text
            
            # è®°å½•å®Œæ•´å“åº”
            logger.info(f"ğŸ“¥ å“åº”ä½“ï¼ˆæµå¼ï¼‰:")
            logger.info(f"   å“åº”é•¿åº¦: {len(full_response)} å­—ç¬¦")
            logger.info(f"   å“åº”å†…å®¹: {full_response[:1000]}{'...' if len(full_response) > 1000 else ''}")
            
            # è®°å½•æ¨ç†é“¾å†…å®¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if full_reasoning:
                logger.info(f"ğŸ§  æ¨ç†é“¾å†…å®¹ï¼ˆæµå¼ï¼‰:")
                logger.info(f"   æ¨ç†é“¾é•¿åº¦: {len(full_reasoning)} å­—ç¬¦")
                logger.info(f"   æ¨ç†é“¾å†…å®¹: {full_reasoning[:1000]}{'...' if len(full_reasoning) > 1000 else ''}")
            
            logger.info("=" * 80)
            
        except Exception as e:
            logger.error(f"âŒ DeepSeek API è°ƒç”¨å¤±è´¥:")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")
            logger.error("=" * 80)
            raise


def wrap_deepseek(deepseek_instance: DeepSeek) -> DeepSeekLogger:
    """åŒ…è£… DeepSeek å®ä¾‹ï¼Œæ·»åŠ æ—¥å¿—è®°å½•åŠŸèƒ½
    
    Args:
        deepseek_instance: DeepSeek å®ä¾‹
        
    Returns:
        åŒ…è£…åçš„ DeepSeekLogger å®ä¾‹
    """
    return DeepSeekLogger(deepseek_instance)

