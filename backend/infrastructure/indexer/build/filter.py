"""
æ–‡æ¡£è¿‡æ»¤æ¨¡å—ï¼šè¿‡æ»¤å·²å‘é‡åŒ–çš„æ–‡æ¡£ï¼Œå®ç°æ–‡æ¡£çº§æ–­ç‚¹ç»­ä¼ 
"""

from typing import List, Tuple, Dict, Optional, TYPE_CHECKING

from llama_index.core.schema import Document as LlamaDocument

from backend.infrastructure.indexer.utils.ids import get_vector_ids_by_metadata
from backend.infrastructure.logger import get_logger

if TYPE_CHECKING:
    from backend.infrastructure.data_loader.github_sync.manager import GitHubSyncManager

logger = get_logger('indexer')


def _extract_repo_info(doc: LlamaDocument) -> Tuple[str, str, str]:
    """ä»æ–‡æ¡£å…ƒæ•°æ®ä¸­æå–ä»“åº“ä¿¡æ¯
    
    Args:
        doc: æ–‡æ¡£å¯¹è±¡
        
    Returns:
        (owner, repo, branch)
    """
    repository = doc.metadata.get("repository", "")
    branch = doc.metadata.get("branch", "main")
    
    if "/" in repository:
        parts = repository.split("/", 1)
        owner = parts[0] if len(parts) > 0 else ""
        repo = parts[1] if len(parts) > 1 else ""
        return owner, repo, branch
    
    # å°è¯•ä»å•ç‹¬çš„å­—æ®µè·å–
    owner = doc.metadata.get("owner", "")
    repo = doc.metadata.get("repo", "")
    return owner, repo, branch


def filter_vectorized_documents(
    index_manager,
    documents: List[LlamaDocument],
    github_sync_manager: Optional["GitHubSyncManager"] = None
) -> Tuple[List[LlamaDocument], int, Dict[str, List[str]]]:
    """è¿‡æ»¤å·²å‘é‡åŒ–çš„æ–‡æ¡£ï¼Œå®ç°æ–‡æ¡£çº§æ–­ç‚¹ç»­ä¼ 
    
    Args:
        index_manager: IndexManagerå®ä¾‹
        documents: æ–‡æ¡£åˆ—è¡¨
        github_sync_manager: GitHubåŒæ­¥ç®¡ç†å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        (å¾…å¤„ç†çš„æ–‡æ¡£åˆ—è¡¨, å·²å‘é‡åŒ–çš„æ–‡æ¡£æ•°é‡, å·²å‘é‡åŒ–æ–‡æ¡£çš„å‘é‡IDæ˜ å°„)
    """
    if not documents:
        return [], 0, {}
    
    logger.info(f"ğŸ” å¼€å§‹è¿‡æ»¤å·²å‘é‡åŒ–æ–‡æ¡£ï¼Œæ€»æ–‡æ¡£æ•°: {len(documents)}")
    
    if index_manager._index is None:
        logger.debug("   _index ä¸º Noneï¼Œè°ƒç”¨ get_index()...")
        index_manager.get_index()
        logger.debug("   get_index() è°ƒç”¨å®Œæˆ")
    
    if not hasattr(index_manager, 'chroma_collection'):
        logger.info("â„¹ï¸  IndexManager æ²¡æœ‰ chroma_collectionï¼Œæ‰€æœ‰æ–‡æ¡£éƒ½éœ€è¦å¤„ç†")
        return documents, 0, {}
    
    logger.debug(f"   æ£€æŸ¥ chroma_collection å±æ€§: {hasattr(index_manager, 'chroma_collection')}")
    logger.debug(f"   chroma_collection å€¼: {index_manager.chroma_collection}")
    
    try:
        logger.info("ğŸ“Š å‡†å¤‡æŸ¥è¯¢ Collection å‘é‡æ•°é‡...")
        logger.debug(f"    Collectionåç§°: {index_manager.collection_name}")
        logger.debug(f"    chroma_collectionå¯¹è±¡: {type(index_manager.chroma_collection).__name__}")
        
        logger.info("ğŸ“Š æ­£åœ¨è°ƒç”¨ chroma_collection.count()...")
        collection_count = index_manager.chroma_collection.count()
        logger.info(f"ğŸ“Š Collection å‘é‡æ•°é‡æŸ¥è¯¢å®Œæˆ: {collection_count}")
        
        if collection_count == 0:
            logger.info("â„¹ï¸  Collectionä¸ºç©ºï¼Œæ‰€æœ‰æ–‡æ¡£éƒ½éœ€è¦å¤„ç†")
            return documents, 0, {}
        
        documents_to_process = []
        already_vectorized_count = 0
        already_vectorized_map = {}  # æ–°å¢ï¼šå·²å‘é‡åŒ–æ–‡æ¡£çš„å‘é‡IDæ˜ å°„
        
        logger.info(f"ğŸ” å¼€å§‹æ£€æŸ¥ {len(documents)} ä¸ªæ–‡æ¡£çš„å‘é‡åŒ–çŠ¶æ€...")
        for idx, doc in enumerate(documents, 1):
            file_path = doc.metadata.get("file_path", "")
            if not file_path:
                documents_to_process.append(doc)
                continue
            
            # æ·»åŠ è¿›åº¦æ—¥å¿—ï¼ˆæ¯10ä¸ªæ–‡æ¡£æˆ–æœ€åä¸€ä¸ªæ–‡æ¡£ï¼‰
            if idx % 10 == 0 or idx == len(documents):
                logger.info(f"   æ£€æŸ¥è¿›åº¦: {idx}/{len(documents)}")
            
            try:
                vector_ids = None
                
                # ä¼˜å…ˆä½¿ç”¨github_sync_manageræŸ¥è¯¢
                if github_sync_manager:
                    try:
                        owner, repo, branch = _extract_repo_info(doc)
                        if owner and repo:
                            vector_ids = github_sync_manager.get_file_vector_ids(
                                owner, repo, branch, file_path
                            )
                            if vector_ids:
                                logger.debug(f"é€šè¿‡github_sync_manageræ‰¾åˆ°å‘é‡ID [{file_path}]: {len(vector_ids)}ä¸ª")
                    except Exception as sync_error:
                        logger.debug(f"github_sync_manageræŸ¥è¯¢å¤±è´¥ [{file_path}]: {sync_error}ï¼Œå›é€€åˆ°ChromaæŸ¥è¯¢")
                
                # å›é€€åˆ°ChromaæŸ¥è¯¢
                if not vector_ids:
                    try:
                        vector_ids = get_vector_ids_by_metadata(index_manager, file_path)
                        if vector_ids:
                            logger.debug(f"é€šè¿‡ChromaæŸ¥è¯¢æ‰¾åˆ°å‘é‡ID [{file_path}]: {len(vector_ids)}ä¸ª")
                    except Exception as chroma_error:
                        logger.warning(f"ChromaæŸ¥è¯¢å¤±è´¥ [{file_path}]: {chroma_error}")
                
                if vector_ids:
                    already_vectorized_count += 1
                    already_vectorized_map[file_path] = vector_ids  # ä¿å­˜å·²å‘é‡åŒ–æ–‡æ¡£çš„å‘é‡ID
                    logger.debug(f"æ–‡æ¡£å·²å‘é‡åŒ–ï¼Œè·³è¿‡: {file_path}")
                else:
                    documents_to_process.append(doc)
            except Exception as check_error:
                logger.warning(f"æ£€æŸ¥æ–‡æ¡£å‘é‡åŒ–çŠ¶æ€å¤±è´¥ [{file_path}]: {check_error}ï¼Œå°†å¤„ç†è¯¥æ–‡æ¡£")
                documents_to_process.append(doc)
        
        logger.info(
            f"âœ… æ–‡æ¡£è¿‡æ»¤å®Œæˆ: "
            f"æ€»æ–‡æ¡£æ•°={len(documents)}, "
            f"å·²å‘é‡åŒ–={already_vectorized_count}, "
            f"å¾…å¤„ç†={len(documents_to_process)}, "
            f"å·²å‘é‡åŒ–æ–‡æ¡£å‘é‡IDæ˜ å°„={len(already_vectorized_map)}ä¸ªæ–‡ä»¶"
        )
        
        return documents_to_process, already_vectorized_count, already_vectorized_map
        
    except Exception as e:
        logger.error(f"âŒ è¿‡æ»¤å·²å‘é‡åŒ–æ–‡æ¡£å¤±è´¥: {e}", exc_info=True)
        logger.error(f"   å¼‚å¸¸ç±»å‹: {type(e).__name__}")
        logger.error(f"   å¼‚å¸¸è¯¦æƒ…: {str(e)}")
        logger.warning("âš ï¸  å°†å¤„ç†æ‰€æœ‰æ–‡æ¡£ï¼ˆè·³è¿‡è¿‡æ»¤ï¼‰")
        return documents, 0, {}
