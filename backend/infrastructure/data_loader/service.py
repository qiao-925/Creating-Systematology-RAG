"""
æ•°æ®å¯¼å…¥æœåŠ¡ - ç»Ÿä¸€å…¥å£ï¼šå°è£…GitHubå’Œæœ¬åœ°å¯¼å…¥åŠŸèƒ½ï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£ã€é”™è¯¯å¤„ç†ã€é‡è¯•æœºåˆ¶å’Œè¿›åº¦åé¦ˆ

ä¸»è¦åŠŸèƒ½ï¼š
- ImportResultç±»ï¼šå¯¼å…¥ç»“æœæ•°æ®ç±»ï¼ŒåŒ…å«æ–‡æ¡£åˆ—è¡¨ã€æˆåŠŸçŠ¶æ€ã€ç»Ÿè®¡ä¿¡æ¯ç­‰
- ProgressReporterç±»ï¼šè¿›åº¦åé¦ˆå™¨ï¼Œç”¨äºæ˜¾ç¤ºå¯¼å…¥è¿›åº¦
- DataImportServiceç±»ï¼šæ•°æ®å¯¼å…¥æœåŠ¡ï¼Œæä¾›ç»Ÿä¸€çš„å¯¼å…¥æ¥å£

æ‰§è¡Œæµç¨‹ï¼š
1. åˆå§‹åŒ–æ•°æ®æºï¼ˆGitHubæˆ–æœ¬åœ°æ–‡ä»¶ï¼‰
2. ä»æ•°æ®æºè·å–æ–‡ä»¶è·¯å¾„
3. è§£ææ–‡ä»¶å¹¶ç”Ÿæˆæ–‡æ¡£
4. è¿”å›å¯¼å…¥ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯

ç‰¹æ€§ï¼š
- æ”¯æŒGitHubå’Œæœ¬åœ°æ–‡ä»¶å¯¼å…¥
- å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- è¿›åº¦åé¦ˆå’Œæ—¥å¿—è®°å½•
- ç»Ÿè®¡ä¿¡æ¯æ”¶é›†
"""

import time
from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Optional, Dict, Any, TYPE_CHECKING

from llama_index.core.schema import Document as LlamaDocument

from backend.infrastructure.logger import get_logger
from backend.infrastructure.data_loader.processor import DocumentProcessor, safe_print

if TYPE_CHECKING:
    from backend.infrastructure.data_loader.source import DataSource

logger = get_logger('data_loader_service')

# æ£€æŸ¥æ–°æ¶æ„æ˜¯å¦å¯ç”¨
try:
    from backend.infrastructure.data_loader.source import GitHubSource, LocalFileSource
    from backend.infrastructure.data_loader.parser import DocumentParser
    NEW_ARCHITECTURE_AVAILABLE = True
    _GitHubSource = GitHubSource  # ä¿å­˜å¼•ç”¨ä»¥ä¾¿åç»­ä½¿ç”¨
except ImportError:
    NEW_ARCHITECTURE_AVAILABLE = False
    _GitHubSource = None


@dataclass
class ImportResult:
    """å¯¼å…¥ç»“æœ"""
    documents: List[LlamaDocument]
    success: bool
    stats: Dict[str, Any] = field(default_factory=dict)
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)


class ProgressReporter:
    """è¿›åº¦åé¦ˆå™¨"""
    
    def __init__(self, show_progress: bool = True):
        """åˆå§‹åŒ–è¿›åº¦åé¦ˆå™¨
        
        Args:
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        """
        self.show_progress = show_progress
    
    def report_stage(self, stage: str, message: str):
        """æŠ¥å‘Šé˜¶æ®µä¿¡æ¯
        
        Args:
            stage: é˜¶æ®µåç§°
            message: æ¶ˆæ¯å†…å®¹
        """
        if self.show_progress:
            safe_print(f"{stage} {message}")
        logger.info(f"[{stage}] {message}")
    
    def report_progress(self, current: int, total: int, message: str = ""):
        """æŠ¥å‘Šè¿›åº¦
        
        Args:
            current: å½“å‰è¿›åº¦
            total: æ€»æ•°
            message: é™„åŠ æ¶ˆæ¯
        """
        if self.show_progress:
            progress_msg = f"è¿›åº¦: {current}/{total}"
            if message:
                progress_msg += f" - {message}"
            safe_print(progress_msg)
        logger.debug(f"è¿›åº¦: {current}/{total} {message}")
    
    def report_success(self, message: str):
        """æŠ¥å‘ŠæˆåŠŸ
        
        Args:
            message: æˆåŠŸæ¶ˆæ¯
        """
        if self.show_progress:
            safe_print(f"âœ… {message}")
        logger.info(f"æˆåŠŸ: {message}")
    
    def report_error(self, message: str):
        """æŠ¥å‘Šé”™è¯¯
        
        Args:
            message: é”™è¯¯æ¶ˆæ¯
        """
        if self.show_progress:
            safe_print(f"âŒ {message}")
        logger.error(f"é”™è¯¯: {message}")
    
    def report_warning(self, message: str):
        """æŠ¥å‘Šè­¦å‘Š
        
        Args:
            message: è­¦å‘Šæ¶ˆæ¯
        """
        if self.show_progress:
            safe_print(f"âš ï¸  {message}")
        logger.warning(f"è­¦å‘Š: {message}")
    
    def print_if_enabled(self, message: str):
        """å¦‚æœå¯ç”¨è¿›åº¦æ˜¾ç¤ºåˆ™æ‰“å°æ¶ˆæ¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
        
        Args:
            message: æ¶ˆæ¯å†…å®¹
        """
        if self.show_progress:
            safe_print(message)


class DataImportService:
    """æ•°æ®å¯¼å…¥æœåŠ¡ - ç»Ÿä¸€å…¥å£
    
    å°è£…æ‰€æœ‰æ•°æ®å¯¼å…¥åŠŸèƒ½ï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£ã€é”™è¯¯å¤„ç†ã€é‡è¯•æœºåˆ¶å’Œè¿›åº¦åé¦ˆã€‚
    åªæ”¯æŒGitHubå’Œæœ¬åœ°ä¸¤ç§æ•°æ®æºã€‚
    """
    
    def __init__(
        self,
        show_progress: bool = True,
        enable_cache: bool = True,
        max_retries: int = 3,
        retry_delay: float = 1.0
    ):
        """åˆå§‹åŒ–æ•°æ®å¯¼å…¥æœåŠ¡
        
        Args:
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜ï¼ˆå·²åºŸå¼ƒï¼šç¼“å­˜ç®¡ç†å™¨åŠŸèƒ½å·²ç§»é™¤ï¼Œæ­¤å‚æ•°ä¸å†ä½¿ç”¨ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            retry_delay: é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
        """
        self.show_progress = show_progress
        self.enable_cache = enable_cache  # å·²åºŸå¼ƒï¼šä¿ç•™å‚æ•°ä»¥ä¿æŒæ¥å£å…¼å®¹æ€§
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        self.progress_reporter = ProgressReporter(show_progress=show_progress)
    
    def import_from_source(
        self,
        source: "DataSource",
        clean: bool = True
    ) -> ImportResult:
        """ä»æ•°æ®æºå¯¼å…¥æ–‡æ¡£
        
        Args:
            source: æ•°æ®æºå¯¹è±¡ï¼ˆGitHubSource, LocalFileSourceï¼‰
            clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
            
        Returns:
            ImportResult: å¯¼å…¥ç»“æœï¼ˆåŒ…å«æ–‡æ¡£åˆ—è¡¨ã€ç»Ÿè®¡ä¿¡æ¯ã€é”™è¯¯ä¿¡æ¯ï¼‰
        """
        start_time = time.time()
        errors = []
        warnings = []
        
        try:
            self.progress_reporter.report_stage("ğŸ”", "æ­£åœ¨ä»æ•°æ®æºè·å–æ–‡ä»¶è·¯å¾„...")
            
            # è°ƒç”¨æ ¸å¿ƒåŠ è½½æµç¨‹
            documents = self._load_documents_from_source(
                source=source,
                clean=clean,
                show_progress=self.show_progress
            )
            
            elapsed = time.time() - start_time
            
            # æ„å»ºç»Ÿè®¡ä¿¡æ¯
            stats = {
                'document_count': len(documents),
                'elapsed_time': elapsed,
                'source_type': getattr(source, 'source_type', 'unknown'),
            }
            
            # è·å–æ•°æ®æºå…ƒæ•°æ®
            if hasattr(source, 'get_source_metadata'):
                source_metadata = source.get_source_metadata()
                stats.update(source_metadata)
            
            if documents:
                self.progress_reporter.report_success(
                    f"æˆåŠŸå¯¼å…¥ {len(documents)} ä¸ªæ–‡æ¡£ (è€—æ—¶: {elapsed:.2f}s)"
                )
                return ImportResult(
                    documents=documents,
                    success=True,
                    stats=stats,
                    errors=errors,
                    warnings=warnings
                )
            else:
                warnings.append("æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£")
                self.progress_reporter.report_warning("æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£")
                return ImportResult(
                    documents=[],
                    success=False,
                    stats=stats,
                    errors=errors,
                    warnings=warnings
                )
                
        except Exception as e:
            error_msg = str(e)
            errors.append(error_msg)
            self.progress_reporter.report_error(f"å¯¼å…¥å¤±è´¥: {error_msg}")
            logger.error(f"ä»æ•°æ®æºå¯¼å…¥å¤±è´¥: {e}", exc_info=True)
            
            return ImportResult(
                documents=[],
                success=False,
                stats={'elapsed_time': time.time() - start_time},
                errors=errors,
                warnings=warnings
            )
    
    def import_from_directory(
        self,
        directory: str | Path,
        recursive: bool = True,
        clean: bool = True,
        **kwargs
    ) -> ImportResult:
        """ä»ç›®å½•å¯¼å…¥æ–‡æ¡£
        
        Args:
            directory: ç›®å½•è·¯å¾„
            recursive: æ˜¯å¦é€’å½’åŠ è½½
            clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼‰
            
        Returns:
            ImportResult: å¯¼å…¥ç»“æœ
        """
        if not NEW_ARCHITECTURE_AVAILABLE:
            error_msg = "æ–°æ¶æ„æœªå¯ç”¨ï¼Œæ— æ³•ä½¿ç”¨ç»Ÿä¸€æœåŠ¡"
            self.progress_reporter.report_error(error_msg)
            return ImportResult(
                documents=[],
                success=False,
                errors=[error_msg]
            )
        
        try:
            self.progress_reporter.report_stage("ğŸ“‚", f"ä»ç›®å½•åŠ è½½: {directory}")
            
            source = LocalFileSource(
                source=directory,
                recursive=recursive
            )
            
            result = self.import_from_source(source, clean=clean)
            
            # ä¸º Markdown æ–‡ä»¶æå–æ ‡é¢˜ï¼ˆä¿æŒåŸæœ‰è¡Œä¸ºï¼‰
            if result.success:
                for doc in result.documents:
                    file_name = doc.metadata.get('file_name', '')
                    if any(file_name.endswith(ext) for ext in ['.md', '.markdown']):
                        title = DocumentProcessor.extract_title_from_markdown(doc.text)
                        if not title:
                            title = Path(file_name).stem if file_name else "æœªå‘½å"
                        doc.metadata.update({
                            "title": title,
                            "source_type": doc.metadata.get("source_type", "markdown"),
                        })
            
            return result
            
        except Exception as e:
            error_msg = f"ä»ç›®å½•å¯¼å…¥å¤±è´¥: {str(e)}"
            self.progress_reporter.report_error(error_msg)
            logger.error(error_msg, exc_info=True)
            return ImportResult(
                documents=[],
                success=False,
                errors=[error_msg]
            )
    
    def import_from_github(
        self,
        owner: str,
        repo: str,
        branch: str = "main",
        clean: bool = True,
        filter_directories: Optional[List[str]] = None,
        filter_file_extensions: Optional[List[str]] = None,
        **kwargs
    ) -> ImportResult:
        """ä»GitHubä»“åº“å¯¼å…¥æ–‡æ¡£
        
        Args:
            owner: ä»“åº“æ‰€æœ‰è€…
            repo: ä»“åº“åç§°
            branch: åˆ†æ”¯åç§°ï¼ˆé»˜è®¤ mainï¼‰
            clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
            filter_directories: åªåŠ è½½æŒ‡å®šç›®å½•ï¼ˆå¯é€‰ï¼‰
            filter_file_extensions: åªåŠ è½½æŒ‡å®šæ‰©å±•åï¼ˆå¯é€‰ï¼‰
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ImportResult: å¯¼å…¥ç»“æœ
        """
        if not NEW_ARCHITECTURE_AVAILABLE:
            error_msg = "æ–°æ¶æ„æœªå¯ç”¨ï¼Œæ— æ³•ä½¿ç”¨ç»Ÿä¸€æœåŠ¡"
            self.progress_reporter.report_error(error_msg)
            return ImportResult(
                documents=[],
                success=False,
                errors=[error_msg]
            )
        
        try:
            self.progress_reporter.report_stage(
                "ğŸ™", 
                f"ä»GitHubåŠ è½½: {owner}/{repo}@{branch}"
            )
            
            source = GitHubSource(
                owner=owner,
                repo=repo,
                branch=branch,
                filter_directories=filter_directories,
                filter_file_extensions=filter_file_extensions,
                show_progress=self.show_progress
            )
            
            return self.import_from_source(
                source,
                clean=clean
            )
            
        except Exception as e:
            error_msg = f"ä»GitHubå¯¼å…¥å¤±è´¥: {str(e)}"
            self.progress_reporter.report_error(error_msg)
            logger.error(error_msg, exc_info=True)
            return ImportResult(
                documents=[],
                success=False,
                errors=[error_msg]
            )
    
    def sync_github_repository(
        self,
        owner: str,
        repo: str,
        branch: str,
        github_sync_manager,
        filter_directories: Optional[List[str]] = None,
        filter_file_extensions: Optional[List[str]] = None
    ) -> tuple:
        """å¢é‡åŒæ­¥GitHubä»“åº“
        
        Args:
            owner: ä»“åº“æ‰€æœ‰è€…
            repo: ä»“åº“åç§°
            branch: åˆ†æ”¯åç§°
            github_sync_manager: GitHubåŒæ­¥ç®¡ç†å™¨
            filter_directories: åªåŠ è½½æŒ‡å®šç›®å½•ï¼ˆå¯é€‰ï¼‰
            filter_file_extensions: åªåŠ è½½æŒ‡å®šæ‰©å±•åï¼ˆå¯é€‰ï¼‰
            
        Returns:
            (æ‰€æœ‰æ–‡æ¡£åˆ—è¡¨, FileChangeå¯¹è±¡, commit_sha)
        """
        from backend.infrastructure.data_loader.github_sync import FileChange
        from backend.infrastructure.config import config
        
        # æ­¥éª¤ 1: å…‹éš†/æ›´æ–°ä»“åº“ï¼Œè·å–æœ€æ–° commit SHA
        try:
            from backend.infrastructure.git import GitRepositoryManager
            if GitRepositoryManager is None:
                error_msg = "GitRepositoryManager æœªå®‰è£…"
                self.progress_reporter.report_error(error_msg)
                return [], FileChange(), None
            
            git_manager = GitRepositoryManager(config.GITHUB_REPOS_PATH)
            self.progress_reporter.report_stage("ğŸ”„", f"æ­£åœ¨åŒæ­¥ä»“åº“: {owner}/{repo}@{branch}")
            
            repo_path, commit_sha = git_manager.clone_or_update(
                owner=owner,
                repo=repo,
                branch=branch
            )
            
            self.progress_reporter.report_success(f"ä»“åº“å·²åŒæ­¥ (Commit: {commit_sha[:8]})")
            
        except RuntimeError as e:
            error_msg = f"Git æ“ä½œå¤±è´¥: {str(e)}"
            self.progress_reporter.report_error(error_msg)
            logger.error(error_msg)
            return [], FileChange(), None
        
        # æ­¥éª¤ 2: å¿«é€Ÿæ£€æµ‹ - æ£€æŸ¥ commit SHA æ˜¯å¦å˜åŒ–
        old_sync_state = github_sync_manager.get_repository_sync_state(owner, repo, branch)
        
        if old_sync_state:
            old_commit_sha = old_sync_state.get('last_commit_sha', '')
            if old_commit_sha == commit_sha:
                # Commit æœªå˜åŒ–ï¼Œè·³è¿‡åŠ è½½
                self.progress_reporter.report_success("ä»“åº“æ— æ–°æäº¤ï¼Œè·³è¿‡åŠ è½½")
                logger.info(f"ä»“åº“ {owner}/{repo}@{branch} æ— æ–°æäº¤ (Commit: {commit_sha[:8]})")
                return [], FileChange(), commit_sha
        
        # æ­¥éª¤ 3: æœ‰æ–°æäº¤ï¼ŒåŠ è½½æ–‡æ¡£
        self.progress_reporter.report_stage("ğŸ“„", "æ£€æµ‹åˆ°æ–°æäº¤ï¼Œæ­£åœ¨åŠ è½½æ–‡æ¡£...")
        
        import_result = self.import_from_github(
            owner=owner,
            repo=repo,
            branch=branch,
            clean=True,
            filter_directories=filter_directories,
            filter_file_extensions=filter_file_extensions
        )
        
        if not import_result.success or not import_result.documents:
            logger.warning(f"æœªèƒ½åŠ è½½ä»»ä½•æ–‡æ¡£ä» {owner}/{repo}")
            return [], FileChange(), commit_sha
        
        documents = import_result.documents
        
        # æ­¥éª¤ 4: ç²¾ç»†æ£€æµ‹ - æ–‡ä»¶çº§å˜æ›´
        self.progress_reporter.report_stage("ğŸ”", "æ­£åœ¨æ£€æµ‹æ–‡ä»¶å˜æ›´...")
        
        changes = github_sync_manager.detect_changes(owner, repo, branch, documents)
        
        if changes.has_changes():
            self.progress_reporter.report_success(f"æ£€æµ‹ç»“æœ: {changes.summary()}")
        else:
            self.progress_reporter.report_success("æ²¡æœ‰æ£€æµ‹åˆ°æ–‡ä»¶å˜æ›´")
        
        return documents, changes, commit_sha
    
    def import_from_github_url(
        self,
        github_url: str,
        clean: bool = True,
        **kwargs
    ) -> ImportResult:
        """ä»GitHub URLå¯¼å…¥æ–‡æ¡£
        
        Args:
            github_url: GitHubä»“åº“URL
            clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ImportResult: å¯¼å…¥ç»“æœ
        """
        from backend.infrastructure.data_loader.github_url import parse_github_url
        
        # è§£æURL
        repo_info = parse_github_url(github_url)
        if not repo_info:
            error_msg = f"æ— æ³•è§£æGitHub URL: {github_url}"
            self.progress_reporter.report_error(error_msg)
            return ImportResult(
                documents=[],
                success=False,
                errors=[error_msg]
            )
        
        # è°ƒç”¨import_from_github
        return self.import_from_github(
            owner=repo_info['owner'],
            repo=repo_info['repo'],
            branch=repo_info.get('branch', 'main'),
            clean=clean,
            **kwargs
        )
    
    def _load_documents_from_source(
        self,
        source: "DataSource",
        clean: bool = True,
        show_progress: bool = True
    ) -> List[LlamaDocument]:
        """ä»æ•°æ®æºåŠ è½½æ–‡æ¡£ï¼ˆæ ¸å¿ƒåŠ è½½æµç¨‹ï¼Œç§æœ‰æ–¹æ³•ï¼‰
        
        æ•´åˆæ•°æ®æ¥æºå±‚å’Œè§£æå±‚ï¼Œæ‰§è¡Œæ ¸å¿ƒåŠ è½½æµç¨‹
        
        Args:
            source: æ•°æ®æºå¯¹è±¡ï¼ˆGitHubSource, LocalFileSourceç­‰ï¼‰
            clean: æ˜¯å¦æ¸…ç†æ–‡æœ¬
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        if not NEW_ARCHITECTURE_AVAILABLE:
            logger.error("[é˜¶æ®µ1.2] æ–°æ¶æ„æœªå¯ç”¨")
            return []
        
        try:
            total_start_time = time.time()
            
            # æ­¥éª¤1: ä»æ•°æ®æºè·å–æ–‡ä»¶è·¯å¾„
            self.progress_reporter.print_if_enabled("ğŸ” æ­£åœ¨ä»æ•°æ®æºè·å–æ–‡ä»¶è·¯å¾„...")
            
            source_start_time = time.time()
            # è°ƒç”¨æ•°æ®æºçš„æ ‡å‡†æ–¹æ³• get_file_paths()
            source_files = source.get_file_paths()
            source_elapsed = time.time() - source_start_time
            
            if not source_files:
                logger.warning(f"[é˜¶æ®µ1.2] æ•°æ®æºæœªè¿”å›ä»»ä½•æ–‡ä»¶")
                self.progress_reporter.print_if_enabled("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶")
                return []
            
            logger.info(f"[é˜¶æ®µ1.2] æ•°æ®æºè¿”å› {len(source_files)} ä¸ªæ–‡ä»¶ (è€—æ—¶: {source_elapsed:.2f}s)")
            self.progress_reporter.print_if_enabled(f"âœ… æ‰¾åˆ° {len(source_files)} ä¸ªæ–‡ä»¶")
            
            # æ­¥éª¤2: æ„å»ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨å’Œå…ƒæ•°æ®æ˜ å°„
            file_paths = [sf.path for sf in source_files]
            metadata_map = {
                sf.path: {**sf.metadata, 'source_type': sf.source_type}
                for sf in source_files
            }
            
            # æ­¥éª¤3: ä½¿ç”¨è§£æå™¨è§£ææ–‡ä»¶
            self.progress_reporter.print_if_enabled("ğŸ“„ æ­£åœ¨è§£ææ–‡ä»¶...")
            
            parser_start_time = time.time()
            documents = DocumentParser().parse_files(
                file_paths, metadata_map, clean=clean
            )
            parser_elapsed = time.time() - parser_start_time
            
            if not documents:
                logger.warning(f"[é˜¶æ®µ1.3] è§£æå™¨æœªè¿”å›ä»»ä½•æ–‡æ¡£ (è¾“å…¥æ–‡ä»¶æ•°: {len(file_paths)})")
                self.progress_reporter.print_if_enabled("âš ï¸  æœªèƒ½è§£æä»»ä½•æ–‡æ¡£")
                return []
            
            logger.info(f"[é˜¶æ®µ1.3] è§£æå™¨è¿”å› {len(documents)} ä¸ªæ–‡æ¡£ (è€—æ—¶: {parser_elapsed:.2f}s)")
            
            # æ­¥éª¤4: å¯é€‰çš„æ–‡æœ¬æ¸…ç†
            clean_start_time = time.time()
            if clean:
                processor = DocumentProcessor()
                documents = [
                    LlamaDocument(
                        text=processor.clean_text(doc.text),
                        metadata=doc.metadata,
                        id_=doc.id_
                    )
                    for doc in documents
                ]
            clean_elapsed = time.time() - clean_start_time if clean else 0.0
            
            total_elapsed = time.time() - total_start_time
            self.progress_reporter.print_if_enabled(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
            
            success_rate = (len(documents) / len(source_files) * 100) if source_files else 0
            logger.info(
                f"[é˜¶æ®µ1.3] æ–‡æ¡£åŠ è½½å®Œæˆ: æºæ–‡ä»¶æ•°={len(source_files)}, "
                f"è§£ææ–‡æ¡£æ•°={len(documents)}, æˆåŠŸç‡={success_rate:.1f}%, "
                f"æ€»è€—æ—¶={total_elapsed:.2f}s (è·å–è·¯å¾„={source_elapsed:.2f}s, "
                f"è§£æ={parser_elapsed:.2f}s, æ¸…ç†={clean_elapsed:.2f}s)"
            )
            
            return documents
            
        except Exception as e:
            logger.error(f"[é˜¶æ®µ1.2/1.3] ä»æ•°æ®æºåŠ è½½æ–‡æ¡£å¤±è´¥: {e}")
            self.progress_reporter.print_if_enabled(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return []
