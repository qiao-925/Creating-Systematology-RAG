#!/usr/bin/env python3
"""
RAGé“¾è·¯è€—æ—¶åˆ†æè„šæœ¬ï¼šæµ‹é‡æŸ¥è¯¢å„é˜¶æ®µè€—æ—¶ï¼Œå®šä½æ€§èƒ½ç“¶é¢ˆ

ä½¿ç”¨æ–¹æ³•ï¼š
    python tests/tools/analyze_rag_timing.py
    python tests/tools/analyze_rag_timing.py --query "ä½ çš„æµ‹è¯•é—®é¢˜"
    python tests/tools/analyze_rag_timing.py --detailed  # è¯¦ç»†æ¨¡å¼
    python tests/tools/analyze_rag_timing.py --agentic   # æµ‹è¯•Agenticæ¨¡å¼

è¾“å‡ºç¤ºä¾‹ï¼š
    ğŸ“Š RAGé“¾è·¯è€—æ—¶è¯Šæ–­æŠ¥å‘Š
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    é˜¶æ®µ                          è€—æ—¶(s)    å æ¯”      çŠ¶æ€
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. æŸ¥è¯¢å¤„ç†ï¼ˆæ„å›¾ç†è§£+æ”¹å†™ï¼‰     1.23    15%       âœ…
    2. æ£€ç´¢ç­–ç•¥é€‰æ‹©                  0.05     1%       âœ…
    3. å‘é‡æ£€ç´¢                      0.45     5%       âœ…
    4. é‡æ’åº                        0.89    11%       ğŸŸ¡
    5. LLMç”Ÿæˆ                       5.67    68%       âš ï¸ ç“¶é¢ˆ
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    æ€»è®¡                             8.29   100%
"""

import sys
import time
import argparse
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any
from contextlib import contextmanager

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ sys.path ä¸­
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


@dataclass
class TimingResult:
    """è®¡æ—¶ç»“æœ"""
    name: str
    duration: float
    success: bool
    error: Optional[str] = None
    details: Dict[str, Any] = field(default_factory=dict)


class RAGTimingAnalyzer:
    """RAGé“¾è·¯è€—æ—¶åˆ†æå™¨"""
    
    def __init__(self, detailed: bool = False):
        self.detailed = detailed
        self.results: List[TimingResult] = []
        self.total_start = time.perf_counter()
    
    @contextmanager
    def measure(self, name: str):
        """è®¡æ—¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        start = time.perf_counter()
        details = {}
        error = None
        success = True
        
        try:
            yield details
        except Exception as e:
            success = False
            error = str(e)
            raise
        finally:
            duration = time.perf_counter() - start
            self.results.append(TimingResult(
                name=name,
                duration=duration,
                success=success,
                error=error,
                details=details
            ))
    
    def add_result(self, name: str, duration: float, success: bool = True, 
                   error: Optional[str] = None, details: Optional[Dict] = None) -> None:
        """æ‰‹åŠ¨æ·»åŠ è®¡æ—¶ç»“æœ"""
        self.results.append(TimingResult(
            name=name,
            duration=duration,
            success=success,
            error=error,
            details=details or {}
        ))
    
    def print_report(self) -> None:
        """æ‰“å°è¯Šæ–­æŠ¥å‘Š"""
        total_time = sum(r.duration for r in self.results)
        
        print("\n" + "â•" * 65)
        print("ğŸ“Š RAGé“¾è·¯è€—æ—¶è¯Šæ–­æŠ¥å‘Š")
        print("â•" * 65)
        print(f"{'é˜¶æ®µ':<32} {'è€—æ—¶(s)':<10} {'å æ¯”':<8} {'çŠ¶æ€':<10}")
        print("â”€" * 65)
        
        for i, result in enumerate(self.results, 1):
            pct = (result.duration / total_time * 100) if total_time > 0 else 0
            status = self._get_status(result, pct)
            name_display = f"{i}. {result.name}"
            print(f"{name_display:<32} {result.duration:>6.2f}    {pct:>5.1f}%    {status}")
            
            if self.detailed and result.details:
                for key, value in result.details.items():
                    print(f"   â””â”€ {key}: {value}")
            
            if result.error and self.detailed:
                print(f"   â””â”€ é”™è¯¯: {result.error[:60]}...")
        
        print("â”€" * 65)
        print(f"{'æ€»è®¡':<32} {total_time:>6.2f}    100.0%")
        print("â•" * 65)
        
        # æ‰“å°å»ºè®®
        self._print_suggestions(total_time)
    
    def _get_status(self, result: TimingResult, pct: float) -> str:
        """è·å–çŠ¶æ€æ ‡è®°"""
        if not result.success:
            return "âŒ å¤±è´¥"
        if pct > 50:
            return "âš ï¸ ä¸»è¦ç“¶é¢ˆ"
        if pct > 30:
            return "ğŸŸ  ç“¶é¢ˆ"
        if pct > 15:
            return "ğŸŸ¡ å…³æ³¨"
        return "âœ…"
    
    def _print_suggestions(self, total_time: float) -> None:
        """æ‰“å°ä¼˜åŒ–å»ºè®®"""
        print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        
        # æŒ‰è€—æ—¶æ’åºï¼Œæ‰¾å‡ºç“¶é¢ˆ
        sorted_results = sorted(self.results, key=lambda r: r.duration, reverse=True)
        
        for i, result in enumerate(sorted_results[:3]):
            pct = (result.duration / total_time * 100) if total_time > 0 else 0
            if pct > 15:
                suggestion = self._get_suggestion(result.name, result.duration, pct)
                print(f"   {i+1}. {suggestion}")
        
        # æ€»ä½“è¯„ä¼°
        print()
        if total_time < 3:
            print("   âœ… æ€»è€—æ—¶ < 3ç§’ï¼Œæ€§èƒ½è‰¯å¥½")
        elif total_time < 8:
            print("   ğŸŸ¡ æ€»è€—æ—¶ 3-8ç§’ï¼Œæœ‰ä¼˜åŒ–ç©ºé—´")
        elif total_time < 15:
            print("   ğŸŸ  æ€»è€—æ—¶ 8-15ç§’ï¼Œå»ºè®®ä¼˜åŒ–")
        else:
            print("   âš ï¸ æ€»è€—æ—¶ > 15ç§’ï¼Œæ€¥éœ€ä¼˜åŒ–")
        
        # å¤±è´¥çš„é˜¶æ®µ
        failed = [r for r in self.results if not r.success]
        if failed:
            print(f"   âŒ æœ‰ {len(failed)} ä¸ªé˜¶æ®µå¤±è´¥ï¼Œéœ€è¦æ’æŸ¥")
    
    def _get_suggestion(self, stage_name: str, duration: float, pct: float) -> str:
        """æ ¹æ®é˜¶æ®µåç§°ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = {
            "æŸ¥è¯¢å¤„ç†": f"ã€Œ{stage_name}ã€å  {pct:.1f}%ï¼ˆ{duration:.2f}sï¼‰- è€ƒè™‘ï¼šç®€åŒ–æŸ¥è¯¢ç›´æ¥è·³è¿‡LLM / ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ / å¢åŠ ç¼“å­˜å‘½ä¸­ç‡",
            "LLMç”Ÿæˆ": f"ã€Œ{stage_name}ã€å  {pct:.1f}%ï¼ˆ{duration:.2f}sï¼‰- è€ƒè™‘ï¼šä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ / å‡å°‘max_tokens / ä¼˜åŒ–prompté•¿åº¦",
            "å‘é‡æ£€ç´¢": f"ã€Œ{stage_name}ã€å  {pct:.1f}%ï¼ˆ{duration:.2f}sï¼‰- è€ƒè™‘ï¼šå‡å°‘top_k / ä¼˜åŒ–ç´¢å¼•ç»“æ„ / ä½¿ç”¨æ›´å¿«çš„å‘é‡åº“",
            "é‡æ’åº": f"ã€Œ{stage_name}ã€å  {pct:.1f}%ï¼ˆ{duration:.2f}sï¼‰- è€ƒè™‘ï¼šç¦ç”¨é‡æ’åº / ä½¿ç”¨æ›´è½»é‡çš„æ¨¡å‹ / å‡å°‘é‡æ’åºæ•°é‡",
            "Embedding": f"ã€Œ{stage_name}ã€å  {pct:.1f}%ï¼ˆ{duration:.2f}sï¼‰- è€ƒè™‘ï¼šä½¿ç”¨æœ¬åœ°æ¨¡å‹ / æ‰¹é‡å¤„ç† / ç¼“å­˜Embedding",
            "Agent": f"ã€Œ{stage_name}ã€å  {pct:.1f}%ï¼ˆ{duration:.2f}sï¼‰- è€ƒè™‘ï¼šå‡å°‘è¿­ä»£æ¬¡æ•° / ç®€åŒ–å·¥å…· / ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼",
        }
        
        # æ¨¡ç³ŠåŒ¹é…
        for key, suggestion in suggestions.items():
            if key in stage_name:
                return suggestion
        
        return f"ã€Œ{stage_name}ã€å  {pct:.1f}%ï¼ˆ{duration:.2f}sï¼‰- å»ºè®®ä¼˜å…ˆä¼˜åŒ–"


def analyze_modular_engine(query: str, detailed: bool = False) -> RAGTimingAnalyzer:
    """åˆ†æ ModularQueryEngineï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰è€—æ—¶"""
    from dotenv import load_dotenv
    load_dotenv()
    
    analyzer = RAGTimingAnalyzer(detailed=detailed)
    
    print("ğŸ” å¼€å§‹åˆ†æ ModularQueryEngine é“¾è·¯è€—æ—¶...\n")
    print(f"ğŸ“ æµ‹è¯•æŸ¥è¯¢: {query}\n")
    
    # 1. åˆå§‹åŒ–é˜¶æ®µ
    index_manager = None
    engine = None
    
    with analyzer.measure("ç´¢å¼•åŠ è½½") as details:
        from backend.infrastructure.indexer import IndexManager
        index_manager = IndexManager()
        details["index_type"] = type(index_manager).__name__
    
    with analyzer.measure("å¼•æ“åˆå§‹åŒ–") as details:
        from backend.business.rag_engine.core.engine import ModularQueryEngine
        engine = ModularQueryEngine(index_manager=index_manager)
        details["strategy"] = engine.retrieval_strategy
        details["rerank"] = engine.enable_rerank
    
    # 2. æŸ¥è¯¢å¤„ç†é˜¶æ®µï¼ˆæ‰‹åŠ¨åˆ†è§£ï¼‰
    query_processor = engine.query_processor
    
    with analyzer.measure("æŸ¥è¯¢å¤„ç†ï¼ˆæ„å›¾ç†è§£+æ”¹å†™ï¼‰") as details:
        processed = query_processor.process(query)
        details["method"] = processed.get("processing_method")
        details["final_query"] = processed["final_query"][:50] + "..." if len(processed["final_query"]) > 50 else processed["final_query"]
    
    final_query = processed["final_query"]
    understanding = processed.get("understanding")
    
    # 3. æ£€ç´¢é˜¶æ®µï¼ˆæ‰‹åŠ¨åˆ†è§£ï¼‰
    with analyzer.measure("æ£€ç´¢ç­–ç•¥é€‰æ‹©/è·¯ç”±") as details:
        query_engine, strategy_info = engine._get_or_create_query_engine(
            final_query, 
            understanding
        )
        details["strategy_info"] = strategy_info[:60] if len(strategy_info) > 60 else strategy_info
    
    # 4. æ£€ç´¢æ‰§è¡Œï¼ˆåŒ…å«å‘é‡æ£€ç´¢+é‡æ’åºï¼‰
    # è¿™é‡Œéœ€è¦æ›´ç»†ç²’åº¦çš„åˆ†è§£ï¼Œä½† LlamaIndex çš„ query_engine.query() æ˜¯åŸå­æ“ä½œ
    # æˆ‘ä»¬è®°å½•æ€»æ—¶é—´ï¼Œç„¶åä¼°ç®—å„éƒ¨åˆ†
    with analyzer.measure("æ£€ç´¢+é‡æ’åº+LLMç”Ÿæˆï¼ˆæ€»è®¡ï¼‰") as details:
        start_time = time.perf_counter()
        answer, sources, reasoning_content, trace_info = engine.query(query, collect_trace=True)
        details["sources_count"] = len(sources)
        details["answer_len"] = len(answer)
        if trace_info:
            details["retrieval_time"] = trace_info.get("retrieval_time", "N/A")
    
    return analyzer


def analyze_modular_engine_detailed(query: str, detailed: bool = False) -> RAGTimingAnalyzer:
    """åˆ†æ ModularQueryEngineï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰è€—æ—¶ - ç»†ç²’åº¦åˆ†è§£ç‰ˆ"""
    from dotenv import load_dotenv
    load_dotenv()
    
    analyzer = RAGTimingAnalyzer(detailed=detailed)
    
    print("ğŸ” å¼€å§‹åˆ†æ ModularQueryEngine é“¾è·¯è€—æ—¶ï¼ˆç»†ç²’åº¦ï¼‰...\n")
    print(f"ğŸ“ æµ‹è¯•æŸ¥è¯¢: {query}\n")
    
    # 1. åˆå§‹åŒ–é˜¶æ®µ
    with analyzer.measure("ç´¢å¼•åŠ è½½") as details:
        from backend.infrastructure.indexer import IndexManager
        index_manager = IndexManager()
        details["index_type"] = type(index_manager).__name__
    
    with analyzer.measure("å¼•æ“åˆå§‹åŒ–") as details:
        from backend.business.rag_engine.core.engine import ModularQueryEngine
        from backend.business.rag_engine.formatting import ResponseFormatter
        from backend.infrastructure.llms import create_deepseek_llm_for_query
        from backend.infrastructure.config import config
        
        # æ‰‹åŠ¨åˆå§‹åŒ–ç»„ä»¶ä»¥åˆ†è§£è€—æ—¶
        engine = ModularQueryEngine(index_manager=index_manager)
        details["strategy"] = engine.retrieval_strategy
        details["rerank"] = engine.enable_rerank
    
    # 2. æŸ¥è¯¢å¤„ç†é˜¶æ®µ
    query_processor = engine.query_processor
    
    with analyzer.measure("æŸ¥è¯¢å¤„ç†ï¼ˆæ„å›¾ç†è§£+æ”¹å†™ï¼‰") as details:
        processed = query_processor.process(query)
        details["method"] = processed.get("processing_method")
        details["complexity"] = processed.get("complexity", "N/A")
    
    final_query = processed["final_query"]
    understanding = processed.get("understanding")
    
    # 3. æ£€ç´¢ç­–ç•¥é€‰æ‹©
    with analyzer.measure("æ£€ç´¢ç­–ç•¥é€‰æ‹©/è·¯ç”±") as details:
        query_engine_instance, strategy_info = engine._get_or_create_query_engine(
            final_query, 
            understanding
        )
        details["strategy"] = strategy_info[:40]
    
    # 4. å‘é‡æ£€ç´¢ï¼ˆæ‰‹åŠ¨æ‰§è¡Œæ£€ç´¢å™¨ï¼‰
    retriever = engine.retriever
    nodes_with_scores = []
    
    with analyzer.measure("å‘é‡æ£€ç´¢") as details:
        if retriever:
            nodes_with_scores = retriever.retrieve(final_query)
            details["retrieved_count"] = len(nodes_with_scores)
    
    # 5. åå¤„ç†ï¼ˆé‡æ’åºç­‰ï¼‰
    with analyzer.measure("åå¤„ç†ï¼ˆé‡æ’åºç­‰ï¼‰") as details:
        if engine.postprocessors and nodes_with_scores:
            for postprocessor in engine.postprocessors:
                nodes_with_scores = postprocessor.postprocess_nodes(
                    nodes_with_scores,
                    query_str=final_query
                )
            details["final_count"] = len(nodes_with_scores)
    
    # 6. LLMç”Ÿæˆ
    with analyzer.measure("LLMç”Ÿæˆ") as details:
        from llama_index.core import get_response_synthesizer
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        for i, node_with_score in enumerate(nodes_with_scores, 1):
            node = node_with_score.node if hasattr(node_with_score, 'node') else node_with_score
            text = node.text if hasattr(node, 'text') else str(node)
            context_parts.append(f"[{i}] {text}")
        context_str = "\n\n".join(context_parts) if context_parts else "ï¼ˆæ— ç›¸å…³ä¿¡æ¯ï¼‰"
        
        # æ„å»º prompt
        from backend.business.rag_engine.formatting.templates import get_template
        prompt = get_template('chat').format(context_str=context_str)
        prompt += f"\n\nç”¨æˆ·é—®é¢˜ï¼š{final_query}\n\nè¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚"
        
        # è°ƒç”¨ LLM
        response = engine.llm.complete(prompt)
        answer = str(response)
        details["answer_len"] = len(answer)
    
    # 7. æ ¼å¼åŒ–
    with analyzer.measure("ç­”æ¡ˆæ ¼å¼åŒ–") as details:
        formatted_answer = engine.formatter.format(answer, None)
        details["formatted_len"] = len(formatted_answer)
    
    return analyzer


def analyze_agentic_engine(query: str, detailed: bool = False) -> RAGTimingAnalyzer:
    """åˆ†æ AgenticQueryEngineï¼ˆAgentæ¨¡å¼ï¼‰è€—æ—¶"""
    from dotenv import load_dotenv
    load_dotenv()
    
    analyzer = RAGTimingAnalyzer(detailed=detailed)
    
    print("ğŸ” å¼€å§‹åˆ†æ AgenticQueryEngine é“¾è·¯è€—æ—¶...\n")
    print(f"ğŸ“ æµ‹è¯•æŸ¥è¯¢: {query}\n")
    
    # 1. åˆå§‹åŒ–é˜¶æ®µ
    with analyzer.measure("ç´¢å¼•åŠ è½½") as details:
        from backend.infrastructure.indexer import IndexManager
        index_manager = IndexManager()
        details["index_type"] = type(index_manager).__name__
    
    with analyzer.measure("Agenticå¼•æ“åˆå§‹åŒ–") as details:
        from backend.business.rag_engine.agentic.engine import AgenticQueryEngine
        engine = AgenticQueryEngine(
            index_manager=index_manager,
            max_iterations=5,
            timeout_seconds=60,
        )
        details["max_iterations"] = engine.max_iterations
    
    # 2. æ‰§è¡ŒæŸ¥è¯¢ï¼ˆAgentæ¨¡å¼æ˜¯åŸå­æ“ä½œï¼Œéš¾ä»¥ç»†åˆ†ï¼‰
    with analyzer.measure("Agentæ‰§è¡Œï¼ˆæ€»è®¡ï¼‰") as details:
        answer, sources, reasoning_content, trace_info = engine.query(query, collect_trace=True)
        details["sources_count"] = len(sources)
        details["answer_len"] = len(answer)
        details["has_reasoning"] = reasoning_content is not None
        if trace_info:
            details["agent_call_time"] = trace_info.get("agent_call_time", "N/A")
            details["extraction_time"] = trace_info.get("extraction_time", "N/A")
    
    return analyzer


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="RAGé“¾è·¯è€—æ—¶è¯Šæ–­è„šæœ¬")
    parser.add_argument("--query", "-q", type=str, 
                        default="ä»€ä¹ˆæ˜¯ç³»ç»Ÿç§‘å­¦ï¼Ÿ",
                        help="æµ‹è¯•æŸ¥è¯¢ï¼ˆé»˜è®¤ï¼šä»€ä¹ˆæ˜¯ç³»ç»Ÿç§‘å­¦ï¼Ÿï¼‰")
    parser.add_argument("--detailed", "-d", action="store_true", 
                        help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯")
    parser.add_argument("--agentic", "-a", action="store_true", 
                        help="æµ‹è¯•Agenticæ¨¡å¼")
    parser.add_argument("--granular", "-g", action="store_true", 
                        help="ç»†ç²’åº¦åˆ†è§£ï¼ˆä»…ä¼ ç»Ÿæ¨¡å¼ï¼‰")
    args = parser.parse_args()
    
    try:
        if args.agentic:
            # æµ‹è¯• Agentic æ¨¡å¼
            print("=" * 65)
            print("ğŸ¤– æµ‹è¯• AgenticQueryEngine")
            print("=" * 65)
            analyzer = analyze_agentic_engine(args.query, detailed=args.detailed)
            analyzer.print_report()
        else:
            # æµ‹è¯•ä¼ ç»Ÿæ¨¡å¼
            print("=" * 65)
            print("ğŸ”§ æµ‹è¯• ModularQueryEngine")
            print("=" * 65)
            
            if args.granular:
                analyzer = analyze_modular_engine_detailed(args.query, detailed=args.detailed)
            else:
                analyzer = analyze_modular_engine(args.query, detailed=args.detailed)
            
            analyzer.print_report()
            
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
