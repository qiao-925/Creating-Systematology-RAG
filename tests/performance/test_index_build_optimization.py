#!/usr/bin/env python3
"""
ç´¢å¼•æ„å»ºæµç¨‹ä¼˜åŒ–æ€§èƒ½æµ‹è¯•

æµ‹è¯•åœºæ™¯ï¼š
1. æ‰¹é‡æ’å…¥æ€§èƒ½æµ‹è¯•ï¼ˆ10/50/100/500ä¸ªæ–‡æ¡£ï¼‰
2. å‘é‡IDæŸ¥è¯¢æ€§èƒ½æµ‹è¯•
3. å¢é‡æ›´æ–°æ€§èƒ½æµ‹è¯•
4. å†…å­˜ä½¿ç”¨æƒ…å†µ

è¿è¡Œæ–¹å¼ï¼š
    python -m pytest tests/performance/test_index_build_optimization.py -v
    æˆ–
    python tests/performance/test_index_build_optimization.py
"""

import os
import sys
import time
import tempfile
import shutil
from pathlib import Path
from typing import List, Dict, Tuple
import statistics

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from llama_index.core.schema import Document as LlamaDocument
from src.indexer import IndexManager
from src.config import config


def create_test_documents(count: int, doc_size: int = 500) -> List[LlamaDocument]:
    """åˆ›å»ºæµ‹è¯•æ–‡æ¡£
    
    Args:
        count: æ–‡æ¡£æ•°é‡
        doc_size: æ¯ä¸ªæ–‡æ¡£çš„å­—ç¬¦æ•°
        
    Returns:
        æ–‡æ¡£åˆ—è¡¨
    """
    documents = []
    base_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ã€‚å†…å®¹ç”¨äºæµ‹è¯•ç´¢å¼•æ„å»ºæ€§èƒ½ã€‚" * 20
    
    for i in range(count):
        doc_text = f"æ–‡æ¡£{i} - {base_text}"[:doc_size]
        doc = LlamaDocument(
            text=doc_text,
            metadata={
                "file_path": f"test/doc_{i}.md",
                "file_name": f"doc_{i}.md",
                "source_type": "test",
                "index": i,
            },
            id_=f"test_doc_{i}"
        )
        documents.append(doc)
    
    return documents


def measure_time(func, *args, **kwargs):
    """æµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´
    
    Returns:
        (ç»“æœ, è€—æ—¶ç§’æ•°)
    """
    start_time = time.time()
    result = func(*args, **kwargs)
    elapsed = time.time() - start_time
    return result, elapsed


class PerformanceTestSuite:
    """æ€§èƒ½æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.test_dir = None
        self.results = []
        
    def setup(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºæµ‹è¯•
        self.test_dir = Path(tempfile.mkdtemp(prefix="index_perf_test_"))
        print(f"ğŸ“ æµ‹è¯•ç›®å½•: {self.test_dir}")
        
    def teardown(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        if self.test_dir and self.test_dir.exists():
            shutil.rmtree(self.test_dir)
            print(f"ğŸ§¹ å·²æ¸…ç†æµ‹è¯•ç›®å½•")
    
    def test_batch_insert_performance(self):
        """æµ‹è¯•æ‰¹é‡æ’å…¥æ€§èƒ½"""
        print("\n" + "="*60)
        print("ğŸ“Š æµ‹è¯•1: æ‰¹é‡æ’å…¥æ€§èƒ½æµ‹è¯•")
        print("="*60)
        
        test_cases = [
            (10, "å°æ‰¹é‡"),
            (50, "ä¸­æ‰¹é‡"),
            (100, "å¤§æ‰¹é‡"),
            (500, "è¶…å¤§æ‰¹é‡"),
        ]
        
        results = []
        
        for doc_count, label in test_cases:
            print(f"\nğŸ”¨ æµ‹è¯• {label} ({doc_count} ä¸ªæ–‡æ¡£)...")
            
            # åˆ›å»ºæµ‹è¯•é›†åˆï¼ˆæ¯æ¬¡æµ‹è¯•ä½¿ç”¨æ–°çš„é›†åˆï¼‰
            collection_name = f"perf_test_{doc_count}_{int(time.time())}"
            index_manager = IndexManager(
                collection_name=collection_name,
                persist_dir=self.test_dir / f"vector_store_{doc_count}",
                embed_model_instance=None,  # ä½¿ç”¨é»˜è®¤æ¨¡å‹
            )
            
            # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
            documents = create_test_documents(doc_count)
            
            # æµ‹è¯•æ‰¹é‡æ’å…¥æ€§èƒ½
            result, elapsed = measure_time(
                index_manager.build_index,
                documents,
                show_progress=False
            )
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = index_manager.get_stats()
            vector_count = stats.get('document_count', 0)
            
            # è®¡ç®—å¹³å‡æ¯ä¸ªæ–‡æ¡£è€—æ—¶
            avg_time_per_doc = elapsed / doc_count if doc_count > 0 else 0
            avg_time_per_vector = elapsed / vector_count if vector_count > 0 else 0
            
            result_data = {
                "test_name": f"æ‰¹é‡æ’å…¥-{label}",
                "doc_count": doc_count,
                "vector_count": vector_count,
                "total_time": elapsed,
                "avg_time_per_doc": avg_time_per_doc,
                "avg_time_per_vector": avg_time_per_vector,
                "throughput_docs_per_sec": doc_count / elapsed if elapsed > 0 else 0,
            }
            results.append(result_data)
            
            print(f"âœ… å®Œæˆ: {doc_count} ä¸ªæ–‡æ¡£, {vector_count} ä¸ªå‘é‡")
            print(f"   æ€»è€—æ—¶: {elapsed:.2f}s")
            print(f"   å¹³å‡æ¯æ–‡æ¡£: {avg_time_per_doc:.3f}s")
            print(f"   å¹³å‡æ¯å‘é‡: {avg_time_per_vector:.3f}s")
            print(f"   ååé‡: {result_data['throughput_docs_per_sec']:.2f} æ–‡æ¡£/ç§’")
            
            # æ¸…ç†
            index_manager.clear_index()
        
        self.results.extend(results)
        return results
    
    def test_incremental_update_performance(self):
        """æµ‹è¯•å¢é‡æ›´æ–°æ€§èƒ½"""
        print("\n" + "="*60)
        print("ğŸ“Š æµ‹è¯•2: å¢é‡æ›´æ–°æ€§èƒ½æµ‹è¯•")
        print("="*60)
        
        collection_name = f"perf_test_incremental_{int(time.time())}"
        index_manager = IndexManager(
            collection_name=collection_name,
            persist_dir=self.test_dir / "vector_store_incremental",
            embed_model_instance=None,
        )
        
        # åˆå§‹åŠ è½½50ä¸ªæ–‡æ¡£
        initial_docs = create_test_documents(50)
        print(f"\nğŸ“¥ åˆå§‹åŠ è½½: 50 ä¸ªæ–‡æ¡£...")
        result, initial_elapsed = measure_time(
            index_manager.build_index,
            initial_docs,
            show_progress=False
        )
        print(f"âœ… åˆå§‹åŠ è½½å®Œæˆ: {initial_elapsed:.2f}s")
        
        # æµ‹è¯•å¢é‡æ·»åŠ 
        incremental_sizes = [10, 25, 50]
        results = []
        
        for add_count in incremental_sizes:
            print(f"\nâ• å¢é‡æ·»åŠ : {add_count} ä¸ªæ–‡æ¡£...")
            
            new_docs = create_test_documents(add_count)
            # ä¿®æ”¹metadataä»¥é¿å…IDå†²çª
            for i, doc in enumerate(new_docs):
                doc.metadata["file_path"] = f"test/incremental_doc_{add_count}_{i}.md"
                doc.id_ = f"test_incremental_{add_count}_{i}"
            
            result, add_elapsed = measure_time(
                index_manager.build_index,
                new_docs,
                show_progress=False
            )
            
            stats = index_manager.get_stats()
            vector_count = stats.get('document_count', 0)
            
            result_data = {
                "test_name": f"å¢é‡æ›´æ–°-æ·»åŠ {add_count}ä¸ª",
                "doc_count": add_count,
                "vector_count": vector_count,
                "total_time": add_elapsed,
                "avg_time_per_doc": add_elapsed / add_count if add_count > 0 else 0,
                "throughput_docs_per_sec": add_count / add_elapsed if add_elapsed > 0 else 0,
            }
            results.append(result_data)
            
            print(f"âœ… å¢é‡æ·»åŠ å®Œæˆ: {add_count} ä¸ªæ–‡æ¡£")
            print(f"   è€—æ—¶: {add_elapsed:.2f}s")
            print(f"   å¹³å‡æ¯æ–‡æ¡£: {result_data['avg_time_per_doc']:.3f}s")
            print(f"   å½“å‰å‘é‡æ€»æ•°: {vector_count}")
        
        self.results.extend(results)
        return results
    
    def test_vector_id_query_performance(self):
        """æµ‹è¯•å‘é‡IDæŸ¥è¯¢æ€§èƒ½"""
        print("\n" + "="*60)
        print("ğŸ“Š æµ‹è¯•3: å‘é‡IDæŸ¥è¯¢æ€§èƒ½æµ‹è¯•")
        print("="*60)
        
        collection_name = f"perf_test_query_{int(time.time())}"
        index_manager = IndexManager(
            collection_name=collection_name,
            persist_dir=self.test_dir / "vector_store_query",
            embed_model_instance=None,
        )
        
        # åˆ›å»º100ä¸ªæµ‹è¯•æ–‡æ¡£
        doc_count = 100
        documents = create_test_documents(doc_count)
        
        print(f"\nğŸ“¥ å‡†å¤‡æµ‹è¯•æ•°æ®: {doc_count} ä¸ªæ–‡æ¡£...")
        index_manager.build_index(documents, show_progress=False)
        
        # æµ‹è¯•å•ä¸ªæŸ¥è¯¢
        print(f"\nğŸ” æµ‹è¯•å•ä¸ªæŸ¥è¯¢...")
        file_paths = [doc.metadata.get("file_path") for doc in documents[:10]]
        
        single_query_times = []
        for file_path in file_paths:
            result, elapsed = measure_time(
                index_manager._get_vector_ids_by_metadata,
                file_path
            )
            single_query_times.append(elapsed)
        
        avg_single_query_time = statistics.mean(single_query_times)
        
        # æµ‹è¯•æ‰¹é‡æŸ¥è¯¢
        print(f"\nğŸ” æµ‹è¯•æ‰¹é‡æŸ¥è¯¢ (100ä¸ªè·¯å¾„)...")
        all_file_paths = [doc.metadata.get("file_path") for doc in documents]
        
        result, batch_query_time = measure_time(
            index_manager._get_vector_ids_batch,
            all_file_paths
        )
        
        result_data = {
            "test_name": "å‘é‡IDæŸ¥è¯¢",
            "single_query_count": 10,
            "avg_single_query_time": avg_single_query_time,
            "batch_query_count": doc_count,
            "batch_query_time": batch_query_time,
            "speedup": (avg_single_query_time * doc_count) / batch_query_time if batch_query_time > 0 else 0,
        }
        
        print(f"âœ… å•æ¬¡æŸ¥è¯¢å¹³å‡è€—æ—¶: {avg_single_query_time*1000:.2f}ms")
        print(f"âœ… æ‰¹é‡æŸ¥è¯¢è€—æ—¶: {batch_query_time:.2f}s (100ä¸ªè·¯å¾„)")
        print(f"âœ… æ€§èƒ½æå‡: {result_data['speedup']:.2f}x")
        
        self.results.append(result_data)
        return result_data
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("\n" + "="*60)
        print("ğŸš€ å¼€å§‹æ€§èƒ½æµ‹è¯•")
        print("="*60)
        
        try:
            self.setup()
            
            # è¿è¡Œæ‰€æœ‰æµ‹è¯•
            self.test_batch_insert_performance()
            self.test_incremental_update_performance()
            self.test_vector_id_query_performance()
            
            # ç”ŸæˆæŠ¥å‘Š
            self.generate_report()
            
        finally:
            self.teardown()
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        if not self.results:
            print("âš ï¸  æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return
        
        # æ‰¹é‡æ’å…¥æ€§èƒ½æ±‡æ€»
        insert_results = [r for r in self.results if "æ‰¹é‡æ’å…¥" in r.get("test_name", "")]
        if insert_results:
            print("\nğŸ“Š æ‰¹é‡æ’å…¥æ€§èƒ½æ±‡æ€»:")
            print(f"{'æ–‡æ¡£æ•°':<10} {'æ€»è€—æ—¶(s)':<12} {'å¹³å‡(ms/æ–‡æ¡£)':<15} {'ååé‡(æ–‡æ¡£/s)':<15}")
            print("-" * 60)
            for r in sorted(insert_results, key=lambda x: x["doc_count"]):
                print(
                    f"{r['doc_count']:<10} "
                    f"{r['total_time']:<12.2f} "
                    f"{r['avg_time_per_doc']*1000:<15.2f} "
                    f"{r['throughput_docs_per_sec']:<15.2f}"
                )
        
        # å¢é‡æ›´æ–°æ€§èƒ½æ±‡æ€»
        incremental_results = [r for r in self.results if "å¢é‡æ›´æ–°" in r.get("test_name", "")]
        if incremental_results:
            print("\nğŸ“Š å¢é‡æ›´æ–°æ€§èƒ½æ±‡æ€»:")
            print(f"{'æ·»åŠ æ•°':<10} {'æ€»è€—æ—¶(s)':<12} {'å¹³å‡(ms/æ–‡æ¡£)':<15} {'ååé‡(æ–‡æ¡£/s)':<15}")
            print("-" * 60)
            for r in sorted(incremental_results, key=lambda x: x["doc_count"]):
                print(
                    f"{r['doc_count']:<10} "
                    f"{r['total_time']:<12.2f} "
                    f"{r['avg_time_per_doc']*1000:<15.2f} "
                    f"{r['throughput_docs_per_sec']:<15.2f}"
                )
        
        # æŸ¥è¯¢æ€§èƒ½æ±‡æ€»
        query_results = [r for r in self.results if "å‘é‡IDæŸ¥è¯¢" in r.get("test_name", "")]
        if query_results:
            print("\nğŸ“Š å‘é‡IDæŸ¥è¯¢æ€§èƒ½æ±‡æ€»:")
            for r in query_results:
                print(f"   å•æ¬¡æŸ¥è¯¢å¹³å‡: {r['avg_single_query_time']*1000:.2f}ms")
                print(f"   æ‰¹é‡æŸ¥è¯¢ ({r['batch_query_count']}ä¸ª): {r['batch_query_time']:.2f}s")
                print(f"   æ€§èƒ½æå‡: {r['speedup']:.2f}x")
        
        # æ€§èƒ½åˆ†æ
        print("\nğŸ“ˆ æ€§èƒ½åˆ†æ:")
        
        if insert_results:
            # è®¡ç®—ä¸åŒæ–‡æ¡£æ•°çš„æ€§èƒ½è¶‹åŠ¿
            doc_counts = sorted([r["doc_count"] for r in insert_results])
            times_per_doc = [
                r["avg_time_per_doc"] * 1000
                for r in sorted(insert_results, key=lambda x: x["doc_count"])
            ]
            
            if len(doc_counts) >= 2:
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ€§èƒ½ä¸‹é™è¶‹åŠ¿
                first_time = times_per_doc[0]
                last_time = times_per_doc[-1]
                if last_time < first_time * 1.5:
                    print("   âœ… æ‰¹é‡æ’å…¥æ€§èƒ½ç¨³å®šï¼Œæ— æ˜æ˜¾æ€§èƒ½ä¸‹é™")
                else:
                    print("   âš ï¸  å¤§æ‰¹é‡æ’å…¥æ—¶æ€§èƒ½æœ‰æ‰€ä¸‹é™ï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†")
        
        print("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆ!")
        
        # ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶
        report_file = project_root / "agent-task-log" / "ç´¢å¼•æ„å»ºæ€§èƒ½æµ‹è¯•æŠ¥å‘Š.md"
        self.save_detailed_report(report_file)
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    def save_detailed_report(self, report_file: Path):
        """ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# ç´¢å¼•æ„å»ºæ€§èƒ½æµ‹è¯•æŠ¥å‘Š\n\n")
            f.write(f"**æµ‹è¯•æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("---\n\n")
            
            # æ‰¹é‡æ’å…¥ç»“æœ
            insert_results = [r for r in self.results if "æ‰¹é‡æ’å…¥" in r.get("test_name", "")]
            if insert_results:
                f.write("## æ‰¹é‡æ’å…¥æ€§èƒ½æµ‹è¯•\n\n")
                f.write("| æ–‡æ¡£æ•° | å‘é‡æ•° | æ€»è€—æ—¶(s) | å¹³å‡(ms/æ–‡æ¡£) | ååé‡(æ–‡æ¡£/s) |\n")
                f.write("|--------|--------|-----------|---------------|----------------|\n")
                for r in sorted(insert_results, key=lambda x: x["doc_count"]):
                    f.write(
                        f"| {r['doc_count']} | {r.get('vector_count', 'N/A')} | "
                        f"{r['total_time']:.2f} | {r['avg_time_per_doc']*1000:.2f} | "
                        f"{r['throughput_docs_per_sec']:.2f} |\n"
                    )
                f.write("\n")
            
            # å¢é‡æ›´æ–°ç»“æœ
            incremental_results = [r for r in self.results if "å¢é‡æ›´æ–°" in r.get("test_name", "")]
            if incremental_results:
                f.write("## å¢é‡æ›´æ–°æ€§èƒ½æµ‹è¯•\n\n")
                f.write("| æ·»åŠ æ–‡æ¡£æ•° | æ€»è€—æ—¶(s) | å¹³å‡(ms/æ–‡æ¡£) | ååé‡(æ–‡æ¡£/s) |\n")
                f.write("|-----------|-----------|---------------|----------------|\n")
                for r in sorted(incremental_results, key=lambda x: x["doc_count"]):
                    f.write(
                        f"| {r['doc_count']} | {r['total_time']:.2f} | "
                        f"{r['avg_time_per_doc']*1000:.2f} | {r['throughput_docs_per_sec']:.2f} |\n"
                    )
                f.write("\n")
            
            # æŸ¥è¯¢ç»“æœ
            query_results = [r for r in self.results if "å‘é‡IDæŸ¥è¯¢" in r.get("test_name", "")]
            if query_results:
                f.write("## å‘é‡IDæŸ¥è¯¢æ€§èƒ½æµ‹è¯•\n\n")
                for r in query_results:
                    f.write(f"- **å•æ¬¡æŸ¥è¯¢å¹³å‡è€—æ—¶**: {r['avg_single_query_time']*1000:.2f}ms\n")
                    f.write(f"- **æ‰¹é‡æŸ¥è¯¢è€—æ—¶**: {r['batch_query_time']:.2f}s ({r['batch_query_count']}ä¸ªè·¯å¾„)\n")
                    f.write(f"- **æ€§èƒ½æå‡**: {r['speedup']:.2f}x\n")
                f.write("\n")


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸ”¬ ç´¢å¼•æ„å»ºæµç¨‹ä¼˜åŒ– - æ€§èƒ½æµ‹è¯•")
    print("="*60)
    print("\næ³¨æ„äº‹é¡¹:")
    print("1. é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½Embeddingæ¨¡å‹ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
    print("2. æµ‹è¯•ä¼šåœ¨ä¸´æ—¶ç›®å½•åˆ›å»ºç´¢å¼•ï¼Œæµ‹è¯•å®Œæˆåè‡ªåŠ¨æ¸…ç†")
    print("3. å»ºè®®åœ¨CPUå’Œå†…å­˜å……è¶³çš„æœºå™¨ä¸Šè¿è¡Œ")
    print("\nå¼€å§‹æµ‹è¯•...\n")
    
    suite = PerformanceTestSuite()
    suite.run_all_tests()


if __name__ == "__main__":
    main()

