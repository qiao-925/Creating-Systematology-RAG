"""
Streamlit Webåº”ç”¨ - ä¸»é¡µï¼šç³»ç»Ÿç§‘å­¦çŸ¥è¯†åº“RAGåº”ç”¨çš„Webç•Œé¢

ä¸»è¦åŠŸèƒ½ï¼š
- cleanup_resources()ï¼šæ¸…ç†åº”ç”¨èµ„æºï¼Œå…³é—­Chromaå®¢æˆ·ç«¯å’Œåå°çº¿ç¨‹
- display_trace_info()ï¼šæ˜¾ç¤ºæŸ¥è¯¢è¿½è¸ªä¿¡æ¯
- get_chat_title()ï¼šä»ç¬¬ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯ä¸­æå–æ ‡é¢˜
- sidebar()ï¼šä¾§è¾¹æ ï¼ŒåŒ…å«æ–°å¯¹è¯æŒ‰é’®ã€å†å²ä¼šè¯åˆ—è¡¨å’Œè¿›å…¥è®¾ç½®å…¥å£
- main()ï¼šä¸»ç•Œé¢ï¼ŒåŒ…å«ç”¨æˆ·è®¤è¯ã€å¯¹è¯æ˜¾ç¤ºã€æŸ¥è¯¢å¤„ç†ç­‰

æ‰§è¡Œæµç¨‹ï¼š
1. åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å’Œèµ„æº
2. ç”¨æˆ·è®¤è¯ï¼ˆç™»å½•/æ³¨å†Œï¼‰
3. åˆå§‹åŒ–RAGæœåŠ¡å’Œå¯¹è¯ç®¡ç†å™¨
4. æ˜¾ç¤ºå¯¹è¯å†å²å’Œå¼•ç”¨æ¥æº
5. å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶ç”Ÿæˆå›ç­”

ç‰¹æ€§ï¼š
- Claudeé£æ ¼UIè®¾è®¡
- æ”¯æŒæ¨ç†é“¾æ˜¾ç¤ºå’Œå­˜å‚¨
- æ”¯æŒå¼•ç”¨æ¥æºå±•ç¤º
- æ”¯æŒä¼šè¯å†å²ç®¡ç†
- æ”¯æŒPhoenixå¯è§‚æµ‹æ€§é›†æˆï¼ˆåœ¨è®¾ç½®é¡µé¢é…ç½®ï¼‰
"""

import streamlit as st
from pathlib import Path
from typing import Optional
import sys
import time
import atexit
import logging

# æŠ‘åˆ¶OpenTelemetryå¯¼å‡ºå™¨çš„é”™è¯¯æ—¥å¿—ï¼ˆé¿å…è¿æ¥å¤±è´¥æ—¶çš„å™ªéŸ³ï¼‰
# è¿™äº›é”™è¯¯é€šå¸¸æ˜¯ transient çš„ï¼Œä¸å½±å“åº”ç”¨åŠŸèƒ½
logging.getLogger('opentelemetry.sdk.trace.export').setLevel(logging.WARNING)
logging.getLogger('opentelemetry.exporter.otlp').setLevel(logging.WARNING)
logging.getLogger('opentelemetry.exporter.otlp.proto.grpc').setLevel(logging.WARNING)

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# ä¼˜å…ˆè®¾ç½® UTF-8 ç¼–ç ï¼ˆç¡®ä¿ emoji æ­£ç¡®æ˜¾ç¤ºï¼‰
try:
    from src.infrastructure.encoding import setup_utf8_encoding
    setup_utf8_encoding()
except ImportError:
    # å¦‚æœ encoding æ¨¡å—å°šæœªåŠ è½½ï¼Œæ‰‹åŠ¨è®¾ç½®åŸºç¡€ç¼–ç 
    import os
    os.environ["PYTHONIOENCODING"] = "utf-8"

from src.infrastructure.config import config
from src.ui import (
    init_session_state,
    load_rag_service,
    load_index,
    load_chat_manager,
    display_hybrid_sources,
    display_model_status,
    format_answer_with_citation_links,
    display_sources_with_anchors
)
from src.ui.sources_panel import display_sources_below_message
from src.ui.styles import CLAUDE_STYLE_CSS
from llama_index.core import Document as LlamaDocument
from src.infrastructure.logger import get_logger

logger = get_logger('app')


def convert_sources_to_dict(sources) -> list:
    """å°†SourceModelå¯¹è±¡åˆ—è¡¨è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    
    Args:
        sources: SourceModelå¯¹è±¡åˆ—è¡¨æˆ–å­—å…¸åˆ—è¡¨
        
    Returns:
        å­—å…¸åˆ—è¡¨
    """
    if not sources:
        return []
    
    result = []
    for idx, source in enumerate(sources):
        if isinstance(source, dict):
            # å·²ç»æ˜¯å­—å…¸ï¼Œæ·»åŠ indexå­—æ®µ
            source_dict = source.copy()
            source_dict['index'] = idx + 1
            result.append(source_dict)
        else:
            # æ˜¯SourceModelå¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—å…¸
            source_dict = source.model_dump() if hasattr(source, 'model_dump') else dict(source)
            source_dict['index'] = idx + 1
            result.append(source_dict)
    
    return result


def cleanup_resources():
    """æ¸…ç†åº”ç”¨èµ„æºï¼Œå…³é—­ Chroma å®¢æˆ·ç«¯å’Œåå°çº¿ç¨‹
    
    è¿™ä¸ªå‡½æ•°ä¼šåœ¨åº”ç”¨é€€å‡ºæ—¶è¢«è°ƒç”¨ï¼Œç¡®ä¿ Chroma çš„åå°çº¿ç¨‹è¢«æ­£ç¡®ç»ˆæ­¢
    """
    try:
        import logging
        log = logging.getLogger('app')
        log.info("ğŸ”§ å¼€å§‹æ¸…ç†åº”ç”¨èµ„æº...")
        
        # æ¸…ç† IndexManagerï¼ˆå…³é—­ Chroma å®¢æˆ·ç«¯ï¼‰
        # æ³¨æ„ï¼šåœ¨ Streamlit ä¸­ï¼Œsession_state å¯èƒ½ä¸å¯ç”¨ï¼Œæ‰€ä»¥éœ€è¦ try-except
        try:
            if hasattr(st, 'session_state') and 'index_manager' in st.session_state:
                index_manager = st.session_state.get('index_manager')
                if index_manager:
                    try:
                        index_manager.close()
                        log.info("âœ… ç´¢å¼•ç®¡ç†å™¨å·²æ¸…ç†")
                    except Exception as e:
                        log.warning(f"âš ï¸  æ¸…ç†ç´¢å¼•ç®¡ç†å™¨æ—¶å‡ºé”™: {e}")
        except Exception as e:
            # Streamlit session_state å¯èƒ½åœ¨æŸäº›æƒ…å†µä¸‹ä¸å¯ç”¨
            log.debug(f"æ— æ³•è®¿é—® session_state: {e}")
        
        # å°è¯•æ¸…ç†å…¨å±€èµ„æº
        try:
            # æ¸…ç†å…¨å±€çš„ Embedding æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
            from src.infrastructure.indexer import clear_embedding_model_cache
            clear_embedding_model_cache()
            log.debug("âœ… å…¨å±€æ¨¡å‹ç¼“å­˜å·²æ¸…ç†")
        except Exception as e:
            log.debug(f"æ¸…ç†å…¨å±€æ¨¡å‹ç¼“å­˜æ—¶å‡ºé”™: {e}")
        
        # æ¸…ç† Hugging Face Embedding èµ„æºï¼ˆçº¿ç¨‹æ± å’Œæ­£åœ¨è¿›è¡Œçš„è¯·æ±‚ï¼‰
        try:
            from src.infrastructure.embeddings.hf_inference_embedding import cleanup_hf_embedding_resources
            cleanup_hf_embedding_resources()
            log.debug("âœ… Hugging Face Embedding èµ„æºå·²æ¸…ç†")
        except Exception as e:
            log.debug(f"æ¸…ç† Hugging Face Embedding èµ„æºæ—¶å‡ºé”™: {e}")
        
        log.info("âœ… åº”ç”¨èµ„æºæ¸…ç†å®Œæˆ")
    except Exception as e:
        # ä½¿ç”¨ print ä½œä¸ºæœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
        print(f"âŒ æ¸…ç†èµ„æºæ—¶å‘ç”Ÿé”™è¯¯: {e}")


# æ³¨å†Œé€€å‡ºé’©å­ï¼ˆåœ¨æ‰€æœ‰æƒ…å†µä¸‹éƒ½ä¼šæ‰§è¡Œï¼‰
atexit.register(cleanup_resources)


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸»é¡µ",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded",
)


def display_trace_info(trace_info: dict):
    """æ˜¾ç¤ºæŸ¥è¯¢è¿½è¸ªä¿¡æ¯
    
    Args:
        trace_info: è¿½è¸ªä¿¡æ¯å­—å…¸
    """
    if not trace_info:
        return
    
    with st.expander("ğŸ“Š æŸ¥è¯¢è¿½è¸ªä¿¡æ¯", expanded=True):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("æ€»è€—æ—¶", f"{trace_info.get('total_time', 0)}s")
        
        with col2:
            retrieval_info = trace_info.get('retrieval', {})
            st.metric("æ£€ç´¢è€—æ—¶", f"{retrieval_info.get('time_cost', 0)}s")
        
        with col3:
            st.metric("å¬å›æ•°é‡", retrieval_info.get('chunks_retrieved', 0))
        
        st.divider()
        
        # æ£€ç´¢è¯¦æƒ…
        st.markdown("**ğŸ” æ£€ç´¢è¯¦æƒ…**")
        col1, col2 = st.columns(2)
        with col1:
            st.text(f"Top K: {retrieval_info.get('top_k', 0)}")
            st.text(f"å¹³å‡ç›¸ä¼¼åº¦: {retrieval_info.get('avg_score', 0)}")
        
        with col2:
            llm_info = trace_info.get('llm_generation', {})
            st.text(f"LLMæ¨¡å‹: {llm_info.get('model', 'N/A')}")
            st.text(f"å›ç­”é•¿åº¦: {llm_info.get('response_length', 0)} å­—ç¬¦")


def get_chat_title(messages: list) -> Optional[str]:
    """ä»ç¬¬ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯ä¸­æå–æ ‡é¢˜
    
    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        
    Returns:
        æ ‡é¢˜å­—ç¬¦ä¸²ï¼Œå¦‚æœæ²¡æœ‰ç”¨æˆ·æ¶ˆæ¯åˆ™è¿”å›None
    """
    if not messages:
        return None
    
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯
    for message in messages:
        if message.get("role") == "user":
            content = message.get("content", "")
            if content:
                # æˆªå–å‰50ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
                title = content[:50].strip()
                # å¦‚æœè¶…è¿‡50ä¸ªå­—ç¬¦ï¼Œæ·»åŠ çœç•¥å·
                if len(content) > 50:
                    title += "..."
                return title
    
    return None


def sidebar():
    """ä¾§è¾¹æ  - ç²¾ç®€ç‰ˆï¼Œåªä¿ç•™æ ¸å¿ƒåŠŸèƒ½"""
    with st.sidebar:
        # ========== åº”ç”¨æ ‡é¢˜åŒºåŸŸ ==========
        st.title("ğŸ“š " + config.APP_TITLE)
        st.caption("åŸºäºLlamaIndexå’ŒDeepSeekçš„ç³»ç»Ÿç§‘å­¦çŸ¥è¯†é—®ç­”ç³»ç»Ÿ")
        
        # ========== æ–°å¯¹è¯ï¼ˆé¡¶éƒ¨ï¼‰ ==========
        if st.button("ğŸ’¬ å¼€å¯æ–°å¯¹è¯", type="primary", use_container_width=True, key="new_chat_top"):
            if st.session_state.chat_manager:
                # åˆ›å»ºæ–°ä¼šè¯ï¼ˆåªé‡ç½®å¯¹è¯çŠ¶æ€ï¼Œä¸é‡æ–°åˆå§‹åŒ–æœåŠ¡ï¼‰
                st.session_state.chat_manager.start_session()
                st.session_state.messages = []
                # æ¸…ç©ºå¼•ç”¨æ¥æºæ˜ å°„ï¼Œé¿å…å³ä¾§æ˜¾ç¤ºä¸Šä¸€ä¸ªå¯¹è¯çš„å¼•ç”¨æ¥æº
                if 'current_sources_map' in st.session_state:
                    st.session_state.current_sources_map = {}
                if 'current_reasoning_map' in st.session_state:
                    st.session_state.current_reasoning_map = {}
                # ä»…åˆ·æ–°UIï¼Œä¸è§¦å‘æœåŠ¡é‡æ–°éªŒè¯
                st.rerun()

        # ========== å†å²ä¼šè¯ï¼ˆç´§éšæ–°å¯¹è¯æŒ‰é’®ï¼‰ ==========
        current_session_id = None
        if st.session_state.chat_manager and st.session_state.chat_manager.current_session:
            current_session_id = st.session_state.chat_manager.current_session.session_id
        from src.ui.history import display_session_history
        display_session_history(user_email=None, current_session_id=current_session_id)
        
        # ========== è®¾ç½®æŒ‰é’® ==========
        st.divider()
        if st.button("âš™ï¸ è®¾ç½®", use_container_width=True, key="settings_button"):
            st.session_state.show_settings_dialog = True
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ˜¾ç¤ºè®¾ç½®å¼¹çª—
        if st.session_state.get("show_settings_dialog", False):
            from src.ui.settings_dialog import show_settings_dialog
            show_settings_dialog()
            # æ³¨æ„ï¼šå¯¹è¯æ¡†çš„å…³é—­ç”±è£…é¥°å™¨è‡ªåŠ¨å¤„ç†ï¼Œä¸éœ€è¦æ‰‹åŠ¨å…³é—­


def main():
    """ä¸»ç•Œé¢"""
    # ========== Claudeé£æ ¼CSSæ ·å¼ ==========
    st.markdown(CLAUDE_STYLE_CSS, unsafe_allow_html=True)
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ï¼ˆéœ€æ—©äºé‡å‹åˆå§‹åŒ–ï¼Œç”¨äºæ§åˆ¶é®ç½©ï¼‰
    init_session_state()
    
    # ========== å¯åŠ¨åˆå§‹åŒ– ==========
    if not st.session_state.boot_ready:
        # å¯åŠ¨é˜¶æ®µï¼šç®€åŒ–åˆå§‹åŒ–æµç¨‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼Œä¸é¢„åŠ è½½æ¨¡å‹ï¼‰
        # æ¨¡å‹å’Œ Phoenix å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶æŒ‰éœ€åŠ è½½
        st.session_state.boot_ready = True
        st.rerun()
        return
    
    # æ˜¾ç¤ºä¾§è¾¹æ 
    sidebar()
    
    # åˆå§‹åŒ–RAGæœåŠ¡ï¼ˆæ–°æ¶æ„æ¨èï¼‰
    rag_service = load_rag_service()
    if not rag_service:
        st.error("âŒ RAGæœåŠ¡åˆå§‹åŒ–å¤±è´¥")
        return
    
    # åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨ï¼ˆç”¨äºä¼šè¯ç®¡ç†å’Œå†å²è®°å½•ï¼‰
    chat_manager = load_chat_manager()
    if not chat_manager:
        st.error("âŒ å¯¹è¯ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥")
        return
    
    # è¾…åŠ©å‡½æ•°ï¼šä½¿ç”¨RAGServiceæ‰§è¡ŒæŸ¥è¯¢
    def execute_query_with_rag_service(query: str, user_id: str = None, session_id: str = None):
        """ä½¿ç”¨RAGServiceæ‰§è¡ŒæŸ¥è¯¢
        
        Returns:
            tuple: (answer, sources)
                - answer: å›ç­”æ–‡æœ¬
                - sources: æ¥æºåˆ—è¡¨
        """
        try:
            # ä½¿ç”¨RAGServiceæŸ¥è¯¢
            response = rag_service.query(
                question=query,
                user_id=user_id,  # å•ç”¨æˆ·æ¨¡å¼ï¼Œuser_idå¯ä¸ºNone
                session_id=session_id or (chat_manager.current_session.session_id if chat_manager.current_session else None),
            )
            
            return response.answer, convert_sources_to_dict(response.sources)
        except Exception as e:
            logger.error(f"RAGServiceæŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
            raise
    
    # ========== å¤„ç†å†å²ä¼šè¯åŠ è½½ ==========
    if 'load_session_id' in st.session_state and st.session_state.load_session_id:
        from src.business.chat import load_session_from_file
        
        # åŠ è½½å†å²ä¼šè¯
        session_path = st.session_state.load_session_path
        loaded_session = load_session_from_file(session_path)
        
        if loaded_session:
            # å°†å†å²ä¼šè¯è®¾ç½®ä¸ºå½“å‰ä¼šè¯
            chat_manager.current_session = loaded_session
            
            # å°†ä¼šè¯å†å²è½¬æ¢ä¸ºmessagesæ ¼å¼
            st.session_state.messages = []
            # æ¸…ç©ºå¼•ç”¨æ¥æºæ˜ å°„ï¼Œé¿å…æ˜¾ç¤ºä¸Šä¸€ä¸ªå¯¹è¯çš„å¼•ç”¨æ¥æº
            st.session_state.current_sources_map = {}
            
            for idx, turn in enumerate(loaded_session.history):
                # ç”¨æˆ·æ¶ˆæ¯
                st.session_state.messages.append({
                    "role": "user",
                    "content": turn.question
                })
                # AIå›å¤ï¼ˆåŒ…å«æ¨ç†é“¾ï¼Œå¦‚æœå­˜åœ¨ï¼‰
                assistant_msg = {
                    "role": "assistant",
                    "content": turn.answer,
                    "sources": turn.sources
                }
                # å¦‚æœä¼šè¯å†å²ä¸­åŒ…å«æ¨ç†é“¾ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                if hasattr(turn, 'reasoning_content') and turn.reasoning_content:
                    assistant_msg["reasoning_content"] = turn.reasoning_content
                st.session_state.messages.append(assistant_msg)
                
                # å¦‚æœæœ‰å¼•ç”¨æ¥æºï¼Œå­˜å‚¨åˆ°current_sources_map
                if turn.sources:
                    message_id = f"msg_{len(st.session_state.messages)-1}_{hash(str(assistant_msg))}"
                    # ç¡®ä¿sourcesæ˜¯å­—å…¸æ ¼å¼å¹¶åŒ…å«indexå­—æ®µ
                    converted_sources = convert_sources_to_dict(turn.sources)
                    st.session_state.current_sources_map[message_id] = converted_sources
                    # åŒæ—¶æ›´æ–°æ¶ˆæ¯ä¸­çš„sources
                    assistant_msg["sources"] = converted_sources
            
            st.success(f"âœ… å·²åŠ è½½ä¼šè¯: {loaded_session.title}")
        else:
            st.error("âŒ åŠ è½½ä¼šè¯å¤±è´¥")
        
        # æ¸…é™¤åŠ è½½æ ‡è®°
        del st.session_state.load_session_id
        del st.session_state.load_session_path
        st.rerun()
    
    # ========== æ˜¾ç¤ºå¸¸é©»æ ‡é¢˜ï¼ˆåŸºäºç¬¬ä¸€ä¸ªç”¨æˆ·é—®é¢˜ï¼Œå±…ä¸­æ˜¾ç¤ºï¼‰ ==========
    chat_title = get_chat_title(st.session_state.messages)
    if chat_title:
        st.markdown(f"<div style='text-align: center;'><h3>{chat_title}</h3></div>", unsafe_allow_html=True)
        st.markdown("---")
    
    # å­˜å‚¨å½“å‰æ¶ˆæ¯çš„å¼•ç”¨æ¥æºå’Œæ¨ç†é“¾ï¼ˆç”¨äºå³ä¾§æ˜¾ç¤ºï¼‰
    if 'current_sources_map' not in st.session_state:
        st.session_state.current_sources_map = {}
    if 'current_reasoning_map' not in st.session_state:
        st.session_state.current_reasoning_map = {}
    current_sources_map = st.session_state.current_sources_map.copy()  # ä½¿ç”¨å‰¯æœ¬ï¼Œé¿å…ç›´æ¥ä¿®æ”¹
    current_reasoning_map = st.session_state.current_reasoning_map.copy()
    
    # å…ˆå¡«å……current_sources_mapï¼ˆä»å†å²æ¶ˆæ¯ä¸­æå–ï¼‰
    for idx, message in enumerate(st.session_state.messages):
        if message["role"] == "assistant":
            message_id = f"msg_{idx}_{hash(str(message))}"
            if "sources" in message and message["sources"]:
                # ç¡®ä¿sourcesæ˜¯å­—å…¸æ ¼å¼
                sources = message["sources"]
                logger.debug(f"å¤„ç†æ¶ˆæ¯ {idx} çš„sources: type={type(sources)}, len={len(sources) if sources else 0}")
                
                # ç»Ÿä¸€è½¬æ¢ï¼šæ— è®ºä»€ä¹ˆæ ¼å¼ï¼Œéƒ½è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨ï¼ˆç¡®ä¿æ ¼å¼ä¸€è‡´ï¼‰
                if sources:
                    # æ£€æŸ¥ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å¦æ˜¯å­—å…¸
                    if len(sources) > 0:
                        first_item = sources[0]
                        # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œæˆ–è€…æœ‰model_dumpæ–¹æ³•ï¼ˆPydanticæ¨¡å‹ï¼‰ï¼Œéƒ½éœ€è¦è½¬æ¢
                        if not isinstance(first_item, dict) or hasattr(first_item, 'model_dump'):
                            logger.debug(f"è½¬æ¢sources: ä» {type(first_item)} è½¬æ¢ä¸ºå­—å…¸")
                            sources = convert_sources_to_dict(sources)
                            message["sources"] = sources  # æ›´æ–°æ¶ˆæ¯ä¸­çš„sources
                    
                    logger.debug(f"æœ€ç»ˆsources: len={len(sources)}, ç¬¬ä¸€ä¸ªå…ƒç´ ç±»å‹={type(sources[0]) if sources else 'empty'}")
                    current_sources_map[message_id] = sources
                else:
                    current_sources_map[message_id] = []
            else:
                current_sources_map[message_id] = []
                
            # å¤„ç†æ¨ç†é“¾
            if "reasoning_content" in message:
                current_reasoning_map[message_id] = message["reasoning_content"]
    
    # ========== ä¸»å†…å®¹åŒºåŸŸï¼šç»Ÿä¸€å¸ƒå±€ï¼Œå¼•ç”¨æ¥æºæ˜¾ç¤ºåœ¨æ¶ˆæ¯ä¸‹æ–¹ ==========
    
    # å¦‚æœæ— å¯¹è¯å†å²ï¼Œå°†"å¿«é€Ÿå¼€å§‹"å’Œè¾“å…¥æ¡†æ•´å—å‚ç›´å±…ä¸­
    if not st.session_state.messages:
        # ä½¿ç”¨ flexbox å®ç°å‚ç›´å±…ä¸­
        st.markdown("""
        <style>
        .quick-start-container {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            min-height: 85vh;
            padding: 2rem 0;
        }
        </style>
        <div class="quick-start-container">
        """, unsafe_allow_html=True)
        
        # ä½¿ç”¨ columns å®ç°æ°´å¹³å±…ä¸­ï¼ˆç¼©å°å®½åº¦ï¼‰
        left_spacer, center_col, right_spacer = st.columns([2, 6, 2])
        
        with center_col:
            st.markdown("### ğŸ’¡ å¿«é€Ÿå¼€å§‹")
            st.caption("ç‚¹å‡»ä¸‹æ–¹é—®é¢˜å¿«é€Ÿä½“éªŒ")
            
            default_questions = [
                "ä»€ä¹ˆæ˜¯ç³»ç»Ÿç§‘å­¦ï¼Ÿå®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯ä»€ä¹ˆï¼Ÿ",
                "é’±å­¦æ£®å¯¹ç³»ç»Ÿç§‘å­¦æœ‰å“ªäº›è´¡çŒ®ï¼Ÿ",
                "ä»å®šæ€§åˆ°å®šé‡çš„ç»¼åˆé›†æˆæ³•å¦‚ä½•ä¸é©¬å…‹æ€ä¸»ä¹‰å“²å­¦ç»“åˆèµ·æ¥ç†è§£ï¼Ÿ",
                "ç³»ç»Ÿå·¥ç¨‹åœ¨ç°ä»£ç§‘å­¦ä¸­çš„åº”ç”¨æœ‰å“ªäº›ï¼Ÿ"
            ]
            
            # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€å±•ç¤ºé—®é¢˜æŒ‰é’®
            col1, col2 = st.columns(2)
            for idx, question in enumerate(default_questions):
                col = col1 if idx % 2 == 0 else col2
                with col:
                    if st.button(f"ğŸ’¬ {question}", key=f"default_q_{idx}", use_container_width=True):
                        # ç«‹å³å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°å†å²ï¼Œé¿å…rerunåå†æ¬¡æ˜¾ç¤º"å¿«é€Ÿå¼€å§‹"
                        st.session_state.messages.append({"role": "user", "content": question})
                        # å°†é—®é¢˜è®¾ç½®ä¸ºç”¨æˆ·è¾“å…¥ï¼ˆç”¨äºè§¦å‘æŸ¥è¯¢ï¼‰
                        st.session_state.selected_question = question
                        st.rerun()
            
            # åœ¨å¿«é€Ÿå¼€å§‹ä¸‹æ–¹æ·»åŠ è¾“å…¥æ¡†ï¼ˆä¹Ÿåœ¨å±…ä¸­å®¹å™¨å†…ï¼‰
            st.markdown("<br>", unsafe_allow_html=True)  # æ·»åŠ ä¸€äº›é—´è·
            from src.ui.chat_input import deepseek_style_chat_input
            # åªæ˜¾ç¤ºè¾“å…¥æ¡†ï¼Œä¸åœ¨è¿™é‡Œå¤„ç†é€»è¾‘ï¼ˆå› ä¸ºä¸€æ—¦æœ‰æ¶ˆæ¯ï¼Œå¿«é€Ÿå¼€å§‹å°±ä¼šæ¶ˆå¤±ï¼‰
            prompt = deepseek_style_chat_input("ç»™ç³»ç»Ÿå‘é€æ¶ˆæ¯", key="main_chat_input", fixed=False)
        
        st.markdown("</div>", unsafe_allow_html=True)
        
        # å¤„ç†è¾“å…¥æ¡†çš„å‘é€é€»è¾‘ï¼ˆåœ¨å®¹å™¨å¤–ï¼Œä½†åªåœ¨æ²¡æœ‰å¯¹è¯å†å²æ—¶æ‰§è¡Œï¼‰
        # æ³¨æ„ï¼šä¸€æ—¦æœ‰æ¶ˆæ¯ï¼Œä¸‹æ¬¡ rerun æ—¶å¿«é€Ÿå¼€å§‹å°±ä¸ä¼šæ˜¾ç¤ºäº†
        if prompt:
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²ï¼ˆè¿™ä¼šå¯¼è‡´å¿«é€Ÿå¼€å§‹æ¶ˆå¤±ï¼‰
            st.session_state.messages.append({"role": "user", "content": prompt})
            # è®¾ç½®å¾…å¤„ç†çš„æŸ¥è¯¢ï¼Œåœ¨ rerun åå¤„ç†
            st.session_state.pending_query = prompt
            # ç«‹å³ rerunï¼Œè®©å¿«é€Ÿå¼€å§‹æ¶ˆå¤±
            st.rerun()
    
    # å¤„ç†å¾…å¤„ç†çš„æŸ¥è¯¢ï¼ˆåœ¨å¿«é€Ÿå¼€å§‹æ¶ˆå¤±åï¼‰
    if 'pending_query' in st.session_state and st.session_state.pending_query:
        prompt = st.session_state.pending_query
        del st.session_state.pending_query  # æ¸…é™¤å¾…å¤„ç†æ ‡è®°
        
        # æ˜¾ç¤ºæ€è€ƒä¸­çš„æç¤º
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” æ€è€ƒä¸­..."):
                try:
                    # ä½¿ç”¨RAGServiceæ‰§è¡ŒæŸ¥è¯¢ï¼ˆæ–°æ¶æ„ï¼‰
                    response = rag_service.query(
                        question=prompt,
                        user_id=None,
                        session_id=chat_manager.current_session.session_id if chat_manager.current_session else None,
                    )
                    
                    answer = response.answer
                    local_sources = convert_sources_to_dict(response.sources)
                    reasoning_content = response.metadata.get('reasoning_content')
                    
                    # ç”Ÿæˆæ¶ˆæ¯ID
                    msg_idx = len(st.session_state.messages)
                    message_id = f"msg_{msg_idx}_{hash(str(answer))}"
                    
                    # ä¿å­˜åˆ°æ¶ˆæ¯å†å²
                    if answer:
                        assistant_msg = {
                            "role": "assistant",
                            "content": answer,
                            "sources": local_sources
                        }
                        if reasoning_content:
                            assistant_msg["reasoning_content"] = reasoning_content
                        st.session_state.messages.append(assistant_msg)
                    
                    # å­˜å‚¨å¼•ç”¨æ¥æº
                    current_sources_map[message_id] = local_sources
                    if reasoning_content:
                        current_reasoning_map[message_id] = reasoning_content
                    
                    # ç«‹å³æ˜¾ç¤ºAIå›ç­”
                    if "sources" in assistant_msg and assistant_msg["sources"]:
                        formatted_content = format_answer_with_citation_links(
                            answer,
                            assistant_msg["sources"],
                            message_id=message_id
                        )
                        st.markdown(formatted_content, unsafe_allow_html=True)
                    else:
                        st.markdown(answer)
                    
                    # æ˜¾ç¤ºæ¨ç†é“¾
                    if reasoning_content:
                        with st.expander("ğŸ§  æ¨ç†è¿‡ç¨‹", expanded=False):
                            st.markdown(f"```\n{reasoning_content}\n```")
                    
                    # æ˜¾ç¤ºå¼•ç”¨æ¥æº
                    if local_sources:
                        st.markdown("#### ğŸ“š å¼•ç”¨æ¥æº")
                        display_sources_below_message(local_sources, message_id=message_id)
                    
                    # ä¿å­˜åˆ°ChatManagerä¼šè¯
                    if chat_manager and answer:
                        if not chat_manager.current_session:
                            chat_manager.start_session()
                        if reasoning_content:
                            chat_manager.current_session.add_turn(prompt, answer, local_sources, reasoning_content)
                        else:
                            chat_manager.current_session.add_turn(prompt, answer, local_sources)
                        if chat_manager.auto_save:
                            chat_manager.save_current_session()
                    
                    # æ›´æ–°session_state
                    st.session_state.current_sources_map = current_sources_map
                    st.session_state.current_reasoning_map = current_reasoning_map
                    
                except Exception as e:
                    import traceback
                    st.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
                    st.error(traceback.format_exc())
    
    # å¦‚æœæœ‰å¯¹è¯å†å²ï¼Œä½¿ç”¨å±…ä¸­å¸ƒå±€
    if st.session_state.messages:
        # ä½¿ç”¨ columns å®ç°æ°´å¹³å±…ä¸­ï¼ˆç¼©å°å®½åº¦ï¼‰
        left_spacer, center_col, right_spacer = st.columns([2, 6, 2])
        
        with center_col:
            # æ˜¾ç¤ºå¯¹è¯å†å²
            for idx, message in enumerate(st.session_state.messages):
                message_id = f"msg_{idx}_{hash(str(message))}"
                with st.chat_message(message["role"]):
                    # å¦‚æœæ˜¯AIå›ç­”ä¸”åŒ…å«å¼•ç”¨ï¼Œä½¿ç”¨å¸¦é“¾æ¥çš„æ ¼å¼
                    if message["role"] == "assistant" and "sources" in message and message["sources"]:
                        formatted_content = format_answer_with_citation_links(
                            message["content"],
                            message["sources"],
                            message_id=message_id
                        )
                        st.markdown(formatted_content, unsafe_allow_html=True)
                    else:
                        st.markdown(message["content"])
                    
                    # æ˜¾ç¤ºæ¨ç†é“¾ï¼ˆå§‹ç»ˆæ˜¾ç¤ºï¼Œå¦‚æœå­˜åœ¨ï¼‰
                    if message["role"] == "assistant":
                        reasoning_content = message.get("reasoning_content")
                        # è°ƒè¯•ï¼šæ£€æŸ¥æ¨ç†é“¾æ˜¯å¦å­˜åœ¨
                        if reasoning_content:
                            with st.expander("ğŸ§  æ¨ç†è¿‡ç¨‹", expanded=False):
                                st.markdown(f"```\n{reasoning_content}\n```")
                        else:
                            # è°ƒè¯•ï¼šæ˜¾ç¤ºä¸ºä»€ä¹ˆæ²¡æœ‰æ¨ç†é“¾
                            if config.DEEPSEEK_ENABLE_REASONING_DISPLAY:
                                # åªåœ¨å¯ç”¨æ˜¾ç¤ºæ—¶æ‰æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                                logger.debug(f"æ¶ˆæ¯ {message_id} æ²¡æœ‰æ¨ç†é“¾å†…å®¹")
                
                # åœ¨æ¶ˆæ¯ä¸‹æ–¹æ˜¾ç¤ºå¼•ç”¨æ¥æºï¼ˆå¦‚æœæœ‰ï¼‰
                if message["role"] == "assistant":
                    sources = current_sources_map.get(message_id, [])
                    if sources:
                        # æ˜¾ç¤ºå¼•ç”¨æ¥æºæ ‡é¢˜
                        st.markdown("#### ğŸ“š å¼•ç”¨æ¥æº")
                        # æ˜¾ç¤ºå¼•ç”¨æ¥æºè¯¦æƒ…
                        display_sources_below_message(sources, message_id=message_id)
                
                # æ›´æ–°session_stateä¸­çš„æ˜ å°„ï¼ˆç¡®ä¿åŒæ­¥ï¼‰
                st.session_state.current_sources_map = current_sources_map
                st.session_state.current_reasoning_map = current_reasoning_map
            
            # å¤„ç†é»˜è®¤é—®é¢˜çš„ç‚¹å‡»ï¼ˆåœ¨æ˜¾ç¤ºæ¶ˆæ¯å¾ªç¯ä¹‹åï¼Œé¿å…é‡å¤æ˜¾ç¤ºï¼‰
            if 'selected_question' in st.session_state and st.session_state.selected_question:
                prompt = st.session_state.selected_question
                st.session_state.selected_question = None  # æ¸…é™¤çŠ¶æ€
                
                # æ³¨æ„ï¼šç”¨æˆ·æ¶ˆæ¯å·²ç»åœ¨ç‚¹å‡»æŒ‰é’®æ—¶æ·»åŠ åˆ°å†å²äº†ï¼Œè¿™é‡Œåªéœ€è¦å¤„ç†æŸ¥è¯¢
                # æ˜¾ç¤ºæ€è€ƒä¸­çš„æç¤ºï¼ˆä½¿ç”¨chat_messageæ ·å¼ï¼‰
                with st.chat_message("assistant"):
                        with st.spinner("ğŸ¤” æ€è€ƒä¸­..."):
                            try:
                                # ä½¿ç”¨RAGServiceæ‰§è¡ŒæŸ¥è¯¢ï¼ˆæ–°æ¶æ„ï¼‰
                                response = rag_service.query(
                                    question=prompt,
                                    user_id=None,  # å•ç”¨æˆ·æ¨¡å¼ï¼Œä¸éœ€è¦ç”¨æˆ·æ ‡è¯†
                                    session_id=chat_manager.current_session.session_id if chat_manager.current_session else None,
                                )
                                
                                answer = response.answer
                                local_sources = convert_sources_to_dict(response.sources)
                                reasoning_content = response.metadata.get('reasoning_content')
                                
                                # ç”Ÿæˆæ¶ˆæ¯ID
                                msg_idx = len(st.session_state.messages)
                                message_id = f"msg_{msg_idx}_{hash(str(answer))}"
                                
                                # ä¿å­˜åˆ°æ¶ˆæ¯å†å²ï¼ˆUIæ˜¾ç¤ºç”¨ï¼ŒåŒ…å«æ¨ç†é“¾ï¼‰
                                if answer:  # åªåœ¨æœ‰ç­”æ¡ˆæ—¶ä¿å­˜
                                    assistant_msg = {
                                        "role": "assistant",
                                        "content": answer,
                                        "sources": local_sources
                                    }
                                    if reasoning_content:
                                        assistant_msg["reasoning_content"] = reasoning_content
                                    st.session_state.messages.append(assistant_msg)
                                
                                # å­˜å‚¨å¼•ç”¨æ¥æº
                                current_sources_map[message_id] = local_sources
                                if reasoning_content:
                                    current_reasoning_map[message_id] = reasoning_content
                                
                                # ç«‹å³æ˜¾ç¤ºAIå›ç­”ï¼ˆé¿å…ç™½å±ï¼‰
                                if "sources" in assistant_msg and assistant_msg["sources"]:
                                    formatted_content = format_answer_with_citation_links(
                                        answer,
                                        assistant_msg["sources"],
                                        message_id=message_id
                                    )
                                    st.markdown(formatted_content, unsafe_allow_html=True)
                                else:
                                    st.markdown(answer)
                                
                                # æ˜¾ç¤ºæ¨ç†é“¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                                if reasoning_content:
                                    with st.expander("ğŸ§  æ¨ç†è¿‡ç¨‹", expanded=False):
                                        st.markdown(f"```\n{reasoning_content}\n```")
                                
                                # æ˜¾ç¤ºå¼•ç”¨æ¥æºï¼ˆå¦‚æœæœ‰ï¼‰
                                if local_sources:
                                    st.markdown("#### ğŸ“š å¼•ç”¨æ¥æº")
                                    display_sources_below_message(local_sources, message_id=message_id)
                                
                                # åŒæ—¶ä¿å­˜åˆ°ChatManagerä¼šè¯ï¼ˆæŒä¹…åŒ–ï¼‰
                                if chat_manager and answer:
                                    # å¦‚æœæ²¡æœ‰å½“å‰ä¼šè¯ï¼Œå…ˆåˆ›å»ºä¸€ä¸ª
                                    if not chat_manager.current_session:
                                        chat_manager.start_session()
                                    # ä¿å­˜å¯¹è¯ï¼ˆå§‹ç»ˆå­˜å‚¨æ¨ç†é“¾ï¼Œå¦‚æœå­˜åœ¨ï¼‰
                                    if reasoning_content:
                                        chat_manager.current_session.add_turn(prompt, answer, local_sources, reasoning_content)
                                    else:
                                        chat_manager.current_session.add_turn(prompt, answer, local_sources)
                                    # è‡ªåŠ¨ä¿å­˜
                                    if chat_manager.auto_save:
                                        chat_manager.save_current_session()
                                
                                # æ›´æ–°session_state
                                st.session_state.current_sources_map = current_sources_map
                                st.session_state.current_reasoning_map = current_reasoning_map
                                
                                # æ¸…é™¤æ€è€ƒä¸­æ ‡å¿—
                                st.session_state.is_thinking = False
                            
                            except Exception as e:
                                import traceback
                                st.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
                                st.error(traceback.format_exc())
                                # å³ä½¿å‡ºé”™ä¹Ÿè¦æ¸…é™¤æ€è€ƒä¸­æ ‡å¿—
                                st.session_state.is_thinking = False
    
    # å¤„ç†ç”¨æˆ·è¾“å…¥åçš„æŸ¥è¯¢ï¼ˆåœ¨æ˜¾ç¤ºæ¶ˆæ¯å¾ªç¯ä¹‹åï¼‰
    if 'user_input_prompt' in st.session_state and st.session_state.user_input_prompt:
        message_id = f"msg_{idx}_{hash(str(message))}"
        with st.chat_message(message["role"]):
            # å¦‚æœæ˜¯AIå›ç­”ä¸”åŒ…å«å¼•ç”¨ï¼Œä½¿ç”¨å¸¦é“¾æ¥çš„æ ¼å¼
            if message["role"] == "assistant" and "sources" in message and message["sources"]:
                formatted_content = format_answer_with_citation_links(
                    message["content"],
                    message["sources"],
                    message_id=message_id
                )
                st.markdown(formatted_content, unsafe_allow_html=True)
            else:
                st.markdown(message["content"])
            
            # æ˜¾ç¤ºæ¨ç†é“¾ï¼ˆå§‹ç»ˆæ˜¾ç¤ºï¼Œå¦‚æœå­˜åœ¨ï¼‰
            if message["role"] == "assistant":
                reasoning_content = message.get("reasoning_content")
                # è°ƒè¯•ï¼šæ£€æŸ¥æ¨ç†é“¾æ˜¯å¦å­˜åœ¨
                if reasoning_content:
                    with st.expander("ğŸ§  æ¨ç†è¿‡ç¨‹", expanded=False):
                        st.markdown(f"```\n{reasoning_content}\n```")
                else:
                    # è°ƒè¯•ï¼šæ˜¾ç¤ºä¸ºä»€ä¹ˆæ²¡æœ‰æ¨ç†é“¾
                    if config.DEEPSEEK_ENABLE_REASONING_DISPLAY:
                        # åªåœ¨å¯ç”¨æ˜¾ç¤ºæ—¶æ‰æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                        logger.debug(f"æ¶ˆæ¯ {message_id} æ²¡æœ‰æ¨ç†é“¾å†…å®¹")
        
        # åœ¨æ¶ˆæ¯ä¸‹æ–¹æ˜¾ç¤ºå¼•ç”¨æ¥æºï¼ˆå¦‚æœæœ‰ï¼‰
        if message["role"] == "assistant":
            sources = current_sources_map.get(message_id, [])
            if sources:
                # æ˜¾ç¤ºå¼•ç”¨æ¥æºæ ‡é¢˜
                st.markdown("#### ğŸ“š å¼•ç”¨æ¥æº")
                # æ˜¾ç¤ºå¼•ç”¨æ¥æºè¯¦æƒ…
                display_sources_below_message(sources, message_id=message_id)
        
        # æ›´æ–°session_stateä¸­çš„æ˜ å°„ï¼ˆç¡®ä¿åŒæ­¥ï¼‰
        st.session_state.current_sources_map = current_sources_map
        st.session_state.current_reasoning_map = current_reasoning_map
    
    # ç”¨æˆ·è¾“å…¥ï¼ˆMaterial Designé£æ ¼ï¼Œå¤šè¡Œè¾“å…¥ + è‡ªåŠ¨é«˜åº¦è°ƒæ•´ + é”®ç›˜å¿«æ·é”® + å­—ç¬¦è®¡æ•°ï¼‰
    # æ³¨æ„ï¼šå¦‚æœæ²¡æœ‰å¯¹è¯å†å²ï¼Œè¾“å…¥æ¡†å·²ç»åœ¨å¿«é€Ÿå¼€å§‹å®¹å™¨å†…äº†ï¼Œè¿™é‡Œåªå¤„ç†æœ‰å¯¹è¯å†å²çš„æƒ…å†µ
    if st.session_state.messages:
        from src.ui.chat_input import deepseek_style_chat_input
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ€è€ƒä¸­
        is_thinking = st.session_state.get('is_thinking', False)
        # æœ‰å¯¹è¯å†å²æ—¶ï¼Œè¾“å…¥æ¡†å›ºå®šåœ¨åº•éƒ¨
        prompt = deepseek_style_chat_input("ç»™ç³»ç»Ÿå‘é€æ¶ˆæ¯", key="main_chat_input", fixed=True)
    else:
        # å¦‚æœæ²¡æœ‰å¯¹è¯å†å²ï¼Œè¾“å…¥æ¡†å·²ç»åœ¨å¿«é€Ÿå¼€å§‹å®¹å™¨å†…å¤„ç†äº†
        prompt = None
    
    # å¤„ç†æœ‰å¯¹è¯å†å²æ—¶çš„ç”¨æˆ·è¾“å…¥
    if prompt and st.session_state.messages:
        # è®¾ç½®æ€è€ƒä¸­æ ‡å¿—
        st.session_state.is_thinking = True
        # ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯ï¼ˆé¿å…ç™½å±ï¼‰- åœ¨å±…ä¸­å¸ƒå±€å†…
        if st.session_state.messages:
            # å¦‚æœæœ‰å¯¹è¯å†å²ï¼Œåœ¨å±…ä¸­å¸ƒå±€å†…æ˜¾ç¤º
            left_spacer, center_col, right_spacer = st.columns([2, 6, 2])
            with center_col:
                with st.chat_message("user"):
                    st.markdown(prompt)
        else:
            # å¦‚æœæ²¡æœ‰å¯¹è¯å†å²ï¼Œç›´æ¥æ˜¾ç¤º
            with st.chat_message("user"):
                st.markdown(prompt)
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # æ˜¾ç¤ºæ€è€ƒä¸­çš„æç¤ºï¼ˆä½¿ç”¨chat_messageæ ·å¼ï¼Œä¸é»˜è®¤é—®é¢˜ä¸€è‡´ï¼‰- åœ¨å±…ä¸­å¸ƒå±€å†…
        if st.session_state.messages:
            left_spacer, center_col, right_spacer = st.columns([2, 6, 2])
            with center_col:
                with st.chat_message("assistant"):
                    # åˆ›å»ºæ¶ˆæ¯å ä½ç¬¦ç”¨äºæµå¼æ›´æ–°
                    message_placeholder = st.empty()
                    
                    try:
                        # ä½¿ç”¨æµå¼å¯¹è¯API
                        full_answer = ""
                        local_sources = []
                        reasoning_content = None
                        
                        # å¼‚æ­¥æµå¼å¤„ç†
                        async def process_stream():
                            nonlocal full_answer, local_sources, reasoning_content
                            async for chunk in chat_manager.stream_chat(prompt):
                                if chunk['type'] == 'token':
                                    full_answer += chunk['data']
                                    # å®æ—¶æ›´æ–°æ˜¾ç¤ºï¼ˆå¸¦å…‰æ ‡æ•ˆæœï¼‰
                                    message_placeholder.markdown(full_answer + "â–Œ")
                                elif chunk['type'] == 'sources':
                                    local_sources = chunk['data']
                                elif chunk['type'] == 'reasoning':
                                    reasoning_content = chunk['data']
                                elif chunk['type'] == 'done':
                                    # æµå¼å®Œæˆï¼Œç§»é™¤å…‰æ ‡
                                    message_placeholder.markdown(full_answer)
                                elif chunk['type'] == 'error':
                                    st.error(f"âŒ æµå¼å¯¹è¯å¤±è´¥: {chunk['data'].get('message', 'Unknown error')}")
                                    return
                        
                        # è¿è¡Œå¼‚æ­¥æµå¼å¤„ç†
                        import asyncio
                        asyncio.run(process_stream())
                        
                        # ç”Ÿæˆæ¶ˆæ¯ID
                        msg_idx = len(st.session_state.messages)
                        message_id = f"msg_{msg_idx}_{hash(str(full_answer))}"
                        
                        # è½¬æ¢å¼•ç”¨æ¥æºæ ¼å¼
                        local_sources = convert_sources_to_dict(local_sources)
                        
                        # è°ƒè¯•ï¼šæ£€æŸ¥æ¨ç†é“¾æå–æƒ…å†µ
                        logger.info(f"ğŸ” æ¨ç†é“¾æå–æ£€æŸ¥: reasoning_content={reasoning_content is not None}, é•¿åº¦={len(reasoning_content) if reasoning_content else 0}")
                        if reasoning_content:
                            logger.info(f"âœ… æ¨ç†é“¾å†…å®¹é¢„è§ˆï¼ˆå‰100å­—ç¬¦ï¼‰: {reasoning_content[:100]}...")
                        else:
                            logger.warning("âš ï¸ å“åº”ä¸­æ²¡æœ‰æ¨ç†é“¾å†…å®¹ï¼Œæ£€æŸ¥ï¼š1) æ˜¯å¦ä½¿ç”¨ deepseek-reasoner æ¨¡å‹ 2) API æ˜¯å¦è¿”å›äº†æ¨ç†é“¾")
                        
                        # ä¿å­˜åˆ°æ¶ˆæ¯å†å²ï¼ˆUIæ˜¾ç¤ºç”¨ï¼ŒåŒ…å«æ¨ç†é“¾ï¼‰
                        if full_answer:  # åªåœ¨æœ‰ç­”æ¡ˆæ—¶ä¿å­˜
                            assistant_msg = {
                                "role": "assistant",
                                "content": full_answer,
                                "sources": local_sources
                            }
                            if reasoning_content:
                                assistant_msg["reasoning_content"] = reasoning_content
                            st.session_state.messages.append(assistant_msg)
                        
                        # å­˜å‚¨å¼•ç”¨æ¥æº
                        current_sources_map[message_id] = local_sources
                        if reasoning_content:
                            current_reasoning_map[message_id] = reasoning_content
                        
                        # æ˜¾ç¤ºå¸¦å¼•ç”¨çš„æ ¼å¼åŒ–å†…å®¹ï¼ˆå¦‚æœæœ‰æ¥æºï¼‰
                        if local_sources:
                            formatted_content = format_answer_with_citation_links(
                                full_answer,
                                local_sources,
                                message_id=message_id
                            )
                            message_placeholder.markdown(formatted_content, unsafe_allow_html=True)
                        
                        # æ˜¾ç¤ºæ¨ç†é“¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if reasoning_content:
                            with st.expander("ğŸ§  æ¨ç†è¿‡ç¨‹", expanded=False):
                                st.markdown(f"```\n{reasoning_content}\n```")
                        
                        # æ˜¾ç¤ºå¼•ç”¨æ¥æºï¼ˆå¦‚æœæœ‰ï¼‰
                        if local_sources:
                            st.markdown("#### ğŸ“š å¼•ç”¨æ¥æº")
                            display_sources_below_message(local_sources, message_id=message_id)
                        
                        # åŒæ—¶ä¿å­˜åˆ°ChatManagerä¼šè¯ï¼ˆæŒä¹…åŒ–ï¼‰
                        if chat_manager and full_answer:
                            if not chat_manager.current_session:
                                chat_manager.start_session()
                            # ä¿å­˜å¯¹è¯ï¼ˆå§‹ç»ˆå­˜å‚¨æ¨ç†é“¾ï¼Œå¦‚æœå­˜åœ¨ï¼‰
                            if reasoning_content:
                                chat_manager.current_session.add_turn(prompt, full_answer, local_sources, reasoning_content)
                            else:
                                chat_manager.current_session.add_turn(prompt, full_answer, local_sources)
                            if chat_manager.auto_save:
                                chat_manager.save_current_session()
                        
                        # æ›´æ–°session_state
                        st.session_state.current_sources_map = current_sources_map
                        st.session_state.current_reasoning_map = current_reasoning_map
                        
                        # æ¸…é™¤æ€è€ƒä¸­æ ‡å¿—
                        st.session_state.is_thinking = False
                        
                    except Exception as e:
                        import traceback
                        st.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
                        st.error(traceback.format_exc())
                        # å³ä½¿å‡ºé”™ä¹Ÿè¦æ¸…é™¤æ€è€ƒä¸­æ ‡å¿—
                        st.session_state.is_thinking = False
        else:
            # å¦‚æœæ²¡æœ‰å¯¹è¯å†å²ï¼Œç›´æ¥æ˜¾ç¤º
            # è®¾ç½®æ€è€ƒä¸­æ ‡å¿—
            st.session_state.is_thinking = True
            with st.chat_message("assistant"):
                # åˆ›å»ºæ¶ˆæ¯å ä½ç¬¦ç”¨äºæµå¼æ›´æ–°
                message_placeholder = st.empty()
                
                try:
                    # ä½¿ç”¨æµå¼å¯¹è¯API
                    full_answer = ""
                    local_sources = []
                    reasoning_content = None
                    
                    # å¼‚æ­¥æµå¼å¤„ç†
                    async def process_stream():
                        nonlocal full_answer, local_sources, reasoning_content
                        async for chunk in chat_manager.stream_chat(prompt):
                            if chunk['type'] == 'token':
                                full_answer += chunk['data']
                                # å®æ—¶æ›´æ–°æ˜¾ç¤ºï¼ˆå¸¦å…‰æ ‡æ•ˆæœï¼‰
                                message_placeholder.markdown(full_answer + "â–Œ")
                            elif chunk['type'] == 'sources':
                                local_sources = chunk['data']
                            elif chunk['type'] == 'reasoning':
                                reasoning_content = chunk['data']
                            elif chunk['type'] == 'done':
                                # æµå¼å®Œæˆï¼Œç§»é™¤å…‰æ ‡
                                message_placeholder.markdown(full_answer)
                            elif chunk['type'] == 'error':
                                st.error(f"âŒ æµå¼å¯¹è¯å¤±è´¥: {chunk['data'].get('message', 'Unknown error')}")
                                return
                    
                    # è¿è¡Œå¼‚æ­¥æµå¼å¤„ç†
                    import asyncio
                    asyncio.run(process_stream())
                    
                    # ç”Ÿæˆæ¶ˆæ¯ID
                    msg_idx = len(st.session_state.messages)
                    message_id = f"msg_{msg_idx}_{hash(str(full_answer))}"
                    
                    # è½¬æ¢å¼•ç”¨æ¥æºæ ¼å¼
                    local_sources = convert_sources_to_dict(local_sources)
                    
                    # è°ƒè¯•ï¼šæ£€æŸ¥æ¨ç†é“¾æå–æƒ…å†µ
                    logger.info(f"ğŸ” æ¨ç†é“¾æå–æ£€æŸ¥: reasoning_content={reasoning_content is not None}, é•¿åº¦={len(reasoning_content) if reasoning_content else 0}")
                    if reasoning_content:
                        logger.info(f"âœ… æ¨ç†é“¾å†…å®¹é¢„è§ˆï¼ˆå‰100å­—ç¬¦ï¼‰: {reasoning_content[:100]}...")
                    else:
                        logger.warning("âš ï¸ å“åº”ä¸­æ²¡æœ‰æ¨ç†é“¾å†…å®¹ï¼Œæ£€æŸ¥ï¼š1) æ˜¯å¦ä½¿ç”¨ deepseek-reasoner æ¨¡å‹ 2) API æ˜¯å¦è¿”å›äº†æ¨ç†é“¾")
                    
                    # ä¿å­˜åˆ°æ¶ˆæ¯å†å²ï¼ˆUIæ˜¾ç¤ºç”¨ï¼ŒåŒ…å«æ¨ç†é“¾ï¼‰
                    if full_answer:  # åªåœ¨æœ‰ç­”æ¡ˆæ—¶ä¿å­˜
                        assistant_msg = {
                            "role": "assistant",
                            "content": full_answer,
                            "sources": local_sources
                        }
                        if reasoning_content:
                            assistant_msg["reasoning_content"] = reasoning_content
                        st.session_state.messages.append(assistant_msg)
                    
                    # å­˜å‚¨å¼•ç”¨æ¥æº
                    current_sources_map[message_id] = local_sources
                    if reasoning_content:
                        current_reasoning_map[message_id] = reasoning_content
                    
                    # æ˜¾ç¤ºå¸¦å¼•ç”¨çš„æ ¼å¼åŒ–å†…å®¹ï¼ˆå¦‚æœæœ‰æ¥æºï¼‰
                    if local_sources:
                        formatted_content = format_answer_with_citation_links(
                            full_answer,
                            local_sources,
                            message_id=message_id
                        )
                        message_placeholder.markdown(formatted_content, unsafe_allow_html=True)
                    
                    # æ˜¾ç¤ºæ¨ç†é“¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if reasoning_content:
                        with st.expander("ğŸ§  æ¨ç†è¿‡ç¨‹", expanded=False):
                            st.markdown(f"```\n{reasoning_content}\n```")
                    
                    # æ˜¾ç¤ºå¼•ç”¨æ¥æºï¼ˆå¦‚æœæœ‰ï¼‰
                    if local_sources:
                        st.markdown("#### ğŸ“š å¼•ç”¨æ¥æº")
                        display_sources_below_message(local_sources, message_id=message_id)
                    
                    # åŒæ—¶ä¿å­˜åˆ°ChatManagerä¼šè¯ï¼ˆæŒä¹…åŒ–ï¼‰
                    if chat_manager and full_answer:
                        if not chat_manager.current_session:
                            chat_manager.start_session()
                        # ä¿å­˜å¯¹è¯ï¼ˆå§‹ç»ˆå­˜å‚¨æ¨ç†é“¾ï¼Œå¦‚æœå­˜åœ¨ï¼‰
                        if reasoning_content:
                            chat_manager.current_session.add_turn(prompt, full_answer, local_sources, reasoning_content)
                        else:
                            chat_manager.current_session.add_turn(prompt, full_answer, local_sources)
                        if chat_manager.auto_save:
                            chat_manager.save_current_session()
                    
                    # æ›´æ–°session_state
                    st.session_state.current_sources_map = current_sources_map
                    st.session_state.current_reasoning_map = current_reasoning_map
                    
                    # æ¸…é™¤æ€è€ƒä¸­æ ‡å¿—
                    st.session_state.is_thinking = False
                    
                except Exception as e:
                    import traceback
                    st.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
                    st.error(traceback.format_exc())
                    # å³ä½¿å‡ºé”™ä¹Ÿè¦æ¸…é™¤æ€è€ƒä¸­æ ‡å¿—
                    st.session_state.is_thinking = False


if __name__ == "__main__":
    main()

